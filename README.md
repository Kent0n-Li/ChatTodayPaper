
# ChatTodayPaperüìë

Subscribe to the topics you follow, and we'll send you the everyday relevant arxiv papers and summaries to your Email. [Subscription Links](http://chat.yunxiangli.top)

ËÆ¢ÈòÖ‰Ω†ÊâÄÂÖ≥Ê≥®ÁöÑ‰∏ªÈ¢òÔºåÊàë‰ª¨‰ºöÊääÊØèÂ§©Áõ∏ÂÖ≥ÁöÑarxivËÆ∫ÊñáÂíåÊëòË¶ÅÂèëÈÄÅÂà∞‰Ω†ÁöÑEmail„ÄÇ[ËÆ¢ÈòÖÈìæÊé•](http://chat.yunxiangli.top)


<div style="font-size: 1rem;">
  <a href="./README-zh.md">‰∏≠Êñá</a> |
  <a href="./README.md">English</a>   
</div>



<details>
<summary>Thu, 27 Apr 2023</summary>
    
<details>
<summary>Diffusion Model</summary>
    
Title: [Functional Diffusion Maps](http://arxiv.org/pdf/2304.14378v1)     
Summary: This paper introduces the use of Diffusion Maps, a non-linear manifold learning method, for functional data analysis. It compares its performance with the widely used functional PCA method in different simulated and real examples. The paper explains how to extend the multivariate Diffusion Maps method to functional data and highlights its advantages over linear methods when the data do not satisfy their assumptions.

Title: [Fast Sampling of $b$-Matchings and $b$-Edge Covers](http://arxiv.org/pdf/2304.14289v1)     
Summary: The paper proposes an efficient algorithm for sampling $b$-matchings and $b$-edge covers in bounded-degree graphs using the simple Glauber dynamics. The paper also proves spectral independence for a broad class of binary symmetric Holant problems with log-concave signatures, including $b$-matchings, $b$-edge covers, and antiferromagnetic $2$-spin edge models. The algorithm's mixing time is shown to be $O(n \log n)$, which significantly improves upon previous results that only worked for small values of $b$ and had worse running time. The paper's contributions are based on spectral graph theory and diffusion models.

Title: [Learning Neural PDE Solvers with Parameter-Guided Channel Attention](http://arxiv.org/pdf/2304.14118v1)     
Summary: The paper proposes a Channel Attention mechanism guided by PDE Parameter Embeddings (CAPE) component for neural surrogate models and a curriculum learning strategy to learn emulators of physical systems governed by partial differential equations (PDE). CAPE allows neural PDE solvers to adapt to unseen PDE parameters, resulting in consistent and significant improvements over baseline models on a popular PDE benchmark. The paper falls under the category of Diffusion Model and Scientific Machine Learning (SciML).

Title: [Linear and Nonlinear Parareal Methods for the Cahn-Hilliard Equation](http://arxiv.org/pdf/2304.14074v1)     
Summary: This paper proposes linear and nonlinear Parareal methods for efficient time parallel simulation of the Cahn-Hilliard equation. The CH equation is important in a range of applications and requires long simulation times, making parallelization desirable. The proposed methods are evaluated through numerical experiments.

Title: [Localized orthogonal decomposition for a multiscale parabolic stochastic partial differential equation](http://arxiv.org/pdf/2304.14049v1)     
Summary: The paper proposes a multiscale method based on the localized orthogonal decomposition (LOD) technique for a parabolic stochastic partial differential equation with highly oscillatory diffusion and additive noise. The method computes a coarse representation of the elliptic operator enriched by fine-scale information on the diffusion, and optimal order strong convergence is obtained. The paper combines LOD with a Monte-Carlo estimator, and numerical examples confirm the theoretical findings and the computational efficiency of the method.

Title: [Two kinds of numerical algorithms for ultra-slow diffusion equations](http://arxiv.org/pdf/2304.13966v1)     
Summary: The paper presents two numerical algorithms for the ultra-slow (or superslow) diffusion equation in one and two dimensions using Caputo-Hadamard fractional derivative of order $\alpha \in (0,1)$. The schemes use the Riesz fractional derivative and the fractional Laplacian to describe the spatial interaction and are discretized by L2-1$_{\sigma}$ and L1-2 methods. The derived numerical schemes are unconditionally stable with error estimates for all $\alpha \in (0, 1)$ and stable with error estimates for $\alpha \in (0, 0.3738)$. The paper includes illustrative examples that align with the theoretical analysis.

</details>
<details>
<summary>Large Language Models</summary>
    
Title: [Industrial Engineering with Large Language Models: A case study of ChatGPT's performance on Oil & Gas problems](http://arxiv.org/pdf/2304.14354v1)     
Summary: This academic paper discusses the potential of Large Language Models (LLMs) in solving complex problems in the field of industrial engineering, specifically in the context of oil and gas engineering. The limitations of LLM approaches, particularly ChatGPT, are identified and discussed. The paper also presents areas where LLMs are most effective in solving problems in this field.

Title: [The Dark Side of ChatGPT: Legal and Ethical Challenges from Stochastic Parrots and Hallucination](http://arxiv.org/pdf/2304.14347v1)     
Summary: The paper discusses the legal and ethical challenges posed by the emergence of Large Language Models like ChatGPT, particularly due to stochastic parrots and hallucination. It highlights the need for further evolution of the EU regulatory paradigm to mitigate these risks.

Title: [MarsEclipse at SemEval-2023 Task 3: Multi-Lingual and Multi-Label Framing Detection with Contrastive Learning](http://arxiv.org/pdf/2304.14339v1)     
Summary: The paper presents the MarsEclipse system for multi-lingual and multi-label framing detection using a contrastive loss function for fine-tuning large pre-trained language models. The system achieved first place on the official test set and leaderboard for five out of six languages in the SemEval-2023 Task 3 Subtask 2 on Framing Detection. The code is available on GitHub, and the paper details the experimental setup and includes various ablation studies.

Title: [q2d: Turning Questions into Dialogs to Teach Models How to Search](http://arxiv.org/pdf/2304.14318v1)     
Summary: The paper proposes a data generation pipeline, q2d, that generates information-seeking dialogs from questions to teach language models how to search. The pipeline uses a large language model to create conversational versions of question answering datasets and improve query generation models that communicate with external search APIs. The experiments show that the synthesized data achieves comparable performance to human-generated data for query generation and can be used to train dialog models in new domains without existing data. The paper falls under the categories of Large Language Models, Visual Question Answering (VQA), and Data Generation.

Title: [Large Language Models Are State-of-the-Art Evaluators of Code Generation](http://arxiv.org/pdf/2304.14317v1)     
Summary: This paper proposes a new evaluation framework, based on the GPT-3.5, for code generation assessments. The framework addresses the limitations of existing approaches by achieving superior correlations with functional correctness and human preferences, without the need for test oracles or references. The authors evaluate the efficacy of their framework on two different tasks and four programming languages, comparing its performance with the state-of-the-art CodeBERTScore metric, and demonstrate that their framework surpasses CodeBERTScore in delivering high levels of accuracy and consistency across various programming languages and tasks.

Title: [Controlled Text Generation with Natural Language Instructions](http://arxiv.org/pdf/2304.14293v1)     
Summary: This paper presents a framework for controlled text generation called InstructCTG that incorporates various constraints through natural language descriptions and demonstrations. It fine-tunes a pre-trained language model using weakly supervised training data and allows for adaptation to new constraints through few-shot task generalization and in-context learning abilities of instruction-tuned language models. The model is more flexible and has a smaller impact on generation quality and speed compared to existing methods that modify the decoding procedure. This paper falls under the categories of Controlled Text Generation, Large Language Models, and Few-Shot Learning.

Title: [AI, write an essay for me: A large-scale comparison of human-written versus ChatGPT-generated essays](http://arxiv.org/pdf/2304.14276v1)     
Summary: This paper compares human-written argumentative essays to those generated by the ChatGPT AI model. The study found that ChatGPT-generated essays were rated higher in quality than human-written essays and exhibited different linguistic characteristics. The paper argues that educators should incorporate AI models into the education system to free up time for other learning objectives.

Title: [What's in a Name? Evaluating Assembly-Part Semantic Knowledge in Language Models through User-Provided Names in CAD Files](http://arxiv.org/pdf/2304.14275v1)     
Summary: This paper proposes that natural language names used in Computer Aided Design (CAD) software contain valuable domain-specific information that can be used to improve Large Language Models' (LLMs) ability to understand assembly-part relationships. The authors extract a large corpus of natural language part, feature, and document names and show that fine-tuning a pre-trained LLM on this data improves its performance on self-supervised tasks, highlighting the value of text data in the CAD domain. The paper concludes by identifying limitations and calling for further work in multimodal text-geometry models.

Title: [Large Language Models are Strong Zero-Shot Retriever](http://arxiv.org/pdf/2304.14233v1)     
Summary: The paper proposes a method called Language model as Retriever (LameR) that utilizes large language models (LLMs) for zero-shot retrieval. The proposed method augments a query with its potential answers by prompting LLMs with a composition of the query and the query's in-domain candidates. This helps LLM generate more precise answers by pattern imitation or candidate summarization, making the retrieval procedure transparent to the LLM. The paper also suggests using a non-parametric lexicon-based method (e.g., BM25) as the retrieval module to capture query-document overlap in a literal fashion. The proposed method outperformed other state-of-the-art methods on benchmark datasets.

Title: [mPLUG-Owl: Modularization Empowers Large Language Models with Multimodality](http://arxiv.org/pdf/2304.14178v1)     
Summary: The paper introduces mPLUG-Owl, a training paradigm that equips LLMs with multi-modal abilities through modularized learning of foundation LLM, a visual knowledge module, and a visual abstractor module. The approach can support multiple modalities and facilitate diverse unimodal and multimodal abilities through modality collaboration. The model outperforms existing multi-modal models and demonstrates impressive instruction and visual understanding ability, multi-turn conversation ability, and knowledge reasoning ability. The paper is available along with code, pre-trained model, instruction-tuned models, and evaluation set on GitHub.

Title: [Origin Tracing and Detecting of LLMs](http://arxiv.org/pdf/2304.14072v1)     
Summary: The paper proposes a method to trace the origin of large language models (LLMs) and detect whether a given text context is generated by an AI system. The method is based on contrastive features between LLMs and extracts model-wise features to trace the text origins. The proposed approach works under both white-box and black-box settings and requires limited data compared to supervised learning methods. The paper provides valuable observations based on experimental results and calls for ethical concerns of LLM providers. The code and data are released as a toolkit and benchmark for future AI origin tracing and detecting studies.

Title: [SweCTRL-Mini: a data-transparent Transformer-based large language model for controllable text generation in Swedish](http://arxiv.org/pdf/2304.13994v1)     
Summary: The paper presents SweCTRL-Mini, a large language model for controllable text generation in Swedish. The model is based on the CTRL architecture and can be fine-tuned and used for inference on a single GPU. The authors provide details on the training data and text pre-processing and evaluate the model's performance on discriminative and generative tasks. SweCTRL-Mini is open-source and available for download.

Title: [Federated Prompting and Chain-of-Thought Reasoning for Improving LLMs Answering](http://arxiv.org/pdf/2304.13911v1)     
Summary: The paper proposes Fed-SP-SC and Fed-DP-CoT methods to enhance answer precision in frequently asked questions posed by distributed users using cloud-based Large Language Models (LLMs). The methods involve improving distributed synonymous questions using Self-Consistency and Chain-of-Thought techniques. Through extensive experiments, the proposed methods are demonstrated to significantly enhance question accuracy by fully exploring the synonymous nature of the questions and the consistency of the answers.

Title: [Is a prompt and a few samples all you need? Using GPT-4 for data augmentation in low-resource classification tasks](http://arxiv.org/pdf/2304.13861v1)     
Summary: The paper explores using GPT-4 and ChatGPT to augment small labeled datasets with synthetic data via simple prompts in low-resource classification tasks. They compare two augmentation strategies and find that synthetic data aids in identifying rare classes but human-annotated data exhibits a stronger predictive power in most cases. They also observe strong zero-shot performance across all tasks using GPT-4 and ChatGPT.

Title: [Translate to Disambiguate: Zero-shot Multilingual Word Sense Disambiguation with Pretrained Language Models](http://arxiv.org/pdf/2304.13803v1)     
Summary: The paper presents a study on how well Pretrained Language Models (PLMs) capture cross-lingual word sense knowledge with Contextual Word-Level Translation (C-WLT) and introduces a zero-shot approach for Word Sense Disambiguation (WSD) using PLMs. The study shows that as the model size increases, PLMs encode more cross-lingual word sense knowledge and better use context to improve WLT performance. The proposed zero-shot approach outperforms fully supervised baselines on recall for many evaluation languages without additional training or finetuning.

Title: [The Internal State of an LLM Knows When its Lying](http://arxiv.org/pdf/2304.13734v1)     
Summary: The paper proposes a method to detect the truthfulness of statements generated by Large Language Models (LLMs) using the LLM's internal state. They use the activation values in the hidden layer of LLM to determine if a statement is true or false. They compose a dataset of true and false statements and train a classifier that outperforms few-shot prompting methods. The paper has practical applicability in enhancing the reliability of LLM-generated content.

Title: [ChatGPT is all you need to decolonize sub-Saharan Vocational Education](http://arxiv.org/pdf/2304.13728v1)     
Summary: This paper argues for the use of Large Language Models in vocational and technical training to modernize educational systems in sub-Saharan African countries. The authors propose an educational policy framework to prioritize vocational education over academic education. Additionally, they provide historical examples of countries successfully implementing such policies, highlighting the potential for socioeconomic transformation.

Title: [Extracting Structured Seed-Mediated Gold Nanorod Growth Procedures from Literature with GPT-3](http://arxiv.org/pdf/2304.13846v1)     
Summary: This paper presents an approach using the GPT-3 language model to extract structured multi-step seed-mediated growth procedures and outcomes for gold nanorods from unstructured scientific literature text with an accuracy of 86%. By developing a tool to extract relevant structured data in an automated, high-throughput manner, the authors aim to better understand the pathways for controlling the shape and optical properties of gold nanorods.

Title: [Text-to-Audio Generation using Instruction-Tuned LLM and Latent Diffusion Model](http://arxiv.org/pdf/2304.13731v1)     
Summary: The paper presents a novel approach, TANGO, for text-to-audio (TTA) generation, utilizing an instruction-tuned LLM as the text encoder and a latent diffusion model (LDM) for audio generation. The proposed method outperforms the state-of-the-art AudioLDM and stays comparable on most metrics on the AudioCaps test set, despite being trained on a smaller dataset and keeping the text encoder frozen. The improvement in performance may also be attributed to the adoption of audio pressure level-based sound mixing for training set augmentation.

</details>
<details>
<summary>Image Reconstruction</summary>
    
Title: [A Probabilistic Attention Model with Occlusion-aware Texture Regression for 3D Hand Reconstruction from a Single RGB Image](http://arxiv.org/pdf/2304.14299v1)     
Summary: 
This paper proposes a novel probabilistic model for 3D hand reconstruction from a single RGB image. The model-based network estimates the prior probability distribution of joints and vertices, while the Attention-based Mesh Vertices Uncertainty Regression (AMVUR) model captures dependencies among vertices and correlation between joints and vertices. An occlusion-aware Hand Texture Regression model is also proposed for high-fidelity texture reconstruction. The proposed model achieves state-of-the-art accuracy in 3D hand and texture reconstruction from a single image in both supervised and weakly-supervised scenarios.

Title: [Contour Completion by Transformers and Its Application to Vector Font Data](http://arxiv.org/pdf/2304.13988v1)     
Summary: The paper proposes a Transformer-based method to solve the contour completion task where the missing points in a contour sequence need to be generated to complete the contour. The paper applies this method to vector font data and shows the results of typeface contour completion.

Title: [Optimization-Inspired Cross-Attention Transformer for Compressive Sensing](http://arxiv.org/pdf/2304.13986v1)     
Summary: The paper proposes an Optimization-inspired Cross-attention Transformer (OCT) module for compressive sensing (CS) in image reconstruction. The OCT is designed as an iterative process that improves visual quality with fewer parameters and reduces feature information loss. The OCT is integrated with a lightweight OCT-based Unfolding Framework (OCTUF) that achieves superior performance in CS compared to other methods while training lower complexity. The paper highlights a novel Dual Cross Attention sub-module that introduces multi-channel inertia forces and increases memory effect by a cross attention mechanism between adjacent iterations.

Title: [MIPI 2023 Challenge on RGB+ToF Depth Completion: Methods and Results](http://arxiv.org/pdf/2304.13916v1)     
Summary: This paper presents the results of an RGB+sparse ToF depth completion competition aimed at encouraging research in depth completion from RGB images and sparse ToF measurements. The paper discusses the strengths and weaknesses of the top-performing methods and their implications for future research in this area. The competition provided a standardized dataset and evaluation metrics to compare the accuracy of different approaches.

Title: [Do SSL Models Have D√©j√† Vu? A Case of Unintended Memorization in Self-supervised Learning](http://arxiv.org/pdf/2304.13850v1)     
Summary: The paper investigates the unintended memorization of SSL models, which can lead to the reconstruction of visual elements from a single image. The authors show that this phenomenon, referred to as "d√©j√† vu memorization," is common to different SSL algorithms and cannot be detected by conventional evaluation techniques. This reveals previously unknown privacy risks in SSL models and suggests potential mitigation strategies.

Title: [A Majorization-Minimization Gauss-Newton Method for 1-Bit Matrix Completion](http://arxiv.org/pdf/2304.13940v1)     
Summary: This paper proposes a novel method for 1-bit matrix completion using the majorization-minimization principle and Gauss-Newton method. The proposed method is compared to existing methods and is shown to output more accurate estimates, often faster, and less sensitive to the spikiness of the underlying matrix.

Title: [Automated Whole Slide Imaging for Label-Free Histology using Photon Absorption Remote Sensing Microscopy](http://arxiv.org/pdf/2304.13736v1)     
Summary: The paper proposes an automated whole slide imaging platform using Photon Absorption Remote Sensing microscopy for label-free histology. The system provides high-quality and high-resolution images of unstained tissue samples, while preserving the samples for other staining techniques. The study demonstrates the potential of this approach in label-free H&E emulation as well.

</details>
<details>
<summary>Medical Image</summary>
    
Title: [Learning Absorption Rates in Glucose-Insulin Dynamics from Meal Covariates](http://arxiv.org/pdf/2304.14300v1)     
Summary: The paper proposes a neural network approach to learn absorption rates in glucose-insulin dynamics from meal covariates. The approach is based on predicting an individual's glucose absorption rate using a neural network, which is then used as a control function in a differential equation of glucose dynamics, allowing for end-to-end training. The method is able to accurately approximate true absorption rates on simulated data, which can pave the way for personalized glucose dynamics models for individuals.

Title: [Deep Imitation Learning for Automated Drop-In Gamma Probe Manipulation](http://arxiv.org/pdf/2304.14294v1)     
Summary: This paper proposes the use of deep imitation learning to create an end-to-end vision-based gamma probe manipulation agent for automated radioactive node detection during sentinel lymph node biopsy. The proposed approach uses simulation data to train the agent, and evaluation results showed promising results for further improvement and extension to hardware setup.

Title: [Towards Medical Artificial General Intelligence via Knowledge-Enhanced Multimodal Pretraining](http://arxiv.org/pdf/2304.14204v1)     
Summary: This paper proposes a new paradigm called Medical-knOwledge-enhanced mulTimOdal pretRaining (MOTOR) for achieving Medical Artificial General Intelligence (MAGI) via knowledge-enhanced multimodal pretraining. The proposed method combines general and specific medical knowledge to boost the general pretraining process and learns compact representations from pretraining radiographic data for better cross-modal alignment. The method unifies the understanding and generation of medical tasks and constructs a comprehensive medical multimodal benchmark including tasks such as chest x-ray report generation and medical VQA. Experimental results on the benchmark demonstrate promising performance with excellent interpretability. Thus, this work makes a significant stride towards realizing MAGI.

Title: [Design of a multimodal device to improve well-being of autistic workers interacting with collaborative robots](http://arxiv.org/pdf/2304.14191v1)     
Summary: The paper describes the design and development of (A)MICO, a multimodal device aimed to improve the user experience of ASD workers interacting with collaborative robots in production lines. The device proposes a new intuitive mode of communication in which information about the cobot activity is transferred through acoustic and visual feedback. The design process involves a co-design process with users with high functioning autism to analyze the system from different perspectives, and Design for All principles were taken into consideration to develop a human-friendly device.

Title: [COSST: Multi-organ Segmentation with Partially Labeled Datasets Using Comprehensive Supervisions and Self-training](http://arxiv.org/pdf/2304.14030v1)     
Summary: This paper proposes a novel approach, called COSST, for multi-organ segmentation using partially labeled medical image datasets. The approach integrates three supervision signals, including pseudo-labels obtained via self-training, to achieve improved segmentation performance. The proposed method outperforms state-of-the-art partial-label segmentation methods on various segmentation tasks with different training data sizes.

Title: [Mimic-IV-ICD: A new benchmark for eXtreme MultiLabel Classification](http://arxiv.org/pdf/2304.13998v1)     
Summary: In this paper, the authors propose a public benchmark suite for ICD-10 and ICD-9 coding using a large EHR dataset derived from MIMIC-IV. They implement and compare several popular methods for ICD coding prediction tasks to standardize data preprocessing and establish a comprehensive ICD coding benchmark dataset. This approach fosters reproducibility and model comparison, accelerating progress toward employing automated ICD coding in future studies. Furthermore, they provide open-source code that offers easy access to data processing steps, benchmark creation, and experiment replication for those with MIMIC-IV access.

Title: [SkinSAM: Empowering Skin Cancer Segmentation with Segment Anything Model](http://arxiv.org/pdf/2304.13973v1)     
Summary: The paper presents SkinSAM, a fine-tuned model based on the Segment Anything Model for skin cancer segmentation on HAM10000 dataset. The model exhibited outstanding segmentation performance, with the finetuned model showing the greatest improvement. The research demonstrates the potential of adapting SAM to medical image segmentation tasks.

Title: [GazeSAM: What You See is What You Segment](http://arxiv.org/pdf/2304.13844v1)     
Summary: The paper proposes a collaborative human-computer interaction system called GazeSAM that utilizes eye-tracking technology and the Segment Anything Model (SAM) to automate medical image segmentation. The system enables radiologists to collect segmentation masks simply by looking at the region of interest during image diagnosis. GazeSAM tracks radiologists' eye movement and utilizes the eye-gaze data as the input prompt for SAM, which generates the segmentation mask in real-time. This study is the first work to leverage the power of eye-tracking technology and SAM to enhance the efficiency of daily clinical practice.

Title: [Customized Segment Anything Model for Medical Image Segmentation](http://arxiv.org/pdf/2304.13785v1)     
Summary: The paper proposes SAMed, a model for medical image segmentation built upon the Segment Anything Model. It applies the low-rank-based finetuning strategy and the AdamW optimizer to achieve successful convergence and lower loss. SAMed achieved competitive results on the Synapse multi-organ segmentation dataset with marginal deployment and storage costs. The paper introduces a new paradigm of customizing large-scale models for medical image segmentation.

Title: [Temporal and geographic analysis of the Hydroxychloroquine controversy in the French Twittosphere](http://arxiv.org/pdf/2304.14075v1)     
Summary: The paper discusses the controversies surrounding the use of Hydroxychloroquine as a treatment for COVID-19 and its spread on the French-speaking Twitter sphere. The study analyzes the geographic dimension of the debate, information flow, and Twitter's retweet hypergraph. Tensor decomposition of hashtag use concludes that the debates are linked to local political choices. The study finds its center in Europe, particularly France, while francophone Africa has a lower participation in the debates due to early acceptance of Hydroxychloroquine and rejection of WHO recommendations.

Title: [Automatically Segment the Left Atrium and Scars from LGE-MRIs Using a Boundary-focused nnU-Net](http://arxiv.org/pdf/2304.14071v1)     
Summary: The paper proposes an automated method for segmenting the left atrial cavity and scars in late gadolinium enhancement magnetic resonance imaging (LGE-MRI) scans. The approach uses nnU-Net as the baseline model and employs a boundary-focused loss function to improve boundary prediction accuracy. In addition, a distance map transformation of the predicted LA boundary is used to predict scar locations. The method achieves superior results on the LAScarQS 2022 dataset, with 88.98% and 64.08% Dice coefficient for LA cavity and scar segmentation, respectively.

Title: [Precise Few-shot Fat-free Thigh Muscle Segmentation in T1-weighted MRI](http://arxiv.org/pdf/2304.14053v1)     
Summary: This paper proposes a few-shot segmentation framework for precise thigh muscle segmentation in T1-weighted MRI images, excluding intra-muscular fat (IMF). The framework uses a novel pseudo-label correction and evaluation scheme, together with a noise robust loss to exploit high certainty areas. With only 1% of fine-annotated training data, the proposed method achieves comparable performance with fully supervised methods.

Title: [A Deep Registration Method for Accurate Quantification of Joint Space Narrowing Progression in Rheumatoid Arthritis](http://arxiv.org/pdf/2304.13938v1)     
Summary: This paper proposes a deep intra-subject rigid registration network to automatically quantify joint space narrowing progression in rheumatoid arthritis through image registration in radiographic images. The proposed method offers sub-pixel level accuracy and is equipped with immune to noise, rotation, and scaling of joints. The method provides loss visualization, aiding radiologists and rheumatologists to assess quantification reliability, with implications for future clinical applications.

Title: [Automated Classification of Stroke Blood Clot Origin using Whole-Slide Digital Pathology Images](http://arxiv.org/pdf/2304.13775v1)     
Summary: The paper presents a novel methodology to classify the origin of blood clots in ischemic stroke patients using whole-slide digital pathology images. The approach integrates data from multiple cutting-edge computer vision models and achieves an accuracy of 94.24% with the SwinTransformerV2 model outperforming all others. The proposed method offers a promising solution for improved diagnosis and management of ischemic stroke.

Title: [Phagocytosis Unveiled: A Scalable and Interpretable Deep learning Framework for Neurodegenerative Disease Analysis](http://arxiv.org/pdf/2304.13764v1)     
Summary: The paper presents a scalable and interpretable deep learning framework for analyzing phagocytic activity in neurodegenerative diseases. The pipeline includes a data quality verification module and an explainable cell segmentation module for improved interpretability. The framework is applied to analyze microglial cell phagocytosis in frontotemporal dementia, and the authors release an open-source pipeline and dataset for future research.

Title: [AIRIVA: A Deep Generative Model of Adaptive Immune Repertoires](http://arxiv.org/pdf/2304.13737v1)     
Summary: The paper presents a generative model called AIRIVA, which learns a low-dimensional, interpretable, and compositional representation of TCR repertoires from immune system data to disentangle systematic effects in repertoires. The model is applied to two infectious disease case-studies, COVID-19 and the Herpes Simplex Virus (HSV), and shows promising results in identifying disease-specific TCRs.

Title: [Automated Whole Slide Imaging for Label-Free Histology using Photon Absorption Remote Sensing Microscopy](http://arxiv.org/pdf/2304.13736v1)     
Summary: The paper proposes an automated whole slide imaging platform using Photon Absorption Remote Sensing microscopy for label-free histology. The system provides high-quality and high-resolution images of unstained tissue samples, while preserving the samples for other staining techniques. The study demonstrates the potential of this approach in label-free H&E emulation as well.

Title: [Ensemble CNNs for Breast Tumor Classification](http://arxiv.org/pdf/2304.13727v1)     
Summary: The paper presents an ensemble mechanism using state-of-the-art classification networks (XceptionNet, DenseNet, EfficientNet) for breast tumor classification among mammographic images. The proposed approach achieved an accuracy of 88% with a 5% improvement over individual models.

Title: [Prediction of brain tumor recurrence location based on multi-modal fusion and nonlinear correlation learning](http://arxiv.org/pdf/2304.13725v1)     
Summary: This paper proposes a deep learning-based brain tumor recurrence location prediction network that segments present brain tumor and predicts its future recurrence location. The method uses transfer learning, multi-modal fusion, and nonlinear correlation learning to extract effective features. The proposed method is effective in predicting brain tumor recurrence location from limited datasets.

</details>
<details>
<summary>Image Classification</summary>
    
Title: [Vision Conformer: Incorporating Convolutions into Vision Transformer Layers](http://arxiv.org/pdf/2304.13991v1)     
Summary: This paper proposes a new model called Vision Conformer (ViC) which incorporates convolutional layers within Vision Transformer (ViT) in order to address the lack of inductive bias towards image structures. ViC replaces the Multi-Layer Perceptron (MLP) in a ViT layer with a CNN and reconstructs the image data after self-attention using a reverse embedding layer. The paper demonstrates through evaluation that the use of convolutional layers improves the classification ability of ViT.

Title: [Human-machine knowledge hybrid augmentation method for surface defect detection based few-data learning](http://arxiv.org/pdf/2304.13963v1)     
Summary: The paper proposes a human-machine knowledge hybrid augmentation method for surface defect detection based on few-data learning. The proposed method utilizes experts' knowledge of abnormality to create data with rich features, positions, sizes, and backgrounds, which can be used as prior knowledge for the model. The method was evaluated on the magnetic tile dataset and achieved better results than the traditional augmentation method, demonstrating its feasibility and effectiveness in few-data industrial defect detection.

Title: [UCF: Uncovering Common Features for Generalizable Deepfake Detection](http://arxiv.org/pdf/2304.13949v1)     
Summary: The paper proposes a disentanglement framework that uncovers common forgery features to address the overfitting issue in deepfake detection. It employs a multi-task learning strategy and contrastive regularization technique to encourage the disentanglement of specific and common forgery features. The proposed framework outperforms current state-of-the-art methods in generalizable deepfake detection.

Title: [CNN based IoT Device Identification](http://arxiv.org/pdf/2304.13894v1)     
Summary: The paper proposes a CNN-based IoT device identification method to detect vulnerabilities in IoT devices. The study uses the Aalto dataset to identify and classify these devices based on the features obtained from the images. This paper falls under the category of Image Classification and CNNs.

Title: [Deep Learning Techniques for Hyperspectral Image Analysis in Agriculture: A Review](http://arxiv.org/pdf/2304.13880v1)     
Summary: This academic paper focuses on the use of deep learning techniques in analyzing hyperspectral images in agriculture. The paper discusses the high redundancy of spectral bands and limited training samples that make the classification of HSI a complex task. The authors review and evaluate the performance of various deep learning approaches, such as Autoencoders, Convolutional Neural Networks, Recurrent Neural Networks, and Generative Adversarial Networks, on well-known land cover datasets. The paper concludes that deep learning techniques show promising results in HSI analysis, especially in agriculture.

Title: [Categorising Products in an Online Marketplace: An Ensemble Approach](http://arxiv.org/pdf/2304.13852v1)     
Summary: This paper proposes an ensemble approach for categorizing products in an online marketplace using a combination of XGBoost and k-nearest neighbours models. The approach separately predicts categories, subcategories, and colors for each product and combines the results for an F1-score of 0.82.

Title: [Distance Weighted Supervised Learning for Offline Interaction Data](http://arxiv.org/pdf/2304.13774v1)     
Summary: The paper introduces a new supervised learning method called Distance Weighted Supervised Learning (DWSL) for learning goal-conditioned policies from offline data. DWSL models the distribution of time-steps between states in data to approximate shortest path distances and extract policies. The method bridges the gap between imitation learning and offline goal-conditioned reinforcement learning. The paper shows that DWSL outperforms prior goal-conditioned imitation learning and reinforcement learning algorithms in high-dimensional image domains. The code and visualizations are available at the provided link.

Title: [Automated Classification of Stroke Blood Clot Origin using Whole-Slide Digital Pathology Images](http://arxiv.org/pdf/2304.13775v1)     
Summary: The paper presents a novel methodology to classify the origin of blood clots in ischemic stroke patients using whole-slide digital pathology images. The approach integrates data from multiple cutting-edge computer vision models and achieves an accuracy of 94.24% with the SwinTransformerV2 model outperforming all others. The proposed method offers a promising solution for improved diagnosis and management of ischemic stroke.

Title: [Ensemble CNNs for Breast Tumor Classification](http://arxiv.org/pdf/2304.13727v1)     
Summary: The paper presents an ensemble mechanism using state-of-the-art classification networks (XceptionNet, DenseNet, EfficientNet) for breast tumor classification among mammographic images. The proposed approach achieved an accuracy of 88% with a 5% improvement over individual models.

</details>
<details>
<summary>Image Registration</summary>
    
Title: [A Deep Registration Method for Accurate Quantification of Joint Space Narrowing Progression in Rheumatoid Arthritis](http://arxiv.org/pdf/2304.13938v1)     
Summary: This paper proposes a deep intra-subject rigid registration network to automatically quantify joint space narrowing progression in rheumatoid arthritis through image registration in radiographic images. The proposed method offers sub-pixel level accuracy and is equipped with immune to noise, rotation, and scaling of joints. The method provides loss visualization, aiding radiologists and rheumatologists to assess quantification reliability, with implications for future clinical applications.

</details>
<details>
<summary>Reinforcement learning</summary>
    
Title: [SMAT: A Self-Reinforcing Framework for Simultaneous Mapping and Tracking in Unbounded Urban Environments](http://arxiv.org/pdf/2304.14356v1)     
Summary: The paper introduces the SMAT (Simultaneous Mapping and Tracking) framework for robots to construct a reliable map online and navigate in unbounded and changing environments. The framework integrates dynamic object detection and tracking with static mapping using a self-reinforcing mechanism, promoting mutual improvement of mapping and tracking performance. The experiments demonstrate the framework's effectiveness in real-world applications, achieving successful long-range navigation and mapping in urban environments using LiDAR, CPU-only onboard computer, and GPS.

Title: [A Best-of-Both-Worlds Algorithm for Constrained MDPs with Long-Term Constraints](http://arxiv.org/pdf/2304.14326v1)     
Summary: The paper presents a best-of-both-worlds algorithm for constrained Markov decision processes with long-term constraints, where the learner aims to maximize reward while satisfying the constraints during the learning process. The proposed algorithm can handle scenarios where rewards and constraints are selected stochastically or adversarially, without requiring knowledge of the underlying process. The algorithm achieves state-of-the-art regret and constraint violation bounds for settings where constraints are stochastic and provides guarantees for the first time in scenarios where they are adversarial.

Title: [Preference Inference from Demonstration in Multi-objective Multi-agent Decision Making](http://arxiv.org/pdf/2304.14126v1)     
Summary: The paper proposes an algorithm for inferring linear preference weights in multi-objective decision-making problems using optimal or near-optimal demonstrations. The algorithm is evaluated in three environments and compared to two baseline methods, showing significant improvements in time requirements and accuracy of the inferred preferences. The authors plan to evaluate the algorithm in a multi-agent system.

Title: [Inferring Preferences from Demonstrations in Multi-objective Reinforcement Learning: A Dynamic Weight-based Approach](http://arxiv.org/pdf/2304.14115v1)     
Summary: This paper proposes a Dynamic Weight-based Preference Inference (DWPI) algorithm that can infer the preferences of agents acting in multi-objective decision-making problems based on observed behavior trajectories in the environment. The proposed method shows significant improvement compared to two existing preference inference methods in terms of both time requirements and accuracy of inferred preferences, and maintains its performance when inferring preferences for sub-optimal behavior demonstrations.

Title: [SocNavGym: A Reinforcement Learning Gym for Social Navigation](http://arxiv.org/pdf/2304.14102v1)     
Summary: The paper introduces SocNavGym, a simulation environment for social navigation that enables the development of intelligent social agents using reinforcement learning algorithms. The environment can generate a wide range of social navigation scenarios and can be configured to work with different hand-crafted and data-driven social reward signals. The paper also includes a case study where a Dueling-DQN agent is trained to learn social-navigation policies using SocNavGym, and the results show improved social compliance compared to a heuristic-based reward function.

Title: [A Distributed Online Optimization Strategy for Cooperative Robotic Surveillance](http://arxiv.org/pdf/2304.14016v1)     
Summary: This paper proposes a distributed algorithm for controlling a team of cooperating robots to protect a target from intruders. The algorithm utilizes an online optimization problem within a distributed aggregative framework. The defending robots determine their positions based on the relative position between the intruders and the target, their contribution to the team barycenter, and collisions with other robots. The effectiveness of the algorithm is validated through simulations and experiments on a team of cooperating quadrotors.

Title: [Level Assembly as a Markov Decision Process](http://arxiv.org/pdf/2304.13922v1)     
Summary: The paper presents an approach to generate levels for players in games by formulating the problem as a Markov Decision Process (MDP) and using adaptive dynamic programming (ADP) to solve the MDP before assembling a level. The approach adapts to the player's performance and preferences and was tested with two case studies, outperforming two baselines. The paper also experiments with player proxies and shows that a simple modification prior to running ADP results in quick adaptation. By using ADP, the approach produces a dynamic progression of levels that adapts to the player.

Title: [Decision Making for Autonomous Vehicles](http://arxiv.org/pdf/2304.13908v1)     
Summary: This academic paper focuses on decision making for autonomous vehicles in roundabouts using reinforcement learning. The paper introduces different decision-making models such as Markov Decision Processes (MDP), Partially Observable Markov Decision Processes (POMDP), Object Oriented Partially Observable Markov Decision Process (OOPOMDP), and the Partially Observable Monte-Carlo Planning algorithm (POMCP). The paper formulates the decision-making problem as a POMDP and presents a penalty function, policy prediction, and augmented objective state to improve decision-making. Simulations are used to demonstrate the effectiveness of the proposed method.

Title: [Discovering Object-Centric Generalized Value Functions From Pixels](http://arxiv.org/pdf/2304.13892v1)     
Summary: The paper introduces a method for discovering object-centric generalized value functions from pixels using deep reinforcement learning. The approach translates meaningful object features to temporally coherent "question" functions and leverages the subsequent learned general value functions for control. The paper compares the approach with state-of-the-art techniques and shows competitive performance in both stationary and non-stationary settings. Through qualitative analysis, the paper shows that the learned representations are interpretable and centered around objects that are invariant to changes across tasks, facilitating fast adaptation.

Title: [Surrogate Assisted Generation of Human-Robot Interaction Scenarios](http://arxiv.org/pdf/2304.13787v1)     
Summary: This paper proposes a method for generating diverse scenarios for evaluating human-robot interaction systems by augmenting scenario generation with surrogate models that can predict both human and robot behaviors, thus efficiently synthesizing challenging scenarios without simulating robot policies and human actions. The proposed method is demonstrated in shared control teleoperation and shared workspace collaboration tasks, with reproducible failures in real-world interactions.

Title: [Distance Weighted Supervised Learning for Offline Interaction Data](http://arxiv.org/pdf/2304.13774v1)     
Summary: The paper introduces a new supervised learning method called Distance Weighted Supervised Learning (DWSL) for learning goal-conditioned policies from offline data. DWSL models the distribution of time-steps between states in data to approximate shortest path distances and extract policies. The method bridges the gap between imitation learning and offline goal-conditioned reinforcement learning. The paper shows that DWSL outperforms prior goal-conditioned imitation learning and reinforcement learning algorithms in high-dimensional image domains. The code and visualizations are available at the provided link.

Title: [Exploring the flavor structure of quarks and leptons with reinforcement learning](http://arxiv.org/pdf/2304.14176v1)     
Summary: The paper proposes a method to use reinforcement learning to explore the flavor structure of quarks and leptons based on a policy-based algorithm for models with $U(1)$ symmetry. The agent trained on the $U(1)$ charges of quarks and leptons identifies 21 models consistent with experimentally measured masses and mixing angles. The paper predicts specific values of effective mass for neutrinoless double beta decay and leptonic CP violation through an autonomous behavior of the agent.

Title: [Adaptation to Misspecified Kernel Regularity in Kernelised Bandits](http://arxiv.org/pdf/2304.13830v1)     
Summary: The paper titled "Adaptation to Misspecified Kernel Regularity in Kernelised Bandits" discusses the adaptivity of learning algorithms to the regularity of associated kernel functions in continuum-armed bandit problems. The paper derives an adaptivity lower bound and connects the statistical difficulty for adaptivity in three fundamental types of function spaces: RKHS, Sobolev space, and H\"older space. This paper falls under the categories of Reinforcement learning and Theory.

</details>
<details>
<summary>Image Segmentation</summary>
    
Title: [Analogy-Forming Transformers for Few-Shot 3D Parsing](http://arxiv.org/pdf/2304.14382v1)     
Summary: The paper presents a model called Analogical Networks that can segment 3D object scenes using few-shot learning. The model retrieves related scenes from memory and predicts analogous part structures for the input scene, conditioning on the appropriate set of memories. Analogical Networks outperforms state-of-the-art 3D segmentation transformers in few-shot settings and successfully segments instances of novel object categories by expanding its memory.

Title: [Zero-shot Unsupervised Transfer Instance Segmentation](http://arxiv.org/pdf/2304.14376v1)     
Summary: The paper introduces a framework called Zero-shot Unsupervised Transfer Instance Segmentation (ZUTIS) that can perform instance and semantic segmentations without requiring instance-level or pixel-level annotations. The model can also perform zero-shot transfer without assuming access to a target data distribution. The proposed framework achieves state-of-the-art performance on both instance and semantic segmentation tasks compared to previous unsupervised methods.

Title: [Instance Segmentation in the Dark](http://arxiv.org/pdf/2304.14298v1)     
Summary: This paper focuses on improving instance segmentation in low-light conditions. The proposed method includes an adaptive weighted downsampling layer, convolutional block, and disturbance suppression learning to reduce feature noise and improve image quality. Additionally, the use of high-bit-depth RAW images is explored for better preservation of scene information. A low-light RAW synthetic pipeline is used to generate realistic data for training, and a real-world low-light instance segmentation dataset is captured for further research. The proposed method achieves higher accuracy than state-of-the-art competitors in very low light conditions.

Title: [EDAPS: Enhanced Domain-Adaptive Panoptic Segmentation](http://arxiv.org/pdf/2304.14291v1)     
Summary: The paper proposes EDAPS, a novel architecture for domain-adaptive panoptic segmentation. EDAPS uses a shared, domain-robust transformer encoder, and task-specific decoders tailored for both domain-adaptive semantic and instance segmentation. The implementation of EDAPS improves the state-of-the-art performance for panoptic segmentation UDA by a large margin on challenging benchmarks. The paper falls under the categories of Image Segmentation and Domain Generalization/Adaptation.

Title: [Human Semantic Segmentation using Millimeter-Wave Radar Sparse Point Clouds](http://arxiv.org/pdf/2304.14132v1)     
Summary: The paper proposes a framework for human semantic segmentation on sparse millimeter-wave radar point clouds using graph structure and topological features. The framework includes a global and sequential feature-extracting module, an efficient loss function for better training and segmentation results, and achieves state-of-the-art performance on both custom and benchmark datasets. The paper falls under the categories of point cloud, image segmentation, graph neural networks, and transformer.

Title: [COSST: Multi-organ Segmentation with Partially Labeled Datasets Using Comprehensive Supervisions and Self-training](http://arxiv.org/pdf/2304.14030v1)     
Summary: This paper proposes a novel approach, called COSST, for multi-organ segmentation using partially labeled medical image datasets. The approach integrates three supervision signals, including pseudo-labels obtained via self-training, to achieve improved segmentation performance. The proposed method outperforms state-of-the-art partial-label segmentation methods on various segmentation tasks with different training data sizes.

Title: [A Review of Panoptic Segmentation for Mobile Mapping Point Clouds](http://arxiv.org/pdf/2304.13980v1)     
Summary: The paper reviews the state of panoptic segmentation of outdoor mobile-mapping data, which is the combined task of assigning semantic classes and separating them into object instances. The paper sets up a modular pipeline for comprehensive experiments and provides the first public dataset for the task, extending NPM3D dataset to include instance labels.

Title: [Adaptive-Mask Fusion Network for Segmentation of Drivable Road and Negative Obstacle With Untrustworthy Features](http://arxiv.org/pdf/2304.13979v1)     
Summary: The paper proposes an Adaptive-Mask Fusion Network for segmentation of drivable road and negative obstacles with untrustworthy features. The proposed network uses adaptive-weight masks to fuse features from RGB and depth images with inconsistency to overcome the issue caused by untrustworthy features. The authors also release a large-scale RGB-depth dataset with manually-labeled ground truth for drivable roads and negative obstacles segmentation. The proposed network achieves state-of-the-art performance compared to other networks.

Title: [SkinSAM: Empowering Skin Cancer Segmentation with Segment Anything Model](http://arxiv.org/pdf/2304.13973v1)     
Summary: The paper presents SkinSAM, a fine-tuned model based on the Segment Anything Model for skin cancer segmentation on HAM10000 dataset. The model exhibited outstanding segmentation performance, with the finetuned model showing the greatest improvement. The research demonstrates the potential of adapting SAM to medical image segmentation tasks.

Title: [GazeSAM: What You See is What You Segment](http://arxiv.org/pdf/2304.13844v1)     
Summary: The paper proposes a collaborative human-computer interaction system called GazeSAM that utilizes eye-tracking technology and the Segment Anything Model (SAM) to automate medical image segmentation. The system enables radiologists to collect segmentation masks simply by looking at the region of interest during image diagnosis. GazeSAM tracks radiologists' eye movement and utilizes the eye-gaze data as the input prompt for SAM, which generates the segmentation mask in real-time. This study is the first work to leverage the power of eye-tracking technology and SAM to enhance the efficiency of daily clinical practice.

Title: [Customized Segment Anything Model for Medical Image Segmentation](http://arxiv.org/pdf/2304.13785v1)     
Summary: The paper proposes SAMed, a model for medical image segmentation built upon the Segment Anything Model. It applies the low-rank-based finetuning strategy and the AdamW optimizer to achieve successful convergence and lower loss. SAMed achieved competitive results on the Synapse multi-organ segmentation dataset with marginal deployment and storage costs. The paper introduces a new paradigm of customizing large-scale models for medical image segmentation.

Title: [Automatically Segment the Left Atrium and Scars from LGE-MRIs Using a Boundary-focused nnU-Net](http://arxiv.org/pdf/2304.14071v1)     
Summary: The paper proposes an automated method for segmenting the left atrial cavity and scars in late gadolinium enhancement magnetic resonance imaging (LGE-MRI) scans. The approach uses nnU-Net as the baseline model and employs a boundary-focused loss function to improve boundary prediction accuracy. In addition, a distance map transformation of the predicted LA boundary is used to predict scar locations. The method achieves superior results on the LAScarQS 2022 dataset, with 88.98% and 64.08% Dice coefficient for LA cavity and scar segmentation, respectively.

Title: [Prediction of brain tumor recurrence location based on multi-modal fusion and nonlinear correlation learning](http://arxiv.org/pdf/2304.13725v1)     
Summary: This paper proposes a deep learning-based brain tumor recurrence location prediction network that segments present brain tumor and predicts its future recurrence location. The method uses transfer learning, multi-modal fusion, and nonlinear correlation learning to extract effective features. The proposed method is effective in predicting brain tumor recurrence location from limited datasets.

</details>
<details>
<summary>Object Detection</summary>
    
Title: [Learning Articulated Shape with Keypoint Pseudo-labels from Web Images](http://arxiv.org/pdf/2304.14396v1)     
Summary: The paper proposes an approach using as few as 50-150 images labeled with 2D keypoints to learn models for monocular 3D reconstruction of articulated objects. The approach involves training category-specific keypoint estimators, generating 2D keypoint pseudo-labels on unlabeled web images, and using both the labeled and self-labeled sets to train 3D reconstruction models. The results show that the approach can effectively utilize web images and improve 3D reconstruction performance for several articulated object categories beyond the fully-supervised baseline.

Title: [SMAT: A Self-Reinforcing Framework for Simultaneous Mapping and Tracking in Unbounded Urban Environments](http://arxiv.org/pdf/2304.14356v1)     
Summary: The paper introduces the SMAT (Simultaneous Mapping and Tracking) framework for robots to construct a reliable map online and navigate in unbounded and changing environments. The framework integrates dynamic object detection and tracking with static mapping using a self-reinforcing mechanism, promoting mutual improvement of mapping and tracking performance. The experiments demonstrate the framework's effectiveness in real-world applications, achieving successful long-range navigation and mapping in urban environments using LiDAR, CPU-only onboard computer, and GPS.

Title: [SparseFusion: Fusing Multi-Modal Sparse Representations for Multi-Sensor 3D Object Detection](http://arxiv.org/pdf/2304.14340v1)     
Summary: The paper proposes a novel multi-sensor 3D detection method called SparseFusion which exclusively uses sparse candidates and representations for efficient and accurate detections of objects in a scene. The proposed method utilizes the outputs of parallel detectors in the LiDAR and camera modalities as sparse candidates for fusion in a unified 3D space using a lightweight self-attention module. The paper achieves state-of-the-art performance on the nuScenes benchmark and is publicly available in GitHub.

Title: [Deep Imitation Learning for Automated Drop-In Gamma Probe Manipulation](http://arxiv.org/pdf/2304.14294v1)     
Summary: This paper proposes the use of deep imitation learning to create an end-to-end vision-based gamma probe manipulation agent for automated radioactive node detection during sentinel lymph node biopsy. The proposed approach uses simulation data to train the agent, and evaluation results showed promising results for further improvement and extension to hardware setup.

Title: [Towards Precise Weakly Supervised Object Detection via Interactive Contrastive Learning of Context Information](http://arxiv.org/pdf/2304.14114v1)     
Summary: This paper proposes a novel end-to-end weakly supervised object detection framework called JLWSOD, which utilizes two types of context information and an interactive graph contrastive learning mechanism to jointly optimize visual appearance and context information for better performance. The iGCL mechanism takes advantage of complementary interpretations of WSOD and forms a more comprehensive solution. Extensive experiments on benchmark datasets demonstrate JLWSOD's superior performance compared to state-of-the-art approaches and baseline models.

Title: [Automatic Localization and Detection Applicable to Robust Image Watermarking Resisting against Camera Shooting](http://arxiv.org/pdf/2304.13953v1)     
Summary: This paper proposes an automatic watermarking system that can resist camera shooting. The scheme deals with two important problems: automatic watermark localization (AWL) and automatic watermark detection (AWD). AWL automatically identifies the region of interest (RoI), which contains watermark information, in the camera-shooting image by analyzing the local statistical characteristics. Meanwhile, AWD extracts the hidden watermark from the identified RoI after applying perspective correction. Extensive experimental results demonstrate the superiority and applicability of the proposed approach.

</details>
<details>
<summary>Object Tracking</summary>
    
Title: [SeqTrack: Sequence to Sequence Learning for Visual Object Tracking](http://arxiv.org/pdf/2304.14394v1)     
Summary: The paper presents SeqTrack, a new sequence-to-sequence learning framework for visual object tracking. It uses a simple encoder-decoder transformer architecture to predict object bounding boxes in an autoregressive fashion instead of relying on complicated head networks. It achieves state-of-the-art performance on benchmarks like LaSOT, simplifying the tracking framework.

Title: [Co-SLAM: Joint Coordinate and Sparse Parametric Encodings for Neural Real-Time SLAM](http://arxiv.org/pdf/2304.14377v1)     
Summary: The paper presents Co-SLAM, a neural RGB-D SLAM system based on a hybrid representation that performs real-time camera tracking and high-fidelity surface reconstruction. Co-SLAM uses a multi-resolution hash-grid and one-blob encoding to enable fast convergence, surface hole filling, and surface coherence. It incorporates a ray sampling strategy that allows global bundle adjustment over all keyframes. Co-SLAM achieves state-of-the-art scene reconstruction results and competitive tracking performance in various datasets and benchmarks.

Title: [SMAT: A Self-Reinforcing Framework for Simultaneous Mapping and Tracking in Unbounded Urban Environments](http://arxiv.org/pdf/2304.14356v1)     
Summary: The paper introduces the SMAT (Simultaneous Mapping and Tracking) framework for robots to construct a reliable map online and navigate in unbounded and changing environments. The framework integrates dynamic object detection and tracking with static mapping using a self-reinforcing mechanism, promoting mutual improvement of mapping and tracking performance. The experiments demonstrate the framework's effectiveness in real-world applications, achieving successful long-range navigation and mapping in urban environments using LiDAR, CPU-only onboard computer, and GPS.

Title: [Direct Visual Servoing Based on Discrete Orthogonal Moments](http://arxiv.org/pdf/2304.14012v1)     
Summary: The paper proposes a new approach for Direct Visual Servoing (DVS) using discrete orthogonal moments (DOM), which helps in bypassing the feature-based visual servoing pipeline. The approach uses Tchebichef, Krawtchouk and Hahn moments as visual features and presents strategies for adaptive adjustment of parameters and orders of these features along with analytical formulation of associated interaction matrix. The proposed framework has been validated through simulations and real experiments, demonstrating its robustness and accuracy over state-of-the-art approaches.

</details>
<details>
<summary>Point Cloud</summary>
    
Title: [SMAT: A Self-Reinforcing Framework for Simultaneous Mapping and Tracking in Unbounded Urban Environments](http://arxiv.org/pdf/2304.14356v1)     
Summary: The paper introduces the SMAT (Simultaneous Mapping and Tracking) framework for robots to construct a reliable map online and navigate in unbounded and changing environments. The framework integrates dynamic object detection and tracking with static mapping using a self-reinforcing mechanism, promoting mutual improvement of mapping and tracking performance. The experiments demonstrate the framework's effectiveness in real-world applications, achieving successful long-range navigation and mapping in urban environments using LiDAR, CPU-only onboard computer, and GPS.

Title: [SparseFusion: Fusing Multi-Modal Sparse Representations for Multi-Sensor 3D Object Detection](http://arxiv.org/pdf/2304.14340v1)     
Summary: The paper proposes a novel multi-sensor 3D detection method called SparseFusion which exclusively uses sparse candidates and representations for efficient and accurate detections of objects in a scene. The proposed method utilizes the outputs of parallel detectors in the LiDAR and camera modalities as sparse candidates for fusion in a unified 3D space using a lightweight self-attention module. The paper achieves state-of-the-art performance on the nuScenes benchmark and is publicly available in GitHub.

Title: [Quadric Representations for LiDAR Odometry, Mapping and Localization](http://arxiv.org/pdf/2304.14190v1)     
Summary: The paper proposes a novel method for describing 3D scenes using quadric surfaces, which are more space-efficient representations than conventional point clouds. The method decomposes a scene into sparse quadric patches, fits each to a quadric implicit function, and describes each patch with additional geometric descriptors. The resulting quadric representations can be used in LiDAR odometry, mapping, and localization algorithms, and are shown to achieve competitive accuracy while maintaining low latency and memory usage.

Title: [ClusterNet: A Perception-Based Clustering Model for Scattered Data](http://arxiv.org/pdf/2304.14185v1)     
Summary: The paper proposes ClusterNet, a point-based deep learning model for cluster separation in scatterplots that is trained to reflect human perception of cluster separability. The authors crowdsourced a large-scale dataset of human annotations, used a PointNet++ architecture for inference on point clouds, and introduce a novel metric for measuring accuracy between clustering techniques and human annotators. The proposed approach is compared to existing state-of-the-art clustering techniques.

Title: [Human Semantic Segmentation using Millimeter-Wave Radar Sparse Point Clouds](http://arxiv.org/pdf/2304.14132v1)     
Summary: The paper proposes a framework for human semantic segmentation on sparse millimeter-wave radar point clouds using graph structure and topological features. The framework includes a global and sequential feature-extracting module, an efficient loss function for better training and segmentation results, and achieves state-of-the-art performance on both custom and benchmark datasets. The paper falls under the categories of point cloud, image segmentation, graph neural networks, and transformer.

Title: [Exploiting Inductive Bias in Transformer for Point Cloud Classification and Segmentation](http://arxiv.org/pdf/2304.14124v1)     
Summary: The paper presents a new Inductive Bias-aided Transformer (IBT) method for learning inter-point relations in point clouds. IBT considers both local and global attentions and incorporates the learned locality into the Transformer module to enhance self-attention mechanism with locality-based channel interaction. The paper demonstrates the superiority of the proposed method experimentally on classification and segmentation tasks.

Title: [RegHEC: Hand-Eye Calibration via Simultaneous Multi-view Point Clouds Registration of Arbitrary Object](http://arxiv.org/pdf/2304.14092v1)     
Summary: The paper presents a registration-based hand-eye calibration technique, RegHEC, that can calibrate the hand-eye relation without the need for an accurate calibration rig. The method uses multi-view point clouds of arbitrary scene and tries to bring them into simultaneous registration under a common reference frame. RegHEC is applicable for both eye-in-hand and eye-to-hand cases and has little requirement on calibration objects, making it suitable for most 3-D vision guided tasks. The technique is verified with extensive experiments using various arbitrary objects and a real hand-eye system. The paper presents an open-source C++ implementation of RegHEC.

Title: [A Review of Panoptic Segmentation for Mobile Mapping Point Clouds](http://arxiv.org/pdf/2304.13980v1)     
Summary: The paper reviews the state of panoptic segmentation of outdoor mobile-mapping data, which is the combined task of assigning semantic classes and separating them into object instances. The paper sets up a modular pipeline for comprehensive experiments and provides the first public dataset for the task, extending NPM3D dataset to include instance labels.

Title: [MIPI 2023 Challenge on RGB+ToF Depth Completion: Methods and Results](http://arxiv.org/pdf/2304.13916v1)     
Summary: This paper presents the results of an RGB+sparse ToF depth completion competition aimed at encouraging research in depth completion from RGB images and sparse ToF measurements. The paper discusses the strengths and weaknesses of the top-performing methods and their implications for future research in this area. The competition provided a standardized dataset and evaluation metrics to compare the accuracy of different approaches.

</details>
<details>
<summary>Neural Rendering</summary>
    
Title: [ActorsNeRF: Animatable Few-shot Human Rendering with Generalizable NeRFs](http://arxiv.org/pdf/2304.14401v1)     
Summary: The paper proposes a new animatable NeRF called ActorsNeRF that is pre-trained on diverse human subjects and adapts to new actors with few-shot video frames. ActorsNeRF uses two human priors to capture human appearance, shape, and pose variations and aligns humans in a category-level canonical space and instance-level canonical space for rendering. The proposed method outperforms existing state-of-the-art methods on few-shot generalization to new people and poses on multiple datasets.

Title: [Co-SLAM: Joint Coordinate and Sparse Parametric Encodings for Neural Real-Time SLAM](http://arxiv.org/pdf/2304.14377v1)     
Summary: The paper presents Co-SLAM, a neural RGB-D SLAM system based on a hybrid representation that performs real-time camera tracking and high-fidelity surface reconstruction. Co-SLAM uses a multi-resolution hash-grid and one-blob encoding to enable fast convergence, surface hole filling, and surface coherence. It incorporates a ray sampling strategy that allows global bundle adjustment over all keyframes. Co-SLAM achieves state-of-the-art scene reconstruction results and competitive tracking performance in various datasets and benchmarks.

Title: [Combining HoloLens with Instant-NeRFs: Advanced Real-Time 3D Mobile Mapping](http://arxiv.org/pdf/2304.14301v1)     
Summary: The paper presents a method of 3D reconstruction using a Microsoft HoloLens 2 as a multisensor platform that includes an RGB camera and an inertial measurement unit for SLAM-based camera-pose determination. The method utilizes a Neural Radiance Field (NeRF) as a neural scene representation in real-time with the acquired data from the HoloLens. The paper shows that the proposed method outperforms grid point sampling with NeRFs by multiple orders of magnitude and can be regarded as a complete real-time 3D reconstruction method in a mobile mapping setup.

Title: [Compositional 3D Human-Object Neural Animation](http://arxiv.org/pdf/2304.14070v1)     
Summary: This paper proposes a compositional approach for animating human-object interactions (HOIs) from a novel perspective by using neural human-object deformation to model and render HOI dynamics based on implicit neural representations. Additionally, the authors devise a new compositional conditional neural radiance field (CC-NeRF) to enable interaction pose transferring among different persons and objects to allow for compositionally animated control of novel HOIs. Their experiments show that this method can generalize well to various novel HOI animation settings.

Title: [ContraNeRF: 3D-Aware Generative Model via Contrastive Learning with Unsupervised Implicit Pose Embedding](http://arxiv.org/pdf/2304.14005v1)     
Summary: The paper proposes a novel 3D-aware GAN optimization technique, called ContraNeRF, that uses contrastive learning with implicit pose embeddings to capture complex 3D scene structures more effectively without relying on ground-truth camera poses. Experimental results show that ContraNeRF outperforms existing methods on datasets with multiple object categories and inconsistent camera poses.

</details>
<details>
<summary>Domain Generalization/Adaptation</summary>
    
Title: [ActorsNeRF: Animatable Few-shot Human Rendering with Generalizable NeRFs](http://arxiv.org/pdf/2304.14401v1)     
Summary: The paper proposes a new animatable NeRF called ActorsNeRF that is pre-trained on diverse human subjects and adapts to new actors with few-shot video frames. ActorsNeRF uses two human priors to capture human appearance, shape, and pose variations and aligns humans in a category-level canonical space and instance-level canonical space for rendering. The proposed method outperforms existing state-of-the-art methods on few-shot generalization to new people and poses on multiple datasets.

Title: [Maximizing Model Generalization for Manufacturing with Self-Supervised Learning and Federated Learning](http://arxiv.org/pdf/2304.14398v1)     
Summary: The paper proposes a method for maximizing model generalization for fault diagnosis in manufacturing using self-supervised learning and federated learning. The approach focuses on maximizing feature generality on the source domain and transferring the model to the target domain via weight transfer. Self-supervised learning with Barlow Twins produces more discriminative features, and federated learning expands the effective training data by sharing information across multiple machines. Results show that the proposed method outperforms traditional supervised learning and domain adaptation methods in an unlabeled target domain with emerging motor faults.

Title: [EDAPS: Enhanced Domain-Adaptive Panoptic Segmentation](http://arxiv.org/pdf/2304.14291v1)     
Summary: The paper proposes EDAPS, a novel architecture for domain-adaptive panoptic segmentation. EDAPS uses a shared, domain-robust transformer encoder, and task-specific decoders tailored for both domain-adaptive semantic and instance segmentation. The implementation of EDAPS improves the state-of-the-art performance for panoptic segmentation UDA by a large margin on challenging benchmarks. The paper falls under the categories of Image Segmentation and Domain Generalization/Adaptation.

Title: [ChatGPT vs State-of-the-Art Models: A Benchmarking Study in Keyphrase Generation Task](http://arxiv.org/pdf/2304.14177v1)     
Summary: This paper evaluates ChatGPT's keyphrase generation ability and compares its performance with state-of-the-art models on six publicly available datasets from scientific articles and news domains. The study finds that ChatGPT outperforms current state-of-the-art models in all tested datasets and environments, generating high-quality keyphrases that adapt well to diverse domains and document lengths.

Title: [Moderately Distributional Exploration for Domain Generalization](http://arxiv.org/pdf/2304.13976v1)     
Summary: This paper proposes a moderately distributional exploration (MODE) approach for domain generalization. It performs distribution exploration in a semantic subset of the uncertainty set to address low-confidence prediction issues. Experimental results show MODE achieves competitive performance compared to state-of-the-art baselines.

</details>
<details>
<summary>Few-Shot/Zero-Shot Learning</summary>
    
Title: [ActorsNeRF: Animatable Few-shot Human Rendering with Generalizable NeRFs](http://arxiv.org/pdf/2304.14401v1)     
Summary: The paper proposes a new animatable NeRF called ActorsNeRF that is pre-trained on diverse human subjects and adapts to new actors with few-shot video frames. ActorsNeRF uses two human priors to capture human appearance, shape, and pose variations and aligns humans in a category-level canonical space and instance-level canonical space for rendering. The proposed method outperforms existing state-of-the-art methods on few-shot generalization to new people and poses on multiple datasets.

Title: [Analogy-Forming Transformers for Few-Shot 3D Parsing](http://arxiv.org/pdf/2304.14382v1)     
Summary: The paper presents a model called Analogical Networks that can segment 3D object scenes using few-shot learning. The model retrieves related scenes from memory and predicts analogous part structures for the input scene, conditioning on the appropriate set of memories. Analogical Networks outperforms state-of-the-art 3D segmentation transformers in few-shot settings and successfully segments instances of novel object categories by expanding its memory.

Title: [ZeroShotDataAug: Generating and Augmenting Training Data with ChatGPT](http://arxiv.org/pdf/2304.14334v1)     
Summary: The paper proposes using ChatGPT, a large generative language model, to generate synthetic training data with task-specific prompts for augmenting data in low-resource scenarios. The augmented data generated from ChatGPT outperforms existing approaches for data augmentation. Additionally, the paper investigates methodologies for evaluating the quality of the data generated.

Title: [Adaptive manifold for imbalanced transductive few-shot learning](http://arxiv.org/pdf/2304.14281v1)     
Summary: The paper proposes a novel algorithm called Adaptive Manifold for imbalanced transductive few-shot learning. The method leverages the underlying manifold of labeled support examples and unlabeled queries by using manifold similarity to predict the class probability distribution per query. It outperforms other state-of-the-art methods on three benchmark datasets and three different backbones. The algorithm is parameterized by one centroid per class and a set of graph-specific parameters that determine the manifold. The parameters are optimized through a loss function that can be tuned towards class-balanced or imbalanced distributions.

Title: [Human-machine knowledge hybrid augmentation method for surface defect detection based few-data learning](http://arxiv.org/pdf/2304.13963v1)     
Summary: The paper proposes a human-machine knowledge hybrid augmentation method for surface defect detection based on few-data learning. The proposed method utilizes experts' knowledge of abnormality to create data with rich features, positions, sizes, and backgrounds, which can be used as prior knowledge for the model. The method was evaluated on the magnetic tile dataset and achieved better results than the traditional augmentation method, demonstrating its feasibility and effectiveness in few-data industrial defect detection.

Title: [Transferring Procedural Knowledge across Commonsense Tasks](http://arxiv.org/pdf/2304.13867v1)     
Summary: This paper proposes a framework called LEAP for transferring procedural knowledge across commonsense tasks in a transparent manner. The framework incorporates state-of-the-art modeling architectures, training regimes, and augmentation strategies based on both natural and synthetic stories. To address the lack of densely annotated training data, a robust automatic labeler based on few-shot prompting is devised for enhancing the augmented data. The experiments demonstrate insights into the interplay of different architectures, training regimes, and augmentation strategies. The LEAP's labeler positively impacts out-of-domain datasets, while the resulting dense annotation provides native explainability.

Title: [Is a prompt and a few samples all you need? Using GPT-4 for data augmentation in low-resource classification tasks](http://arxiv.org/pdf/2304.13861v1)     
Summary: The paper explores using GPT-4 and ChatGPT to augment small labeled datasets with synthetic data via simple prompts in low-resource classification tasks. They compare two augmentation strategies and find that synthetic data aids in identifying rare classes but human-annotated data exhibits a stronger predictive power in most cases. They also observe strong zero-shot performance across all tasks using GPT-4 and ChatGPT.

Title: [Translate to Disambiguate: Zero-shot Multilingual Word Sense Disambiguation with Pretrained Language Models](http://arxiv.org/pdf/2304.13803v1)     
Summary: The paper presents a study on how well Pretrained Language Models (PLMs) capture cross-lingual word sense knowledge with Contextual Word-Level Translation (C-WLT) and introduces a zero-shot approach for Word Sense Disambiguation (WSD) using PLMs. The study shows that as the model size increases, PLMs encode more cross-lingual word sense knowledge and better use context to improve WLT performance. The proposed zero-shot approach outperforms fully supervised baselines on recall for many evaluation languages without additional training or finetuning.

Title: [TR0N: Translator Networks for 0-Shot Plug-and-Play Conditional Generation](http://arxiv.org/pdf/2304.13742v1)     
Summary: The paper proposes a framework called TR0N, which can turn pre-trained unconditional generative models into conditional models without any training data. It learns a stochastic mapping between the space of conditions and the latent space of the generative model, enabling the generation of data samples satisfying the desired conditions. The proposed TR0N framework achieves zero-shot FID of 10.9 on MS-COCO and outperforms its competitors in terms of sampling speed and generality.

Title: [The Internal State of an LLM Knows When its Lying](http://arxiv.org/pdf/2304.13734v1)     
Summary: The paper proposes a method to detect the truthfulness of statements generated by Large Language Models (LLMs) using the LLM's internal state. They use the activation values in the hidden layer of LLM to determine if a statement is true or false. They compose a dataset of true and false statements and train a classifier that outperforms few-shot prompting methods. The paper has practical applicability in enhancing the reliability of LLM-generated content.

Title: [Precise Few-shot Fat-free Thigh Muscle Segmentation in T1-weighted MRI](http://arxiv.org/pdf/2304.14053v1)     
Summary: This paper proposes a few-shot segmentation framework for precise thigh muscle segmentation in T1-weighted MRI images, excluding intra-muscular fat (IMF). The framework uses a novel pseudo-label correction and evaluation scheme, together with a noise robust loss to exploit high certainty areas. With only 1% of fine-annotated training data, the proposed method achieves comparable performance with fully supervised methods.

</details>
<details>
<summary>Visual Question Answering(VQA)</summary>
    
</details>
<details>
<summary>Image-to-Image Translation</summary>
    
Title: [Automated Whole Slide Imaging for Label-Free Histology using Photon Absorption Remote Sensing Microscopy](http://arxiv.org/pdf/2304.13736v1)     
Summary: The paper proposes an automated whole slide imaging platform using Photon Absorption Remote Sensing microscopy for label-free histology. The system provides high-quality and high-resolution images of unstained tissue samples, while preserving the samples for other staining techniques. The study demonstrates the potential of this approach in label-free H&E emulation as well.

</details>
<details>
<summary>Transformer</summary>
    
Title: [IconShop: Text-Based Vector Icon Synthesis with Autoregressive Transformers](http://arxiv.org/pdf/2304.14400v1)     
Summary: The paper proposes IconShop, a text-guided vector icon synthesis method using an autoregressive transformer to sequence and tokenize SVG paths into a command sequence. The proposed method consistently exhibits better icon synthesis performance than existing methods in terms of quality, diversity, and speed. The paper also demonstrates the flexibility of IconShop with two novel icon manipulation tasks.

Title: [SeqTrack: Sequence to Sequence Learning for Visual Object Tracking](http://arxiv.org/pdf/2304.14394v1)     
Summary: The paper presents SeqTrack, a new sequence-to-sequence learning framework for visual object tracking. It uses a simple encoder-decoder transformer architecture to predict object bounding boxes in an autoregressive fashion instead of relying on complicated head networks. It achieves state-of-the-art performance on benchmarks like LaSOT, simplifying the tracking framework.

Title: [Analogy-Forming Transformers for Few-Shot 3D Parsing](http://arxiv.org/pdf/2304.14382v1)     
Summary: The paper presents a model called Analogical Networks that can segment 3D object scenes using few-shot learning. The model retrieves related scenes from memory and predicts analogous part structures for the input scene, conditioning on the appropriate set of memories. Analogical Networks outperforms state-of-the-art 3D segmentation transformers in few-shot settings and successfully segments instances of novel object categories by expanding its memory.

Title: [NAP at SemEval-2023 Task 3: Is Less Really More? (Back-)Translation as Data Augmentation Strategies for Detecting Persuasion Techniques](http://arxiv.org/pdf/2304.14179v1)     
Summary: The paper explores the use of (back-)translation as a data augmentation strategy for detecting persuasion techniques in news using multi-lingual transformer models. The results show that both data augmentation strategies boost performance, but balancing human-produced and machine-generated data is crucial.

Title: [ChatGPT vs State-of-the-Art Models: A Benchmarking Study in Keyphrase Generation Task](http://arxiv.org/pdf/2304.14177v1)     
Summary: This paper evaluates ChatGPT's keyphrase generation ability and compares its performance with state-of-the-art models on six publicly available datasets from scientific articles and news domains. The study finds that ChatGPT outperforms current state-of-the-art models in all tested datasets and environments, generating high-quality keyphrases that adapt well to diverse domains and document lengths.

Title: [Human Semantic Segmentation using Millimeter-Wave Radar Sparse Point Clouds](http://arxiv.org/pdf/2304.14132v1)     
Summary: The paper proposes a framework for human semantic segmentation on sparse millimeter-wave radar point clouds using graph structure and topological features. The framework includes a global and sequential feature-extracting module, an efficient loss function for better training and segmentation results, and achieves state-of-the-art performance on both custom and benchmark datasets. The paper falls under the categories of point cloud, image segmentation, graph neural networks, and transformer.

Title: [Exploiting Inductive Bias in Transformer for Point Cloud Classification and Segmentation](http://arxiv.org/pdf/2304.14124v1)     
Summary: The paper presents a new Inductive Bias-aided Transformer (IBT) method for learning inter-point relations in point clouds. IBT considers both local and global attentions and incorporates the learned locality into the Transformer module to enhance self-attention mechanism with locality-based channel interaction. The paper demonstrates the superiority of the proposed method experimentally on classification and segmentation tasks.

Title: [Deeply-Coupled Convolution-Transformer with Spatial-temporal Complementary Learning for Video-based Person Re-identification](http://arxiv.org/pdf/2304.14122v1)     
Summary: The paper proposes a novel spatial-temporal complementary learning framework for video-based person re-identification called Deeply-Coupled Convolution-Transformer (DCCT). The framework includes coupling CNNs and Transformers to extract visual features, Complementary Content Attention (CCA) to guide spatial learning, Hierarchical Temporal Aggregation (HTA) to capture inter-frame dependencies and gated attention to deliver aggregated temporal information for temporal learning. The proposed framework outperforms most state-of-the-art methods on public Re-ID benchmarks.

Title: [Lightweight, Pre-trained Transformers for Remote Sensing Timeseries](http://arxiv.org/pdf/2304.14065v1)     
Summary: The paper presents a pre-trained transformer-based model, Pretrained Remote Sensing Transformer (Presto), trained on remote sensing pixel-timeseries data. The model is designed specifically for remote sensing data and outperforms larger models. It can be used for transfer learning or feature extraction for simple models, enabling efficient deployment at scale. This paper falls under the categories of Remote Sensing/Satellite Image, Self-supervised learning, and Transformer.

Title: [SweCTRL-Mini: a data-transparent Transformer-based large language model for controllable text generation in Swedish](http://arxiv.org/pdf/2304.13994v1)     
Summary: The paper presents SweCTRL-Mini, a large language model for controllable text generation in Swedish. The model is based on the CTRL architecture and can be fine-tuned and used for inference on a single GPU. The authors provide details on the training data and text pre-processing and evaluate the model's performance on discriminative and generative tasks. SweCTRL-Mini is open-source and available for download.

Title: [Vision Conformer: Incorporating Convolutions into Vision Transformer Layers](http://arxiv.org/pdf/2304.13991v1)     
Summary: This paper proposes a new model called Vision Conformer (ViC) which incorporates convolutional layers within Vision Transformer (ViT) in order to address the lack of inductive bias towards image structures. ViC replaces the Multi-Layer Perceptron (MLP) in a ViT layer with a CNN and reconstructs the image data after self-attention using a reverse embedding layer. The paper demonstrates through evaluation that the use of convolutional layers improves the classification ability of ViT.

Title: [Contour Completion by Transformers and Its Application to Vector Font Data](http://arxiv.org/pdf/2304.13988v1)     
Summary: The paper proposes a Transformer-based method to solve the contour completion task where the missing points in a contour sequence need to be generated to complete the contour. The paper applies this method to vector font data and shows the results of typeface contour completion.

Title: [Optimization-Inspired Cross-Attention Transformer for Compressive Sensing](http://arxiv.org/pdf/2304.13986v1)     
Summary: The paper proposes an Optimization-inspired Cross-attention Transformer (OCT) module for compressive sensing (CS) in image reconstruction. The OCT is designed as an iterative process that improves visual quality with fewer parameters and reduces feature information loss. The OCT is integrated with a lightweight OCT-based Unfolding Framework (OCTUF) that achieves superior performance in CS compared to other methods while training lower complexity. The paper highlights a novel Dual Cross Attention sub-module that introduces multi-channel inertia forces and increases memory effect by a cross attention mechanism between adjacent iterations.

Title: [Neural Keyphrase Generation: Analysis and Evaluation](http://arxiv.org/pdf/2304.13883v1)     
Summary: This paper focuses on analyzing and evaluating keyphrase generation using neural models. Three models, T5, CatSeq-Transformer, and ExHiRD, were analyzed for their performance and behavior during keyphrase generation. The paper also proposes a novel metric framework, SoftKeyScore, to evaluate keyphrase similarity. The study finds that SoftKeyScore is more suitable than the standard F1 metric for evaluating keyphrases.

Title: [TR0N: Translator Networks for 0-Shot Plug-and-Play Conditional Generation](http://arxiv.org/pdf/2304.13742v1)     
Summary: The paper proposes a framework called TR0N, which can turn pre-trained unconditional generative models into conditional models without any training data. It learns a stochastic mapping between the space of conditions and the latent space of the generative model, enabling the generation of data samples satisfying the desired conditions. The proposed TR0N framework achieves zero-shot FID of 10.9 on MS-COCO and outperforms its competitors in terms of sampling speed and generality.

Title: [Distinguishing a planetary transit from false positives: a Transformer-based classification for planetary transit signals](http://arxiv.org/pdf/2304.14283v1)     
Summary: This paper proposes a new architecture for automatic classification of planetary transit signals using the self-attention mechanism inspired by the Transformer architecture. The proposed model achieves competitive results compared to previous methods and offers a level of interpretability through attention map inspection. The paper falls into the Transformer category because it uses this architecture and into Image Classification category because it classifies transit signals.

Title: [TempEE: Temporal-Spatial Parallel Transformer for Radar Echo Extrapolation Beyond Auto-Regression](http://arxiv.org/pdf/2304.14131v1)     
Summary: This paper proposes a novel radar echo extrapolation algorithm that utilizes temporal-spatial correlation features and the Transformer technology. The algorithm extracts features from multi-frame echo images to accurately represent non-stationary motion processes for precipitation prediction. The proposed algorithm uses a novel parallel encoder based on Transformer technology and a Multi-level Temporal-Spatial attention mechanism. The proposed method's effectiveness has been validated on the classic radar echo extrapolation task using the real-world dataset.

Title: [Phenotyping with Positive Unlabelled Learning for Genome-Wide Association Studies](http://arxiv.org/pdf/2202.07451v1)     
Summary: The paper proposes a model called AnchorBERT, which uses a combination of anchor learning and transformer architectures for phenotyping in genome-wide association studies (GWAS). The proposed model outperforms standard phenotype definitions and can detect significant genomic associations that were previously found only in large consortium studies with 5x more cases. The paper highlights the importance of reducing noise and phenotypic misclassification in GWAS, and the potential of machine learning in phenotypic discovery.

</details>
<details>
<summary>Semi-supervised learning</summary>
    
Title: [Learning Articulated Shape with Keypoint Pseudo-labels from Web Images](http://arxiv.org/pdf/2304.14396v1)     
Summary: The paper proposes an approach using as few as 50-150 images labeled with 2D keypoints to learn models for monocular 3D reconstruction of articulated objects. The approach involves training category-specific keypoint estimators, generating 2D keypoint pseudo-labels on unlabeled web images, and using both the labeled and self-labeled sets to train 3D reconstruction models. The results show that the approach can effectively utilize web images and improve 3D reconstruction performance for several articulated object categories beyond the fully-supervised baseline.

Title: [Cluster Flow: how a hierarchical clustering layer make allows deep-NNs more resilient to hacking, more human-like and easily implements relational reasoning](http://arxiv.org/pdf/2304.14081v1)     
Summary: The paper introduces a semi-supervised hierarchical clustering framework called ClusterFlow that operates on trained deep convolutional neural networks (NNs), utilizing multi-dimensional class and feature data. This framework adds more human-like functionality, improves the resilience of NNs against hacking, and allows for relational reasoning over sets of images. The paper suggests that ClusterFlow can be used as a tool to make modern NNs more human-like without re-training them.

Title: [Mimic-IV-ICD: A new benchmark for eXtreme MultiLabel Classification](http://arxiv.org/pdf/2304.13998v1)     
Summary: In this paper, the authors propose a public benchmark suite for ICD-10 and ICD-9 coding using a large EHR dataset derived from MIMIC-IV. They implement and compare several popular methods for ICD coding prediction tasks to standardize data preprocessing and establish a comprehensive ICD coding benchmark dataset. This approach fosters reproducibility and model comparison, accelerating progress toward employing automated ICD coding in future studies. Furthermore, they provide open-source code that offers easy access to data processing steps, benchmark creation, and experiment replication for those with MIMIC-IV access.

</details>
<details>
<summary>Self-supervised learning</summary>
    
Title: [Putting People in Their Place: Affordance-Aware Human Insertion into Scenes](http://arxiv.org/pdf/2304.14406v1)     
Summary: The paper presents a self-supervised method for realistically inserting humans into scene images while respecting scene affordances. The method involves a large-scale diffusion model trained on a dataset of 2.4M video clips to produce diverse and plausible poses while considering the scene context. The model can also hallucinate realistic people and scenes and enable interactive editing. The approach outperforms prior work in synthesizing more realistic human appearance and natural human-scene interactions.

Title: [Maximizing Model Generalization for Manufacturing with Self-Supervised Learning and Federated Learning](http://arxiv.org/pdf/2304.14398v1)     
Summary: The paper proposes a method for maximizing model generalization for fault diagnosis in manufacturing using self-supervised learning and federated learning. The approach focuses on maximizing feature generality on the source domain and transferring the model to the target domain via weight transfer. Self-supervised learning with Barlow Twins produces more discriminative features, and federated learning expands the effective training data by sharing information across multiple machines. Results show that the proposed method outperforms traditional supervised learning and domain adaptation methods in an unlabeled target domain with emerging motor faults.

Title: [Lightweight, Pre-trained Transformers for Remote Sensing Timeseries](http://arxiv.org/pdf/2304.14065v1)     
Summary: The paper presents a pre-trained transformer-based model, Pretrained Remote Sensing Transformer (Presto), trained on remote sensing pixel-timeseries data. The model is designed specifically for remote sensing data and outperforms larger models. It can be used for transfer learning or feature extraction for simple models, enabling efficient deployment at scale. This paper falls under the categories of Remote Sensing/Satellite Image, Self-supervised learning, and Transformer.

Title: [MAPConNet: Self-supervised 3D Pose Transfer with Mesh and Point Contrastive Learning](http://arxiv.org/pdf/2304.13819v1)     
Summary: The paper presents a self-supervised framework for 3D pose transfer which can be trained in unsupervised, semi-supervised, or fully supervised settings without any correspondence labels. The framework uses two contrastive learning constraints in the latent space (a mesh-level loss for disentangling global patterns and a point-level loss for discriminating local semantics) and achieves state-of-the-art results in supervised 3D pose transfer, with comparable results in unsupervised and semi-supervised settings. The method is also generalizable to unseen human and animal data with complex topologies.

</details>
<details>
<summary>UAV/Remote Sensing/Satellite Image</summary>
    
Title: [Fault Tolerant Super Twisting Sliding Mode Control of a Quadrotor UAV Using Control Allocation](http://arxiv.org/pdf/2304.14350v1)     
Summary: This paper proposes a fault-tolerant super-twisting sliding mode controller for a quadrotor UAV using control allocation. The proposed controller increases accuracy and reduces chattering while the control allocation algorithm optimizes trajectory tracking performance in the presence of an actuator fault. Simulation results show the effectiveness of the proposed approach in stabilizing the quadrotor in case of an actuator fault.

Title: [Density Invariant Contrast Maximization for Neuromorphic Earth Observations](http://arxiv.org/pdf/2304.14125v1)     
Summary: This paper proposes a solution to the problem of multiple extrema and noise-intolerance in contrast maximization techniques used in event-based vision systems for neuromorphic earth observation. The proposed solution corrects the warped events before calculating the contrast, making it insensitive to event data and does not require any prior knowledge of the camera motion. The approach enables the creation of better motion-compensated maps through an analytical compensation technique using a novel dataset from the International Space Station.

Title: [Securing Autonomous Air Traffic Management: Blockchain Networks Driven by Explainable AI](http://arxiv.org/pdf/2304.14095v1)     
Summary: The paper proposes the development of a secure network that leverages blockchain technology and explainable AI for autonomous air traffic management in the UAV sector. The authors review research in blockchain development, self-learning networking architectures, and explainable AI, and present a case study of federated learning UTM that uses real air traffic and weather data. The proposed system requires further research and development to enable future autonomous air mobility.

Title: [Improved path planning algorithms for non-holonomic autonomous vehicles in industrial environments with narrow corridors: Roadmap Hybrid A* and Waypoints Hybrid B*. Roadmap hybrid A* and Waypoints hybrid A* Pseudocodes](http://arxiv.org/pdf/2304.14043v1)     
Summary: This paper proposes two new path planning algorithms, Roadmap Hybrid A* and Waypoints Hybrid A*, specifically designed for navigating narrow industrial corridors with obstacles. These algorithms outperform the standard Hybrid A* in terms of computational speed and other metrics. The algorithms utilize a static roadmap and waypoints generated from a topological map of the environment to guide Hybrid A*. The simulation study conducted in an industrial plant demonstrates the effectiveness of these algorithms in servicing machines.

Title: [A Distributed Online Optimization Strategy for Cooperative Robotic Surveillance](http://arxiv.org/pdf/2304.14016v1)     
Summary: This paper proposes a distributed algorithm for controlling a team of cooperating robots to protect a target from intruders. The algorithm utilizes an online optimization problem within a distributed aggregative framework. The defending robots determine their positions based on the relative position between the intruders and the target, their contribution to the team barycenter, and collisions with other robots. The effectiveness of the algorithm is validated through simulations and experiments on a team of cooperating quadrotors.

Title: [Learning and Reasoning Multifaceted and Longitudinal Data for Poverty Estimates and Livelihood Capabilities of Lagged Regions in Rural India](http://arxiv.org/pdf/2304.13958v1)     
Summary: The paper proposes a project to examine poverty in rural India from 1990-2022 using artificial intelligence and multiple data sources, including satellite images and communication networks. The study aims to classify districts into different types based on poverty indicators and examine causation and longitudinal analysis. The paper emphasizes the importance of targeting lagging regions and vulnerable populations to eradicate poverty.

Title: [Deep Learning Techniques for Hyperspectral Image Analysis in Agriculture: A Review](http://arxiv.org/pdf/2304.13880v1)     
Summary: This academic paper focuses on the use of deep learning techniques in analyzing hyperspectral images in agriculture. The paper discusses the high redundancy of spectral bands and limited training samples that make the classification of HSI a complex task. The authors review and evaluate the performance of various deep learning approaches, such as Autoencoders, Convolutional Neural Networks, Recurrent Neural Networks, and Generative Adversarial Networks, on well-known land cover datasets. The paper concludes that deep learning techniques show promising results in HSI analysis, especially in agriculture.

Title: [Hybrid Genetic Algorithm and Mixed Integer Linear Programming for Flying Sidekick TSP](http://arxiv.org/pdf/2304.13832v1)     
Summary: The paper proposes a hybrid genetic algorithm and mixed integer linear programming approach for optimizing the Flying Sidekick TSP problem, wherein trucks and drones work in cooperation. The proposed algorithm (HGenFS) incorporates specific heuristics and a local search phase, and is capable of finding optimal solutions in a matter of seconds. The mathematical formulations presented are suitable for solving problems up to ten customers. This paper falls under the category of UAV/Remote Sensing/Satellite Image as it focuses on optimizing the use of drones for logistics delivery.

Title: [Green UAV-enabled Internet-of-Things Network with AI-assisted NOMA for Disaster Management](http://arxiv.org/pdf/2304.13802v1)     
Summary: This paper proposes a UAV-assisted wireless IoT network using NOMA and AI-assisted resource allocation to maximize energy efficiency in emergency-based IoT applications. The proposed scheme outperforms other methods in terms of energy consumption and complexity.

Title: [A Method for Classifying Snow Using Ski-Mounted Strain Sensors](http://arxiv.org/pdf/2304.14307v1)     
Summary: The paper proposes a method for classifying snow types using strain sensors mounted on ski surfaces. The method can accurately distinguish between three snow types with 97% accuracy using two strain gauges and an inertial measurement unit. The study suggests optimal placement of strain gauges halfway between the binding and the tip/tail of the ski. The proposed method can have various applications, including citizen science efforts to map snow surface characteristics in the backcountry and developing skis with automated stiffness tuning based on snow type.

</details>
<details>
<summary>Image Synthesis/Generation</summary>
    
Title: [Putting People in Their Place: Affordance-Aware Human Insertion into Scenes](http://arxiv.org/pdf/2304.14406v1)     
Summary: The paper presents a self-supervised method for realistically inserting humans into scene images while respecting scene affordances. The method involves a large-scale diffusion model trained on a dataset of 2.4M video clips to produce diverse and plausible poses while considering the scene context. The model can also hallucinate realistic people and scenes and enable interactive editing. The approach outperforms prior work in synthesizing more realistic human appearance and natural human-scene interactions.

Title: [Motion-Conditioned Diffusion Model for Controllable Video Synthesis](http://arxiv.org/pdf/2304.14404v1)     
Summary: The paper introduces MCDiff, a motion-conditioned diffusion model for controllable video synthesis that generates a video from a starting image frame and a set of strokes. MCDiff utilizes a flow completion model to predict the dense video motion based on the semantic understanding of the video frame and the sparse motion control. The diffusion model synthesizes high-quality future frames to form the output video. The paper showcases the effectiveness of MCDiff in stroke-guided controllable video synthesis and exhibits its capability on diverse content and motion synthesis.

Title: [Make It So: Steering StyleGAN for Any Image Inversion and Editing](http://arxiv.org/pdf/2304.14403v1)     
Summary: The paper proposes a novel GAN inversion method called Make It So, which operates in the noise space instead of the latent style space, and preserves editing capabilities even for out-of-domain images. The proposed method outperforms the state-of-the-art method by a significant margin in inversion accuracy and edit quality for complex indoor scenes.

Title: [IconShop: Text-Based Vector Icon Synthesis with Autoregressive Transformers](http://arxiv.org/pdf/2304.14400v1)     
Summary: The paper proposes IconShop, a text-guided vector icon synthesis method using an autoregressive transformer to sequence and tokenize SVG paths into a command sequence. The proposed method consistently exhibits better icon synthesis performance than existing methods in terms of quality, diversity, and speed. The paper also demonstrates the flexibility of IconShop with two novel icon manipulation tasks.

Title: [ZeroShotDataAug: Generating and Augmenting Training Data with ChatGPT](http://arxiv.org/pdf/2304.14334v1)     
Summary: The paper proposes using ChatGPT, a large generative language model, to generate synthetic training data with task-specific prompts for augmenting data in low-resource scenarios. The augmented data generated from ChatGPT outperforms existing approaches for data augmentation. Additionally, the paper investigates methodologies for evaluating the quality of the data generated.

Title: [Edit Everything: A Text-Guided Generative System for Images Editing](http://arxiv.org/pdf/2304.14006v1)     
Summary: The paper introduces Edit Everything, a generative system that takes image and text inputs and produces image outputs for editing images using simple text instructions. The system utilizes prompts to guide the visual module in generating requested images and incorporates Stable Diffusion with the use of Segment Anything model and CLIP. The system is publicly available on GitHub.

Title: [TR0N: Translator Networks for 0-Shot Plug-and-Play Conditional Generation](http://arxiv.org/pdf/2304.13742v1)     
Summary: The paper proposes a framework called TR0N, which can turn pre-trained unconditional generative models into conditional models without any training data. It learns a stochastic mapping between the space of conditions and the latent space of the generative model, enabling the generation of data samples satisfying the desired conditions. The proposed TR0N framework achieves zero-shot FID of 10.9 on MS-COCO and outperforms its competitors in terms of sampling speed and generality.

Title: [ganX -- generate artificially new XRF a python library to generate MA-XRF raw data out of RGB images](http://arxiv.org/pdf/2304.14078v1)     
Summary: The paper presents ganX, a Python library that can convert a coloured RGB image to X-ray fluorescence Macro maps (MA-XRF) using a Monte Carlo method. The probability function used for the conversion is computed using a database of pigment XRF signals and their corresponding RGB values. The library is available open source and released to PyPi.

</details>
<details>
<summary>Graph Neural Networks</summary>
    
Title: [A Simple and Efficient Parallel Laplacian Solver](http://arxiv.org/pdf/2304.14345v1)     
Summary: The paper introduces a simple and efficient parallel Laplacian solver based on random sampling and block Cholesky factorization. The solver achieves better depth and work than the best-known parallel Laplacian solvers for dense graphs. The Laplacian matrices are commonly used in graph neural networks for deep learning tasks on graph-structured data.

Title: [Fast Sampling of $b$-Matchings and $b$-Edge Covers](http://arxiv.org/pdf/2304.14289v1)     
Summary: The paper proposes an efficient algorithm for sampling $b$-matchings and $b$-edge covers in bounded-degree graphs using the simple Glauber dynamics. The paper also proves spectral independence for a broad class of binary symmetric Holant problems with log-concave signatures, including $b$-matchings, $b$-edge covers, and antiferromagnetic $2$-spin edge models. The algorithm's mixing time is shown to be $O(n \log n)$, which significantly improves upon previous results that only worked for small values of $b$ and had worse running time. The paper's contributions are based on spectral graph theory and diffusion models.

Title: [Adaptive manifold for imbalanced transductive few-shot learning](http://arxiv.org/pdf/2304.14281v1)     
Summary: The paper proposes a novel algorithm called Adaptive Manifold for imbalanced transductive few-shot learning. The method leverages the underlying manifold of labeled support examples and unlabeled queries by using manifold similarity to predict the class probability distribution per query. It outperforms other state-of-the-art methods on three benchmark datasets and three different backbones. The algorithm is parameterized by one centroid per class and a set of graph-specific parameters that determine the manifold. The parameters are optimized through a loss function that can be tuned towards class-balanced or imbalanced distributions.

Title: [When Do Graph Neural Networks Help with Node Classification: Investigating the Homophily Principle on Node Distinguishability](http://arxiv.org/pdf/2304.14274v1)     
Summary: The paper investigates the role of homophily in the performance of Graph Neural Networks (GNNs) on Node Classification (NC) tasks. It demonstrates the insufficiency of considering only intra-class Node Distinguishability (ND) and proposes a Contextual Stochastic Block Model for Homophily (CSBM-H) to better understand the effect of homophily. Two metrics, Probabilistic Bayes Error (PBE) and Expected Negative KL-divergence (ENKL), are defined to quantify ND and visualize the results. The paper verifies that the superiority of GNNs is closely related to both intra- and inter-class ND regardless of homophily levels and proposes a new Kernel Performance Metric (KPM) to reveal the advantage and disadvantage of GNNs on synthetic and real-world datasets.

Title: [Graphlet and Orbit Computation on Heterogeneous Graphs](http://arxiv.org/pdf/2304.14268v1)     
Summary: The paper explores the computation of graphlets and orbits on heterogeneous graphs, which can be treated as colored graphs. The canonical label technique is used to determine graph isomorphism with multiple states on nodes and edges. The authors provide a Python package to generate orbits for colored directed graphs and determine orbit occurrence frequency. The paper provides examples to illustrate the use of the package.

Title: [Compact Distance Oracles with Large Sensitivity and Low Stretch](http://arxiv.org/pdf/2304.14184v1)     
Summary: The paper introduces a new type of data structure called an $f$-edge fault-tolerant distance sensitive oracle, which provides an estimate of the distance between two nodes in a graph even when some edges are removed. The paper presents an $f$-DSO with large sensitivity, low stretch, and subquadratic space complexity. The authors use approximate distance oracles and derandomization techniques to achieve their results. The paper falls under the categories of Graph Neural Networks and Theory.

Title: [Human Semantic Segmentation using Millimeter-Wave Radar Sparse Point Clouds](http://arxiv.org/pdf/2304.14132v1)     
Summary: The paper proposes a framework for human semantic segmentation on sparse millimeter-wave radar point clouds using graph structure and topological features. The framework includes a global and sequential feature-extracting module, an efficient loss function for better training and segmentation results, and achieves state-of-the-art performance on both custom and benchmark datasets. The paper falls under the categories of point cloud, image segmentation, graph neural networks, and transformer.

Title: [Universal Obstructions of Graph Parameters](http://arxiv.org/pdf/2304.14121v1)     
Summary: The paper introduces a graph-parametric framework for obtaining obstruction characterizations of graph parameters. The framework defines the notions of class obstruction, parametric obstruction, and universal obstruction as combinatorial objects that determine the asymptotic behavior of graph parameters. The paper surveys existing graph-theoretic results on most known graph parameters and provides some unifying results on their classification.

Title: [Interweaved Graph and Attention Network for 3D Human Pose Estimation](http://arxiv.org/pdf/2304.14045v1)     
Summary: The paper proposes a novel Interweaved Graph and Attention Network (IGANet) for 3D human pose estimation. The network allows bidirectional communications between graph convolutional networks and attentions to capture global and local correlations for better representation learning of human skeleton. The proposed method achieves state-of-the-art performance on two benchmark datasets.

Title: [Bitcoin Double-Spending Attack Detection using Graph Neural Network](http://arxiv.org/pdf/2304.13935v1)     
Summary: The paper proposes a graph neural network (GNN) approach for detecting Bitcoin double-spending attacks. The GNN model predicts whether all nodes in the network contain a given payment transaction in their own memory pool (mempool) using information only obtained from some observer nodes in the network. The proposed model can detect double-spending with an accuracy of at least 0.95 when more than about 1% of the entire nodes in the network are observer nodes.

Title: [Network Analysis as a Tool for Shaping Conservation and Development Policy: A Case Study of Timber Market Optimization in India](http://arxiv.org/pdf/2304.13907v1)     
Summary: This paper discusses the potential for using network analysis as a tool for shaping conservation and development policy in the context of optimizing the timber market between farmers and traders in India. The authors formulate the commercial tree market as a transportation problem and optimize the transactions using a model based on a detailed dataset of market interactions between farmers and timber traders. They find a high potential to increase efficiency of market transactions within this region through a maximum-flow-minimum-cost optimization. The paper proposes that using this network flow optimization model to strategically distribute permits can reduce costs associated with market transactions and establish tree planting programs to support a long-term sustainable tree market, benefiting farmers, traders, and industries.

Title: [highway2vec -- representing OpenStreetMap microregions with respect to their road network characteristics](http://arxiv.org/pdf/2304.13865v1)     
Summary: The paper proposes a method for generating embeddings of OpenStreetMap microregions based on their road network characteristics using the H3 spatial index. The obtained vector representations allow detection of similarity between map hexagons in their road networks, and an arithmetic in the latent space yields meaningful results. The contribution aids data scientists in infrastructure-related prediction tasks with spatial variables.

Title: [Revisiting Network Value: Sublinear Knowledge Law](http://arxiv.org/pdf/2304.14084v1)     
Summary: This paper introduces a novel concept called the sublinear knowledge law, which examines knowledge growth in citation networks and demonstrates that it is notably slower than traditional network growth as outlined by established laws such as Sarnoff's Law, Metcalfe's Law, and Reed's Law. The authors utilized the Deep-time Digital Earth academic literature to demonstrate the coexistence of these laws in citation networks. The results offer an innovative perspective on network value while also filling a gap in network research.

</details>
<details>
<summary>Vision-Language (Multimodality)</summary>
    
Title: [Energy-based Models as Zero-Shot Planners for Compositional Scene Rearrangement](http://arxiv.org/pdf/2304.14391v1)     
Summary: This paper proposes a language-instructed spatial concept representation using energy functions to rearrange scenes. The instruction is mapped to corresponding energy functions using a language parser, and a visual-language model grounds their arguments to relevant objects in the scene. The goal scene configurations are generated by gradient descent on the energy functions, and local vision-based policies relocate objects to inferred goal locations. The model outperforms language-to-action reactive policies and Large Language Model planners for long instructions that involve compositions of multiple spatial concepts. The paper tests the model on established instruction-guided manipulation benchmarks and introduces compositional instruction benchmarks.

Title: [$œÄ$-Tuning: Transferring Multimodal Foundation Models with Optimal Multi-task Interpolation](http://arxiv.org/pdf/2304.14381v1)     
Summary: The paper introduces a transfer learning method called Predict-Interpolate Tuning ($\pi$-Tuning) for vision, language, and vision-language tasks. It utilizes the parameters of lightweight task-specific experts learned from similar tasks to aid the target downstream task, with task similarities predicted in a modality-independent space. $\pi$-Tuning offers benefits such as intra- and inter-modal transferability exploration and compatibility with diverse types of parameter-efficient experts. The paper demonstrates through experiments on 14 unimodal and 6 multimodal datasets that $\pi$-Tuning surpasses fine-tuning and other parameter-efficient transfer learning methods in full-shot and low-shot regimes.

Title: [Design of a multimodal device to improve well-being of autistic workers interacting with collaborative robots](http://arxiv.org/pdf/2304.14191v1)     
Summary: The paper describes the design and development of (A)MICO, a multimodal device aimed to improve the user experience of ASD workers interacting with collaborative robots in production lines. The device proposes a new intuitive mode of communication in which information about the cobot activity is transferred through acoustic and visual feedback. The design process involves a co-design process with users with high functioning autism to analyze the system from different perspectives, and Design for All principles were taken into consideration to develop a human-friendly device.

Title: [mPLUG-Owl: Modularization Empowers Large Language Models with Multimodality](http://arxiv.org/pdf/2304.14178v1)     
Summary: The paper introduces mPLUG-Owl, a training paradigm that equips LLMs with multi-modal abilities through modularized learning of foundation LLM, a visual knowledge module, and a visual abstractor module. The approach can support multiple modalities and facilitate diverse unimodal and multimodal abilities through modality collaboration. The model outperforms existing multi-modal models and demonstrates impressive instruction and visual understanding ability, multi-turn conversation ability, and knowledge reasoning ability. The paper is available along with code, pre-trained model, instruction-tuned models, and evaluation set on GitHub.

Title: [Figments and Misalignments: A Framework for Fine-grained Crossmodal Misinformation Detection](http://arxiv.org/pdf/2304.14133v1)     
Summary: This paper proposes a framework for fine-grained crossmodal misinformation detection by introducing a benchmark dataset named FIGMENTS and a synthetic data generation method called Crossmodal HArd Synthetic MisAlignment (CHASMA). The authors conducted an extensive study using a Transformer-based architecture, and the results showed that incorporating CHASMA in conjunction with other generated datasets consistently improved the overall performance on FIGMENTS in both binary and multiclass settings.

Title: [A sensemaking system for grouping and suggesting stories from multiple affective viewpoints in museums](http://arxiv.org/pdf/2304.14117v1)     
Summary: The paper presents a sensemaking system that utilizes affective-based reasoning to group and suggest stories created by users in a museum context. The system is designed to promote inclusive and empathy-based interpretations of cultural content by recommending stories with different emotional stances. The system is tested on the collection of the Gallery of Modern Art in Turin and is integrated with an app called GAMGame.

Title: [DataComp: In search of the next generation of multimodal datasets](http://arxiv.org/pdf/2304.14108v1)     
Summary: The paper introduces DataComp, a benchmark for improving multimodal datasets. The benchmark entails proposing new training sets by designing new filtering techniques or curating new data sources and testing them on a standardized CLIP training code and evaluating on downstream test sets. The benchmark consists of various scales, facilitating the study of scaling trends and making the benchmark accessible to researchers with different resources. The paper also introduces DataComp-1B, a dataset that shows promising results by curating the training sets, enabling training CLIP ViT-L/14 from scratch to 79.2% zero-shot accuracy on ImageNet.

Title: [Learning Human-Human Interactions in Images from Weak Textual Supervision](http://arxiv.org/pdf/2304.14104v1)     
Summary: The paper proposes a new paradigm for learning human-human interactions in images as free text from a single still image using knowledge distillation applied to synthetic caption data produced by a large language model without explicit supervision. The pseudo-labels produced by this procedure are used to train a captioning model to effectively understand human-human interactions in images. The approach outperforms SOTA image captioning and situation recognition models on this task.

Title: [Edit Everything: A Text-Guided Generative System for Images Editing](http://arxiv.org/pdf/2304.14006v1)     
Summary: The paper introduces Edit Everything, a generative system that takes image and text inputs and produces image outputs for editing images using simple text instructions. The system utilizes prompts to guide the visual module in generating requested images and incorporates Stable Diffusion with the use of Segment Anything model and CLIP. The system is publicly available on GitHub.

Title: [Retrieval-based Knowledge Augmented Vision Language Pre-training](http://arxiv.org/pdf/2304.13923v1)     
Summary: The paper proposes a retrieval-based knowledge augmented vision language pre-training model (REAVL) that retrieves world knowledge from knowledge graphs and incorporates it into vision-language pre-training. The model promotes the mutual integration of multi-modal data and knowledge by fusing explicit knowledge with vision-language pairs. The experiments show that REAVL achieves state-of-the-art results on knowledge-based vision-language understanding and multimodal entity linking tasks, as well as competitive results on general vision-language tasks.

Title: [Programmatically Grounded, Compositionally Generalizable Robotic Manipulation](http://arxiv.org/pdf/2304.13826v1)     
Summary: The paper proposes a modular approach, ProgramPort, to leverage pre-trained vision-language models for robotic manipulation. It disentangles domain-specific action information and domain-general visual information, resulting in improved zero-shot and compositional generalization in a variety of manipulation behaviors. The entire modular network can be trained with end-to-end imitation learning objectives.

Title: [Towards ethical multimodal systems](http://arxiv.org/pdf/2304.13765v1)     
Summary: The paper discusses the ethical evaluation of multimodal artificial intelligence systems that take both text and an image as input and output text. The authors propose creating a multimodal ethical database through human feedback and using this database to construct morality-evaluating algorithms. The models tested are a RoBERTa-large classifier and a multilayer perceptron classifier. The paper addresses the ethical concerns surrounding generative AI systems and the growing field of AI alignment.

</details>
<details>
<summary>Model Compression/Knowledge Distillation/Pruning</summary>
    
Title: [LaMini-LM: A Diverse Herd of Distilled Models from Large-Scale Instructions](http://arxiv.org/pdf/2304.14402v1)     
Summary: The paper proposes a method called LaMini-LM that distills knowledge from instruction-trained Large Language Models (LLMs) to smaller ones. The authors developed a large set of diverse instructions and demonstrated that their LaMini-LM models of varying sizes are on par with competitive baselines while being nearly 10 times smaller in size. The proposed approach has applications in natural language processing tasks.

Title: [CONSCENDI: A Contrastive and Scenario-Guided Distillation Approach to Guardrail Models for Virtual Assistants](http://arxiv.org/pdf/2304.14364v1)     
Summary: The paper proposes a contrastive and scenario-guided distillation approach, named CONSCENDI, for creating a guardrail model to monitor the output of large language models in virtual assistants. The paper outlines two critical steps, scenario-augmented generation, and contrastive training examples, which lead to a diverse training set of rule-violating conversations and greater control over the classification process. The approach results in guardrail models that outperform baselines, making it a promising technique for knowledge distillation and model compression in virtual assistants.

Title: [Self-discipline on multiple channels](http://arxiv.org/pdf/2304.14224v1)     
Summary: The paper proposes a self-distillation method called Self-discipline on multiple channels (SMC) which combines consistency regularization with self-distillation using the concept of multiple channels to improve the generalization ability and robustness of models. SMC-2, containing only two channels, outperforms existing methods on various models and datasets and can also curb the negative effects of label noise interference. The paper falls under the category of Model Compression/Knowledge Distillation/Pruning.

Title: [Learning Human-Human Interactions in Images from Weak Textual Supervision](http://arxiv.org/pdf/2304.14104v1)     
Summary: The paper proposes a new paradigm for learning human-human interactions in images as free text from a single still image using knowledge distillation applied to synthetic caption data produced by a large language model without explicit supervision. The pseudo-labels produced by this procedure are used to train a captioning model to effectively understand human-human interactions in images. The approach outperforms SOTA image captioning and situation recognition models on this task.

Title: [JaxPruner: A concise library for sparsity research](http://arxiv.org/pdf/2304.14082v1)     
Summary: This paper introduces JaxPruner, a JAX-based library for pruning and sparse training of neural networks. The library provides concise implementations of popular algorithms with minimal memory and latency overhead, using a common API and integrating seamlessly with the Optimax optimization library. The paper demonstrates easy integration with four different codebases and provides baseline experiments on popular benchmarks.

Title: [Guaranteed Quantization Error Computation for Neural Network Model Compression](http://arxiv.org/pdf/2304.13812v1)     
Summary: The paper addresses the problem of guaranteed output error computation for neural network compression with quantization. The proposed approach involves building a merged neural network from a feedforward neural network and its quantized version, and then applying optimization-based and reachability analysis methods to compute the guaranteed quantization error. A numerical example is also presented to validate the effectiveness of the approach.

Title: [Fine Tuning with Abnormal Examples](http://arxiv.org/pdf/2304.13783v1)     
Summary: The paper proposes a methodology for pruning datasets in fine-tuning natural language processing models using abnormal examples, leading to better out of sample performance. The authors use the SQUAD dataset and identify 10,500 examples that create a more uniform distribution for training, resulting in improved performance when fine-tuning ELECTRA.

</details>
<details>
<summary>Contrastive Learning</summary>
    
Title: [CONSCENDI: A Contrastive and Scenario-Guided Distillation Approach to Guardrail Models for Virtual Assistants](http://arxiv.org/pdf/2304.14364v1)     
Summary: The paper proposes a contrastive and scenario-guided distillation approach, named CONSCENDI, for creating a guardrail model to monitor the output of large language models in virtual assistants. The paper outlines two critical steps, scenario-augmented generation, and contrastive training examples, which lead to a diverse training set of rule-violating conversations and greater control over the classification process. The approach results in guardrail models that outperform baselines, making it a promising technique for knowledge distillation and model compression in virtual assistants.

Title: [MarsEclipse at SemEval-2023 Task 3: Multi-Lingual and Multi-Label Framing Detection with Contrastive Learning](http://arxiv.org/pdf/2304.14339v1)     
Summary: The paper presents the MarsEclipse system for multi-lingual and multi-label framing detection using a contrastive loss function for fine-tuning large pre-trained language models. The system achieved first place on the official test set and leaderboard for five out of six languages in the SemEval-2023 Task 3 Subtask 2 on Framing Detection. The code is available on GitHub, and the paper details the experimental setup and includes various ablation studies.

Title: [Origin Tracing and Detecting of LLMs](http://arxiv.org/pdf/2304.14072v1)     
Summary: The paper proposes a method to trace the origin of large language models (LLMs) and detect whether a given text context is generated by an AI system. The method is based on contrastive features between LLMs and extracts model-wise features to trace the text origins. The proposed approach works under both white-box and black-box settings and requires limited data compared to supervised learning methods. The paper provides valuable observations based on experimental results and calls for ethical concerns of LLM providers. The code and data are released as a toolkit and benchmark for future AI origin tracing and detecting studies.

Title: [ContraNeRF: 3D-Aware Generative Model via Contrastive Learning with Unsupervised Implicit Pose Embedding](http://arxiv.org/pdf/2304.14005v1)     
Summary: The paper proposes a novel 3D-aware GAN optimization technique, called ContraNeRF, that uses contrastive learning with implicit pose embeddings to capture complex 3D scene structures more effectively without relying on ground-truth camera poses. Experimental results show that ContraNeRF outperforms existing methods on datasets with multiple object categories and inconsistent camera poses.

Title: [UCF: Uncovering Common Features for Generalizable Deepfake Detection](http://arxiv.org/pdf/2304.13949v1)     
Summary: The paper proposes a disentanglement framework that uncovers common forgery features to address the overfitting issue in deepfake detection. It employs a multi-task learning strategy and contrastive regularization technique to encourage the disentanglement of specific and common forgery features. The proposed framework outperforms current state-of-the-art methods in generalizable deepfake detection.

</details>
<details>
<summary>Continual Learning</summary>
    
Title: [Incremental Generalized Category Discovery](http://arxiv.org/pdf/2304.14310v1)     
Summary: The paper explores the problem of Incremental Generalized Category Discovery (IGCD), where the model needs to categorize images from previously seen and novel categories, over a series of time steps. The proposed method uses non-parametric categorization with efficient image sampling to mitigate catastrophic forgetting and outperforms existing related methods. A new benchmark dataset named iNatIGCD is proposed for performance evaluation.

</details>
<details>
<summary>Adversarial Learning</summary>
    
Title: [Boosting Big Brother: Attacking Search Engines with Encodings](http://arxiv.org/pdf/2304.14031v1)     
Summary: The paper presents an attack on search engines by manipulating text encodings, which is successful against major commercial search engines and chatbots. The authors also demonstrate a variant of the attack targeting text summarization and plagiarism detection models, which are closely tied to search. The paper provides defenses against these techniques and highlights the need for security patches to prevent disinformation campaigns launched by adversaries.

Title: [Attacks on Robust Distributed Learning Schemes via Sensitivity Curve Maximization](http://arxiv.org/pdf/2304.14024v1)     
Summary: The paper introduces a new attack on robust distributed learning schemes used in federated or decentralized learning paradigms. The attack is based on sensitivity curve maximization (SCM) and is able to disrupt existing robust aggregation schemes by injecting small but effective perturbations. The paper is focused on the vulnerability of aggregation schemes based on robust variations of the mean in distributed learning and proposes a new attack method to overcome them. Thus, the paper falls under both the categories of Adversarial Learning and Federated Learning.

Title: [Detection of Adversarial Physical Attacks in Time-Series Image Data](http://arxiv.org/pdf/2304.13919v1)     
Summary: The paper proposes a real-time detector called VisionGuard* (VG) for detecting adversarial physical attacks in time-series image data. VG utilizes majority-vote mechanisms and is evaluated on videos of traffic signs with physical attacks. The paper investigates how majority-vote mechanisms can be leveraged to enhance the performance of adversarial detectors. The proposed method provides comparative experiments against detectors designed for out-of-distribution data and digitally attacked images.

</details>
<details>
<summary>Federated Learning</summary>
    
Title: [Maximizing Model Generalization for Manufacturing with Self-Supervised Learning and Federated Learning](http://arxiv.org/pdf/2304.14398v1)     
Summary: The paper proposes a method for maximizing model generalization for fault diagnosis in manufacturing using self-supervised learning and federated learning. The approach focuses on maximizing feature generality on the source domain and transferring the model to the target domain via weight transfer. Self-supervised learning with Barlow Twins produces more discriminative features, and federated learning expands the effective training data by sharing information across multiple machines. Results show that the proposed method outperforms traditional supervised learning and domain adaptation methods in an unlabeled target domain with emerging motor faults.

Title: [Attacks on Robust Distributed Learning Schemes via Sensitivity Curve Maximization](http://arxiv.org/pdf/2304.14024v1)     
Summary: The paper introduces a new attack on robust distributed learning schemes used in federated or decentralized learning paradigms. The attack is based on sensitivity curve maximization (SCM) and is able to disrupt existing robust aggregation schemes by injecting small but effective perturbations. The paper is focused on the vulnerability of aggregation schemes based on robust variations of the mean in distributed learning and proposes a new attack method to overcome them. Thus, the paper falls under both the categories of Adversarial Learning and Federated Learning.

Title: [Federated Prompting and Chain-of-Thought Reasoning for Improving LLMs Answering](http://arxiv.org/pdf/2304.13911v1)     
Summary: The paper proposes Fed-SP-SC and Fed-DP-CoT methods to enhance answer precision in frequently asked questions posed by distributed users using cloud-based Large Language Models (LLMs). The methods involve improving distributed synonymous questions using Self-Consistency and Chain-of-Thought techniques. Through extensive experiments, the proposed methods are demonstrated to significantly enhance question accuracy by fully exploring the synonymous nature of the questions and the consistency of the answers.

</details>
<details>
<summary>Video</summary>
    
Title: [ChatVideo: A Tracklet-centric Multimodal and Versatile Video Understanding System](http://arxiv.org/pdf/2304.14407v1)     
Summary: The paper presents a prototype system called ChatVideo that aims to address the limitations of existing deep video models by employing a tracklet-centric paradigm and various Video Foundation Models to annotate tracklet properties. The system stores all detected tracklets in a database and interacts with the user through a database manager. The effectiveness of the method is demonstrated through case studies on different types of in-the-wild videos.

Title: [Motion-Conditioned Diffusion Model for Controllable Video Synthesis](http://arxiv.org/pdf/2304.14404v1)     
Summary: The paper introduces MCDiff, a motion-conditioned diffusion model for controllable video synthesis that generates a video from a starting image frame and a set of strokes. MCDiff utilizes a flow completion model to predict the dense video motion based on the semantic understanding of the video frame and the sparse motion control. The diffusion model synthesizes high-quality future frames to form the output video. The paper showcases the effectiveness of MCDiff in stroke-guided controllable video synthesis and exhibits its capability on diverse content and motion synthesis.

Title: [Deeply-Coupled Convolution-Transformer with Spatial-temporal Complementary Learning for Video-based Person Re-identification](http://arxiv.org/pdf/2304.14122v1)     
Summary: The paper proposes a novel spatial-temporal complementary learning framework for video-based person re-identification called Deeply-Coupled Convolution-Transformer (DCCT). The framework includes coupling CNNs and Transformers to extract visual features, Complementary Content Attention (CCA) to guide spatial learning, Hierarchical Temporal Aggregation (HTA) to capture inter-frame dependencies and gated attention to deliver aggregated temporal information for temporal learning. The proposed framework outperforms most state-of-the-art methods on public Re-ID benchmarks.

Title: [SeeHow: Workflow Extraction from Programming Screencasts through Action-Aware Video Analytics](http://arxiv.org/pdf/2304.14042v1)     
Summary: The paper presents a method called SeeHow, which uses computer vision techniques to automatically extract editing steps and code snippets from programming screencasts, resulting in a programming workflow. The proposed method accurately extracts code-line editing steps and allows for better accessibility and interaction with screencast content for developers. The evaluation on 41 hours of tutorial videos and live coding screencasts demonstrated promising results.

Title: [Detection of Adversarial Physical Attacks in Time-Series Image Data](http://arxiv.org/pdf/2304.13919v1)     
Summary: The paper proposes a real-time detector called VisionGuard* (VG) for detecting adversarial physical attacks in time-series image data. VG utilizes majority-vote mechanisms and is evaluated on videos of traffic signs with physical attacks. The paper investigates how majority-vote mechanisms can be leveraged to enhance the performance of adversarial detectors. The proposed method provides comparative experiments against detectors designed for out-of-distribution data and digitally attacked images.

</details>
<details>
<summary>3D</summary>
    
Title: [Learning Articulated Shape with Keypoint Pseudo-labels from Web Images](http://arxiv.org/pdf/2304.14396v1)     
Summary: The paper proposes an approach using as few as 50-150 images labeled with 2D keypoints to learn models for monocular 3D reconstruction of articulated objects. The approach involves training category-specific keypoint estimators, generating 2D keypoint pseudo-labels on unlabeled web images, and using both the labeled and self-labeled sets to train 3D reconstruction models. The results show that the approach can effectively utilize web images and improve 3D reconstruction performance for several articulated object categories beyond the fully-supervised baseline.

Title: [Analogy-Forming Transformers for Few-Shot 3D Parsing](http://arxiv.org/pdf/2304.14382v1)     
Summary: The paper presents a model called Analogical Networks that can segment 3D object scenes using few-shot learning. The model retrieves related scenes from memory and predicts analogous part structures for the input scene, conditioning on the appropriate set of memories. Analogical Networks outperforms state-of-the-art 3D segmentation transformers in few-shot settings and successfully segments instances of novel object categories by expanding its memory.

Title: [Co-SLAM: Joint Coordinate and Sparse Parametric Encodings for Neural Real-Time SLAM](http://arxiv.org/pdf/2304.14377v1)     
Summary: The paper presents Co-SLAM, a neural RGB-D SLAM system based on a hybrid representation that performs real-time camera tracking and high-fidelity surface reconstruction. Co-SLAM uses a multi-resolution hash-grid and one-blob encoding to enable fast convergence, surface hole filling, and surface coherence. It incorporates a ray sampling strategy that allows global bundle adjustment over all keyframes. Co-SLAM achieves state-of-the-art scene reconstruction results and competitive tracking performance in various datasets and benchmarks.

Title: [Occ3D: A Large-Scale 3D Occupancy Prediction Benchmark for Autonomous Driving](http://arxiv.org/pdf/2304.14365v1)     
Summary: This paper introduces Occ3D, a large-scale 3D occupancy prediction benchmark for autonomous driving. The paper proposes a Coarse-to-Fine Occupancy (CTF-Occ) network that demonstrates superior performance in the 3D occupancy prediction task. The paper includes a label generation pipeline that produces dense, visibility-aware labels for a given scene, and constructs benchmarks based on the Waymo Open Dataset and the nuScenes Dataset. The paper addresses the need for finer geometric understanding in a coarse-to-fine fashion.

Title: [SparseFusion: Fusing Multi-Modal Sparse Representations for Multi-Sensor 3D Object Detection](http://arxiv.org/pdf/2304.14340v1)     
Summary: The paper proposes a novel multi-sensor 3D detection method called SparseFusion which exclusively uses sparse candidates and representations for efficient and accurate detections of objects in a scene. The proposed method utilizes the outputs of parallel detectors in the LiDAR and camera modalities as sparse candidates for fusion in a unified 3D space using a lightweight self-attention module. The paper achieves state-of-the-art performance on the nuScenes benchmark and is publicly available in GitHub.

Title: [Combining HoloLens with Instant-NeRFs: Advanced Real-Time 3D Mobile Mapping](http://arxiv.org/pdf/2304.14301v1)     
Summary: The paper presents a method of 3D reconstruction using a Microsoft HoloLens 2 as a multisensor platform that includes an RGB camera and an inertial measurement unit for SLAM-based camera-pose determination. The method utilizes a Neural Radiance Field (NeRF) as a neural scene representation in real-time with the acquired data from the HoloLens. The paper shows that the proposed method outperforms grid point sampling with NeRFs by multiple orders of magnitude and can be regarded as a complete real-time 3D reconstruction method in a mobile mapping setup.

Title: [A Probabilistic Attention Model with Occlusion-aware Texture Regression for 3D Hand Reconstruction from a Single RGB Image](http://arxiv.org/pdf/2304.14299v1)     
Summary: 
This paper proposes a novel probabilistic model for 3D hand reconstruction from a single RGB image. The model-based network estimates the prior probability distribution of joints and vertices, while the Attention-based Mesh Vertices Uncertainty Regression (AMVUR) model captures dependencies among vertices and correlation between joints and vertices. An occlusion-aware Hand Texture Regression model is also proposed for high-fidelity texture reconstruction. The proposed model achieves state-of-the-art accuracy in 3D hand and texture reconstruction from a single image in both supervised and weakly-supervised scenarios.

Title: [What's in a Name? Evaluating Assembly-Part Semantic Knowledge in Language Models through User-Provided Names in CAD Files](http://arxiv.org/pdf/2304.14275v1)     
Summary: This paper proposes that natural language names used in Computer Aided Design (CAD) software contain valuable domain-specific information that can be used to improve Large Language Models' (LLMs) ability to understand assembly-part relationships. The authors extract a large corpus of natural language part, feature, and document names and show that fine-tuning a pre-trained LLM on this data improves its performance on self-supervised tasks, highlighting the value of text data in the CAD domain. The paper concludes by identifying limitations and calling for further work in multimodal text-geometry models.

Title: [Compositional 3D Human-Object Neural Animation](http://arxiv.org/pdf/2304.14070v1)     
Summary: This paper proposes a compositional approach for animating human-object interactions (HOIs) from a novel perspective by using neural human-object deformation to model and render HOI dynamics based on implicit neural representations. Additionally, the authors devise a new compositional conditional neural radiance field (CC-NeRF) to enable interaction pose transferring among different persons and objects to allow for compositionally animated control of novel HOIs. Their experiments show that this method can generalize well to various novel HOI animation settings.

Title: [Interweaved Graph and Attention Network for 3D Human Pose Estimation](http://arxiv.org/pdf/2304.14045v1)     
Summary: The paper proposes a novel Interweaved Graph and Attention Network (IGANet) for 3D human pose estimation. The network allows bidirectional communications between graph convolutional networks and attentions to capture global and local correlations for better representation learning of human skeleton. The proposed method achieves state-of-the-art performance on two benchmark datasets.

Title: [ContraNeRF: 3D-Aware Generative Model via Contrastive Learning with Unsupervised Implicit Pose Embedding](http://arxiv.org/pdf/2304.14005v1)     
Summary: The paper proposes a novel 3D-aware GAN optimization technique, called ContraNeRF, that uses contrastive learning with implicit pose embeddings to capture complex 3D scene structures more effectively without relying on ground-truth camera poses. Experimental results show that ContraNeRF outperforms existing methods on datasets with multiple object categories and inconsistent camera poses.

Title: [Provably Stabilizing Global-Position Tracking Control for Hybrid Models of Multi-Domain Bipedal Walking via Multiple Lyapunov Analysis](http://arxiv.org/pdf/2304.13943v1)     
Summary: This paper proposes a time-based nonlinear control method for achieving accurate global position tracking (GPT) for multi-domain bipedal walking. The paper introduces a GPT control law for multi-domain walking that provably ensures exponential convergence of the entire error state within the full and over actuation domains and the directly regulated error state within the underactuation domain. The paper also constructs sufficient multiple-Lyapunov stability conditions for the hybrid multi-domain tracking error system under the proposed GPT control law. The proposed control approach is demonstrated on a ROBOTIS OP3 bipedal humanoid robot through simulations of three-domain walking with all motors activated and two-domain gait with inactive ankle motors.

Title: [Open Metaverse: Issues, Evolution, and Future](http://arxiv.org/pdf/2304.13931v1)     
Summary: This academic paper discusses the evolution, issues, and future prospects of the Open Metaverse, a space where real and virtual worlds are combined. It provides a comprehensive survey of the Metaverse, including related concepts such as trusted Metaverse, AI-enabled Metaverse, personalized Metaverse, and Metaverse-as-a-service. The paper presents challenges faced by the Metaverse such as limited resources and ethical issues. It explores promising directions such as autonomous Metaverse and lightweight Metaverse.

Title: [MAPConNet: Self-supervised 3D Pose Transfer with Mesh and Point Contrastive Learning](http://arxiv.org/pdf/2304.13819v1)     
Summary: The paper presents a self-supervised framework for 3D pose transfer which can be trained in unsupervised, semi-supervised, or fully supervised settings without any correspondence labels. The framework uses two contrastive learning constraints in the latent space (a mesh-level loss for disentangling global patterns and a point-level loss for discriminating local semantics) and achieves state-of-the-art results in supervised 3D pose transfer, with comparable results in unsupervised and semi-supervised settings. The method is also generalizable to unseen human and animal data with complex topologies.

Title: [Metal Inter-layer Via Keep-out-zone in M3D IC: A Critical Process-aware Design Consideration](http://arxiv.org/pdf/2304.13808v1)     
Summary: This paper discusses the impact of Metal Inter-layer Via (MIV) on the performance of adjacent devices in Monolithic Three-Dimensional Integrated Circuits (M3D-IC) and the need for a keep-out-zone (KOZ) to ensure reliability. The study uses simulations to analyze the performance changes of transistors placed near MIV and shows that there can be an increase in leakage current, which can be reduced significantly by having a KOZ. The paper falls under the 3D category as it focuses on the impact of MIV on adjacent devices in M3D-IC technology.

</details>
<details>
<summary>Sound</summary>
    
Title: [XAI-based Comparison of Input Representations for Audio Event Classification](http://arxiv.org/pdf/2304.14019v1)     
Summary: This paper explores the effect of different input representations for Audio Event Classification using eXplainable AI (XAI) to understand the underlying classification strategies of models. Two model architectures are compared - one directly processes the raw waveform, while the other takes in its time-frequency spectrogram representation. The use of relevance heatmaps obtained via "Siren" helps uncover representation-dependent decision strategies. The paper confirms that the model's classification strategies align with human requirements and identifies the best input representation in terms of robustness and representativity.

Title: [Data-driven Balanced Truncation for Predictive Model Order Reduction of Aeroacoustic Response](http://arxiv.org/pdf/2304.13900v1)     
Summary: The paper proposes a data-driven model reduction approach for the rapid prediction of aeroacoustic response in aircraft and turbomachinery. The technique uses the eigensystem realization algorithm (ERA) as a balanced truncation method and compares ERA reduced-order models (ROMs) based on training data generated by solving the linearized and nonlinear Euler equations. The authors address the computational bottleneck of operating on a large Hankel matrix by proposing a multi-fidelity gappy POD method and using tangential interpolation at the ROM level. The proposed methods enable highly accurate online acoustic response prediction and reduce the offline computation cost of ROMs.

Title: [Text-to-Audio Generation using Instruction-Tuned LLM and Latent Diffusion Model](http://arxiv.org/pdf/2304.13731v1)     
Summary: The paper presents a novel approach, TANGO, for text-to-audio (TTA) generation, utilizing an instruction-tuned LLM as the text encoder and a latent diffusion model (LDM) for audio generation. The proposed method outperforms the state-of-the-art AudioLDM and stays comparable on most metrics on the AudioCaps test set, despite being trained on a smaller dataset and keeping the text encoder frozen. The improvement in performance may also be attributed to the adoption of audio pressure level-based sound mixing for training set augmentation.

</details>
<details>
<summary>Dataset</summary>
    
Title: [A transparent approach to data representation](http://arxiv.org/pdf/2304.14209v1)     
Summary: The paper proposes a binary attribute representation (BAR) model for describing a dataset of Netflix viewers' ratings of movies. This representation uses discrete bits to classify viewers and requires fewer attributes than similar methods to achieve the same level of error. The nonuniform distribution of ratings among the movies in the dataset is also taken advantage of in training on a small selection of movies without compromising performance on the rest of the movies.

Title: [DataComp: In search of the next generation of multimodal datasets](http://arxiv.org/pdf/2304.14108v1)     
Summary: The paper introduces DataComp, a benchmark for improving multimodal datasets. The benchmark entails proposing new training sets by designing new filtering techniques or curating new data sources and testing them on a standardized CLIP training code and evaluating on downstream test sets. The benchmark consists of various scales, facilitating the study of scaling trends and making the benchmark accessible to researchers with different resources. The paper also introduces DataComp-1B, a dataset that shows promising results by curating the training sets, enabling training CLIP ViT-L/14 from scratch to 79.2% zero-shot accuracy on ImageNet.

Title: [Mimic-IV-ICD: A new benchmark for eXtreme MultiLabel Classification](http://arxiv.org/pdf/2304.13998v1)     
Summary: In this paper, the authors propose a public benchmark suite for ICD-10 and ICD-9 coding using a large EHR dataset derived from MIMIC-IV. They implement and compare several popular methods for ICD coding prediction tasks to standardize data preprocessing and establish a comprehensive ICD coding benchmark dataset. This approach fosters reproducibility and model comparison, accelerating progress toward employing automated ICD coding in future studies. Furthermore, they provide open-source code that offers easy access to data processing steps, benchmark creation, and experiment replication for those with MIMIC-IV access.

Title: [A Review of Panoptic Segmentation for Mobile Mapping Point Clouds](http://arxiv.org/pdf/2304.13980v1)     
Summary: The paper reviews the state of panoptic segmentation of outdoor mobile-mapping data, which is the combined task of assigning semantic classes and separating them into object instances. The paper sets up a modular pipeline for comprehensive experiments and provides the first public dataset for the task, extending NPM3D dataset to include instance labels.

Title: [Adaptive-Mask Fusion Network for Segmentation of Drivable Road and Negative Obstacle With Untrustworthy Features](http://arxiv.org/pdf/2304.13979v1)     
Summary: The paper proposes an Adaptive-Mask Fusion Network for segmentation of drivable road and negative obstacles with untrustworthy features. The proposed network uses adaptive-weight masks to fuse features from RGB and depth images with inconsistency to overcome the issue caused by untrustworthy features. The authors also release a large-scale RGB-depth dataset with manually-labeled ground truth for drivable roads and negative obstacles segmentation. The proposed network achieves state-of-the-art performance compared to other networks.

Title: [The Structurally Complex with Additive Parent Causality (SCARY) Dataset](http://arxiv.org/pdf/2304.14109v1)     
Summary: The paper proposes a new synthetic causal dataset, the Structurally Complex with Additive paRent causalitY (SCARY) dataset, which includes 40 scenarios generated with two different data generation mechanisms for generating the causal relationship between parent and child nodes. The dataset has a Varsortability of 0.5 and offers a valuable resource for researchers to explore causal discovery under more realistic scenarios. The dataset is available at https://github.com/JayJayc/SCARY.

</details>
<details>
<summary>Theory</summary>
    
Title: [Generalized Automorphisms of Channel Codes: Properties, Code Design, and a Decoder](http://arxiv.org/pdf/2304.14379v1)     
Summary: The paper proposes a Generalized Automorphism Ensemble Decoder (GAED) based on the Definition of automorphisms from linear algebra. The paper presents an explicit joint construction of codes and automorphisms, which can improve the decoding performance of low-density parity-check codes in the short block length regime. The paper also demonstrates a code construction of parity-check codes for designing suitable automorphisms.

Title: [Universal Algebra for Generalised Metric Spaces](http://arxiv.org/pdf/2304.14361v1)     
Summary: The paper investigates a generalization of the quantitative algebra framework to include generalised metric spaces and operations that need not be non-expansive. The authors introduce a sound and complete deductive system and show that equationally defined classes of quantitative algebras have free objects, proving monadicity theorems. The paper falls under the category of theory.

Title: [On the Generalization Error of Meta Learning for the Gibbs Algorithm](http://arxiv.org/pdf/2304.14332v1)     
Summary: The paper analyzes the generalization error of joint-training meta learning algorithms, specifically the Gibbs algorithm, using symmetrized KL information. The authors provide an exact characterization of the expected meta generalization error for the meta Gibbs algorithm and derive a similar characterization for the super-task Gibbs algorithm. The results also enable the authors to provide distribution-free generalization error upper bounds for these Gibbs algorithms applicable to meta learning.

Title: [Pushing the Boundaries of Tractable Multiperspective Reasoning: A Deduction Calculus for Standpoint EL+](http://arxiv.org/pdf/2304.14323v1)     
Summary: This paper introduces Standpoint EL+, an extended logic that allows for the integrated representation of domain knowledge relative to diverse standpoints or perspectives while maintaining tractability. The paper achieves this by designing a satisfiability-checking deduction calculus that addresses the need for practical algorithms. Overall, the paper pushes the boundaries of tractable multiperspective reasoning.

Title: [Empirical Individual State Observability](http://arxiv.org/pdf/2304.14313v1)     
Summary: The paper introduces a new empirical approach called Empirical Individual State Observability (E-ISO) to determine the level of observability of individual state variables in a dynamical system. The approach involves building an empirical observability matrix via simulation, applying convex optimization to efficiently determine the subset of its rows required to estimate each state variable individually, and calculating (un)observability measures for these subsets. The paper provides multiple example applications of E-ISO on linear and nonlinear systems and shows that the results are consistent with analytical results. E-ISO can be useful for designing active sensing control laws or optimizing sensor placement to increase the observability of individual state variables for engineered systems and analyzing trajectory decisions made by organisms.

Title: [On Solution Discovery via Reconfiguration](http://arxiv.org/pdf/2304.14295v1)     
Summary: The paper proposes a new framework for constructing feasible solutions for a given problem by making small modifications starting from a given state. The framework integrates different aspects of classical local search, reoptimization, and combinatorial reconfiguration and is exemplified on several combinatorial problems. The paper also studies the complexity of solution discovery variants of those problems and explores the boundary between tractable and intractable instances.

Title: [Structured interpolation for multivariate transfer functions of quadratic-bilinear systems](http://arxiv.org/pdf/2304.14292v1)     
Summary: This paper proposes a method for constructing multivariate interpolants in the frequency domain for structured quadratic-bilinear systems. The goal is to reduce the computational cost of simulating large-scale nonlinear systems by constructing accurate reduced-order surrogates. The proposed method is based on interpolation-based model reduction and preserves the internal structure of weakly nonlinear systems. The theoretical results are demonstrated with two numerical examples, including the simulation of molecular dynamics in crystal structures.

Title: [A posteriori error estimates of Darcy flows with Robin-type jump interface conditions](http://arxiv.org/pdf/2304.14287v1)     
Summary: The paper presents an a posteriori error estimator for mixed finite element methods of Darcy flow problems with Robin-type jump interface conditions. The estimator is constructed using Stenberg post-processing and interface-adapted Helmholtz-type decomposition and interpolation operator. The paper proves the reliability of the estimator, and includes numerical results illustrating adaptivity algorithms using the estimator.

Title: [LDPC Decoders Prefer More Reliable Parity Bits: Unequal Data Protection Over BSC](http://arxiv.org/pdf/2304.14278v1)     
Summary: The paper investigates the value of engineering parity bits in LDPC decoders and measures them to be more reliable than message bits. It studies the impact of unequal data protection on the threshold of a regular LDPC code over binary symmetric channel (BSC) with different types of decoders. The analysis includes non-equiprobable inputs and doping of parity bits. The paper shows that unequal data protection leads to significant improvements in threshold and convergence speed, even with a simple decoder.

Title: [When Do Graph Neural Networks Help with Node Classification: Investigating the Homophily Principle on Node Distinguishability](http://arxiv.org/pdf/2304.14274v1)     
Summary: The paper investigates the role of homophily in the performance of Graph Neural Networks (GNNs) on Node Classification (NC) tasks. It demonstrates the insufficiency of considering only intra-class Node Distinguishability (ND) and proposes a Contextual Stochastic Block Model for Homophily (CSBM-H) to better understand the effect of homophily. Two metrics, Probabilistic Bayes Error (PBE) and Expected Negative KL-divergence (ENKL), are defined to quantify ND and visualize the results. The paper verifies that the superiority of GNNs is closely related to both intra- and inter-class ND regardless of homophily levels and proposes a new Kernel Performance Metric (KPM) to reveal the advantage and disadvantage of GNNs on synthetic and real-world datasets.

Title: [Variational Bayes Made Easy](http://arxiv.org/pdf/2304.14251v1)     
Summary: The paper presents a 3-step recipe for simplifying the derivation of Variational Bayes, a popular method for approximate inference. The recipe involves identifying the posterior form by looking for linearity with respect to expectations of well-known distributions and then writing the update by "reading-off" the terms in front of those expectations. This simplifies and speeds up the derivation process while also making it more general.

Title: [Standpoint Linear Temporal Logic](http://arxiv.org/pdf/2304.14243v1)     
Summary: The paper presents a new logic called Standpoint Linear Temporal Logic (SLTL) by combining the multi-perspective modelling capacity of Standpoint Logic (SL) with the temporal features of Linear Temporal Logic (LTL). SLTL is a formalism that enables temporal reasoning in multi-perspective settings by allowing one to reason with diverse and potentially conflicting viewpoints by means of indexed modalities. The paper defines the syntax and semantics of SLTL, establishes its decidability and complexity, and provides a terminating tableau calculus to automate SLTL reasoning. The paper also presents a clear path to extend existing LTL reasoners with practical reasoning support for temporal reasoning in multi-perspective settings.

Title: [The Mutual Information In The Vicinity of Capacity-Achieving Input Distributions](http://arxiv.org/pdf/2304.14219v1)     
Summary: This paper analyzes the mutual information in the vicinity of capacity-achieving input distributions using linear cost constraints and finite input/output sets. The mutual information is bounded above by a quadratic function and closed-form expressions for the threshold and coefficient of the quadratic decrease are derived. Implications for the channel coding problem and related problems are discussed.

Title: [A particle method for non-local advection-selection-mutation equations](http://arxiv.org/pdf/2304.14210v1)     
Summary: This academic paper proposes a particle method for non-local advection-selection-mutation equations, which is shown to have well-posedness for a wide range of initial data. The method approximates the solution by a regularised sum of weighted Dirac masses, with characteristics solving a defined ODE system. The paper proves the convergence of the particle method over any finite interval and investigates its asymptotic-preserving properties in large times. The paper also provides examples of the method's application in two cases from the literature.

Title: [Compact Distance Oracles with Large Sensitivity and Low Stretch](http://arxiv.org/pdf/2304.14184v1)     
Summary: The paper introduces a new type of data structure called an $f$-edge fault-tolerant distance sensitive oracle, which provides an estimate of the distance between two nodes in a graph even when some edges are removed. The paper presents an $f$-DSO with large sensitivity, low stretch, and subquadratic space complexity. The authors use approximate distance oracles and derandomization techniques to achieve their results. The paper falls under the categories of Graph Neural Networks and Theory.

Title: [Tractability of sampling recovery on unweighted function classes](http://arxiv.org/pdf/2304.14169v1)     
Summary: The paper discusses the tractability of sampling recovery on unweighted function classes, focusing on the curse of dimensionality problem in the $L_2$-norm on certain spaces. The authors show that intersecting these classes with the Wiener algebra of functions with summable Fourier coefficients can make the problem tractable, but nonlinear algorithms are required. The paper relies on previous work by Rauhut and Ward.

Title: [Hypothesis Testing for Adversarial Channels: Chernoff-Stein Exponents](http://arxiv.org/pdf/2304.14166v1)     
Summary: The paper focuses on studying the Chernoff-Stein exponent for binary hypothesis testing problem in the presence of adversarial channels with different types of randomness. The authors investigate the cases where the transmitter is deterministic, may privately randomize, and shares randomness with the detector that is unavailable to the adversary. The analysis shows that a memoryless transmission strategy is optimal under shared randomness but suboptimal when the transmitter has private randomness.

Title: [An Algorithm for Computing with Brauer's Group Equivariant Neural Network Layers](http://arxiv.org/pdf/2304.14165v1)     
Summary: This paper presents an algorithm for computing with Brauer's Group Equivariant Neural Network Layers. The algorithm uses category theoretic constructions and Kronecker product matrices to perform multiplication for the orthogonal group, special orthogonal group, symplectic group, and symmetric group. The approach is shown to extend to the symmetric group, recovering the algorithm of arXiv:2303.06208. The paper achieves a significant reduction in computational cost compared to a naive implementation.

Title: [Traced Types for Safe Strategic Rewriting](http://arxiv.org/pdf/2304.14154v1)     
Summary: The paper proposes a static type system for strategy languages to assist with correct composition of rewrite strategies. The system combines a structural type system with a novel tracing system to detect potential errors in strategy execution paths. The paper presents a formalization of the language and tracing type system, and proves its type soundness.

Title: [Multiplicity Problems on Algebraic Series and Context-Free Grammars](http://arxiv.org/pdf/2304.14145v1)     
Summary: The paper presents complexity bounds for computational problems on algebraic power series over several commuting variables, specified by systems of polynomial equations related to weighted context-free grammars. Three problems - identifying an algebraic series as identically zero, determining if only finitely many coefficients are zero, and computing the coefficient of a specific monomial - are related to well-known computational problems on arithmetic circuits and shown to lie in the counting hierarchy. The paper also covers new complexity bounds on various language models and image processing techniques.

Title: [Categorification of Group Equivariant Neural Networks](http://arxiv.org/pdf/2304.14144v1)     
Summary: This paper explores the use of category theory to understand and improve group equivariant neural networks. The authors develop a new algorithm for computing the results of vector passing through an equivariant, linear layer for different groups using category theoretic constructions. The success of this approach shows that category theory can be beneficial for other fields of deep learning.

Title: [Improved Online Scheduling of Moldable Task Graphs under Common Speedup Models](http://arxiv.org/pdf/2304.14127v1)     
Summary: The paper proposes a new online scheduling algorithm for moldable task graphs on multiprocessor systems to minimize the overall completion time (makespan), and derive constant competitive ratios under four common speedup models. The paper also provides lower bounds on the competitiveness of any online list scheduling algorithm, matching the competitive ratio of the proposed algorithm for three speedup models, and close to the ratio for the general model.

Title: [Universal Obstructions of Graph Parameters](http://arxiv.org/pdf/2304.14121v1)     
Summary: The paper introduces a graph-parametric framework for obtaining obstruction characterizations of graph parameters. The framework defines the notions of class obstruction, parametric obstruction, and universal obstruction as combinatorial objects that determine the asymptotic behavior of graph parameters. The paper surveys existing graph-theoretic results on most known graph parameters and provides some unifying results on their classification.

Title: [A Linearized L1-Galerkin FEM for Non-smooth Solutions of Kirchhoff type Quasilinear Time-fractional Integro-differential Equation](http://arxiv.org/pdf/2304.14100v1)     
Summary: The paper proposes a linearized numerical scheme for a Kirchhoff type quasilinear time-fractional integro-differential equation, which has a weak singularity near time t=0. The scheme is semi-discrete and fully discrete, and uses a weighted H1 norm to derive a priori bounds on the solution. Accuracy rates in L‚àû(0,T;L2(Œ©)) and L‚àû(0,T;H10(Œ©)) are proven, and the scheme is demonstrated to be efficient through numerical examples.

Title: [Optimal Covariance Cleaning for Heavy-Tailed Distributions: Insights from Information Theory](http://arxiv.org/pdf/2304.14098v1)     
Summary: The paper explores the relationship between optimal covariance cleaning theory and information theory for normal and Student's t distributions. While the minimal Frobenius norm is equivalent to minimizing the loss of information for normal distributions, this is not necessarily true for Student's t distributions. However, in the asymptotic regime of large matrices, this deviation disappears, which has implications for extending the applicability of random matrix theory to heavy-tailed distributions often encountered in real-world applications.

Title: [Categorical Foundations of Explainable AI: A Unifying Formalism of Structures and Semantics](http://arxiv.org/pdf/2304.14094v1)     
Summary: This paper proposes a formal and unifying theory of Explainable AI (XAI) using the framework of category theory and feedback monoidal categories. The authors provide formal definitions for all essential terms in XAI and propose a taxonomy of the field following the introduced structure. The proposed foundation represents a significant tool to properly frame future research lines and a precious guidance for new researchers approaching the field.

Title: [Structured level-2 condition numbers of matrix functions](http://arxiv.org/pdf/2304.14077v1)     
Summary: The paper investigates the structured level-2 condition numbers of matrix functions, specifically in cases where the perturbation matrix is restricted to certain groups or spaces. The study compares unstructured and structured condition numbers for specific matrix functions through numerical experiments.

Title: [A Parameterized Theory of PAC Learning](http://arxiv.org/pdf/2304.14058v1)     
Summary: The paper introduces a parameterized theory of PAC learning, filling a gap in the domain of sample complexity that did not have an analogue in the parameterized complexity paradigm. The theory identifies two distinct notions of fixed-parameter learnability that form counterparts to the class FPT, and develops the machinery required to exclude fixed-parameter learnability. The theory is applied to refine tractability boundaries for CNF and DNF learning, and for learning problems on graphs.

Title: [Unification of Lagrangian staggered-grid hydrodynamics and cell-centered hydrodynamics in one dimension](http://arxiv.org/pdf/2304.14054v1)     
Summary: This academic paper proposes a novel scheme to unify Lagrangian staggered-grid and cell-centered hydrodynamic methods in one dimension. The paper does not fall into any of the provided categories.

Title: [Localized orthogonal decomposition for a multiscale parabolic stochastic partial differential equation](http://arxiv.org/pdf/2304.14049v1)     
Summary: The paper proposes a multiscale method based on the localized orthogonal decomposition (LOD) technique for a parabolic stochastic partial differential equation with highly oscillatory diffusion and additive noise. The method computes a coarse representation of the elliptic operator enriched by fine-scale information on the diffusion, and optimal order strong convergence is obtained. The paper combines LOD with a Monte-Carlo estimator, and numerical examples confirm the theoretical findings and the computational efficiency of the method.

Title: [Discrete Weber inequalities and related Maxwell compactness for hybrid spaces over polyhedral partitions of domains with general topology](http://arxiv.org/pdf/2304.14041v1)     
Summary: This academic paper presents a proof for discrete versions of the first and second Weber inequalities on $\boldsymbol{H}(\mathbf{curl})\cap\boldsymbol{H}(\mathrm{div}_{\eta})$-like hybrid spaces over polyhedral partitions of domains with general topology. The results are optimal in terms of being formulated in $\boldsymbol{H}(\mathbf{curl})$- and $\boldsymbol{H}(\mathrm{div}_{\eta})$-like hybrid semi-norms and being valid for face polynomials in the smallest possible stability-compatible spaces. The paper also proves related discrete Maxwell compactness properties in a general topological setting.

Title: [communication of information in systems of heterogenious agents and systems' dynamics](http://arxiv.org/pdf/2304.14013v1)     
Summary: The paper discusses the communication of information in complex systems consisting of heterogeneous agents and its impact on the dynamics of the system. The study shows that the mechanisms of meaning and information processing can be evaluated analytically in a model framework, and the results accurately fit observed data from systems of different origins.

Title: [Explicit Constructions of Optimal $(r,Œ¥)$-Locally Repairable Codes](http://arxiv.org/pdf/2304.14011v1)     
Summary: The paper proposes a more general construction of locally repairable codes (LRCs) with $(r,\delta)$-locality, which have practical applications in distributed storage systems. The authors use MDS codes to give three classes of explicit constructions of optimal $(r,\delta)$-LRCs with block length beyond $q$. The paper extends the results of a previous work on optimal minimum distance LRCs and presents new LRCs with optimal parameters.

Title: [A barrier for further approximating Sorting By Transpositions](http://arxiv.org/pdf/2304.13996v1)     
Summary: This paper focuses on the Transposition Distance Problem (TDP) which seeks to determine the minimum number of transpositions needed to transform a linear chromosome into another represented by permutations. The paper investigates properties of palisades, a family of permutations that are "hard" to sort and determines their transposition distance. It provides the exact transposition diameter for a special subset of the Symmetric Group essential for the study of approximate solutions using the simplification technique. The paper also shows the implications of the transposition distance of palisades for the study of Sorting By Transpositions (SBT), implying that it is impossible to guarantee approximation ratios lower than 1.375 when approximating SBT.

Title: [An FPTAS for Budgeted Laminar Matroid Independent Set](http://arxiv.org/pdf/2304.13984v1)     
Summary: The paper presents an FPTAS (Fully Polynomial-Time Approximation Scheme) for the budgeted laminar matroid independent set problem, improving the previous EPTAS (Efficient Polynomial-Time Approximation Scheme) for this matroid family. The problem involves selecting a maximum profit independent set of a laminar matroid while keeping the total cost bounded by a given budget. The proposed scheme is based on a dynamic program utilizing the tree-like structure of laminar matroids and generalizes the FPTAS known for knapsack problems with a cardinality constraint and multiple-choice knapsack.

Title: [Noise Is Not the Main Factor Behind the Gap Between SGD and Adam on Transformers, but Sign Descent Might Be](http://arxiv.org/pdf/2304.13960v1)     
Summary: The paper investigates the performance gap between stochastic gradient descent (SGD) and Adam optimizer on language tasks. While previous work attributed the gap to heavy-tailed noise, the paper shows that stochasticity and heavy-tailed noise are not major factors in the performance gap. Instead, Adam outperforms SGD as batch size increases, while SGD is less effective at taking advantage of noise reduction. Further investigation suggests that the behavior of Adam with large batches is similar to sign descent with momentum.

Title: [A central scheme for coupled hyperbolic systems](http://arxiv.org/pdf/2304.13946v1)     
Summary: The paper presents a novel numerical scheme for solving coupled systems of conservation laws that is derived based on a relaxation approach. The coupling condition for the underlying relaxation system is discussed and well-posedness is analyzed. The scheme is validated using the p-system of gas dynamics as a case study.

Title: [A One-Dimensional Symmetric Force-Based Blending Method for Atomistic-to-Continuum Coupling](http://arxiv.org/pdf/2304.13939v1)     
Summary: This paper presents a new symmetric and consistent blended force-based Atomistic-to-Continuum (a/c) scheme for the atomistic chain in one-dimensional space. The paper analyzes the conditions for the well-posedness of the underlying model and establishes an optimal blending size and type to ensure the semi-norm stability for the blended force-based operator. Several numerical experiments are presented to test and confirm the theoretical findings.

Title: [Tight Upper Bounds on the Error Probability of Spinal Codes over Fading Channels](http://arxiv.org/pdf/2304.13910v1)     
Summary: The paper provides explicit and tight upper bounds on the error probability of Spinal codes under maximum-likelihood decoding and perfect channel state information over three fading channels. The derived upper bounds are verified to be tight through simulation results. The focus of the paper is on theoretical analysis rather than practical implementation or application in a specific field. Hence, it falls under the Theory category.

Title: [Proving Logical Atomicity using Lock Invariants](http://arxiv.org/pdf/2304.13898v1)     
Summary: This paper explores the use of older lock-invariant-based specifications for locks in proving logically atomic specifications for data structures with fine-grained locking. The authors compare this approach with one based on atomic specifications for locks and show that logical atomicity can still be proven using the older specs, but the proofs are more complex. The technique is implemented in the Verified Software Toolchain and applied to C implementations of lock-based concurrent data structures.

Title: [Structure-Aware Lower Bounds and Broadening the Horizon of Tractability for QBF](http://arxiv.org/pdf/2304.13896v1)     
Summary: The paper presents a study of the quantified Boolean formula (QBF) problem, which is a fundamental problem in computational complexity theory. The authors develop structure-aware reductions to obtain nearly tight lower bounds for highly restricted instances of QBF and complement these with novel algorithms that establish the problem's complexity under standard graph-theoretic parameterizations. The study broadens the understanding of the complexity of QBF under different representations of instances and provides implications for other natural graph representations.

Title: [The $n_s$-step Interpolatory (Quasi)-Stationary Subdivision Schemes and Their Interpolating Refinable Functions](http://arxiv.org/pdf/2304.13824v1)     
Summary: This paper introduces and studies $n_s$-step interpolatory M-subdivision schemes and their interpolating M-refinable functions with convergence and smoothness properties characterized. The paper also introduces the concept of $n_s$-step interpolatory quasi-stationary subdivision schemes and provides examples of convergent $n_s$-step interpolatory M-subdivision schemes with dilation factors $M=2,3,4$.

Title: [Backpropagation and F-adjoint](http://arxiv.org/pdf/2304.13820v1)     
Summary: The paper proposes a mathematical framework for studying feed-forward and backward propagation processes in deep neural networks. Based on the two-step rule for back-propagation, the authors introduce the F-adjoint concept aimed at better describing the backpropagation process. The study shows that the F-adjoint of the corresponding F-propagation characterizes the backpropagation process associated with any cost/loss function.

Title: [Verifying linear temporal specifications of constant-rate multi-mode systems](http://arxiv.org/pdf/2304.13816v1)     
Summary: The paper introduces a variant of linear temporal logic (LTL) for constant-rate multi-mode systems (MMS) and investigates the complexity of the model-checking problem for syntactic fragments of LTL. The paper obtains a complexity landscape where each fragment is either P-complete, NP-complete, or undecidable. The results generalize and unify several results on MMS and continuous counter systems.

Title: [The Hellan-Herrmann-Johnson and TDNNS method for linear and nonlinear shells](http://arxiv.org/pdf/2304.13806v1)     
Summary: The paper proposes an extension to the mixed Hellan-Herrmann-Johnson (HHJ) method for nonlinear Koiter shells to nonlinear Naghdi shells by a hierarchical approach. The proposed method is locking-free and can be applied to structures with kinks and branched shells. The method is validated through numerical examples and experiments. The paper falls under the category of theory.

Title: [Resampling Gradients Vanish in Differentiable Sequential Monte Carlo Samplers](http://arxiv.org/pdf/2304.14390v1)     
Summary: The paper proposes an extension to Differentiable AIS by adding a resampling step inspired by Sequential Monte Carlo to address the issue of low effective sample size and degenerate distributions in DAIS. The authors find that it is not necessary to differentiate through the resampling step, which avoids gradient variance issues observed in similar approaches for Particle Filters.

Title: [Detection of a very serious error in the paper: "On identifiability of nonlinear ODE models and applications in viral dynamics"](http://arxiv.org/pdf/2304.14288v1)     
Summary: The paper identifies a serious error in a highly cited article on the identifiability of nonlinear ODE models and its applications in viral dynamics. The paper proves the non-uniqueness of the three unidentifiable parameters and details the error made by the authors. It is important to notify this error to correct the false claim of local identifiability of all model parameters.

Title: [Comparison of Stochastic Parametrization Schemes using Data Assimilation on Triad Models](http://arxiv.org/pdf/2304.14216v1)     
Summary: The paper examines two stochastic parametrization schemes, namely Stochastic Advection by Lie Transport (SALT) and Location Uncertainty (LU), which are commonly used in modeling uncertainty in fluid dynamics models. The authors then compare reduced-order versions of these schemes, termed helicity-preserving stochastic triad (HST) and energy-preserving stochastic triad (EST), respectively. The models are considered as ideal benchmark models for testing new data assimilation algorithms, exhibiting diverse behaviors depending on the coefficients used and coming with natural physical properties such as the conservation of energy and helicity.

Title: [Exploring the flavor structure of quarks and leptons with reinforcement learning](http://arxiv.org/pdf/2304.14176v1)     
Summary: The paper proposes a method to use reinforcement learning to explore the flavor structure of quarks and leptons based on a policy-based algorithm for models with $U(1)$ symmetry. The agent trained on the $U(1)$ charges of quarks and leptons identifies 21 models consistent with experimentally measured masses and mixing angles. The paper predicts specific values of effective mass for neutrinoless double beta decay and leptonic CP violation through an autonomous behavior of the agent.

Title: [On the Discrete Logarithm Problem for elliptic curves over local fields](http://arxiv.org/pdf/2304.14150v1)     
Summary: The paper discusses an attack on the Discrete Logarithm Problem (DLP) for elliptic curves, which is the core of security for cryptosystems such as Elliptic Curve Cryptography (ECC). The attack is based on a connection between the DLP and lifting, using the exponential map for elliptic curves and its inverse over $ \mathbb{Z} / p^k \mathbb{Z} $. The paper also shows that hyperelliptic curves are resistant to this attack, offering a higher level of security compared to classic elliptic curves used in cryptography.

Title: [Revisiting Network Value: Sublinear Knowledge Law](http://arxiv.org/pdf/2304.14084v1)     
Summary: This paper introduces a novel concept called the sublinear knowledge law, which examines knowledge growth in citation networks and demonstrates that it is notably slower than traditional network growth as outlined by established laws such as Sarnoff's Law, Metcalfe's Law, and Reed's Law. The authors utilized the Deep-time Digital Earth academic literature to demonstrate the coexistence of these laws in citation networks. The results offer an innovative perspective on network value while also filling a gap in network research.

Title: [Counting unate and balanced monotone Boolean functions](http://arxiv.org/pdf/2304.14069v1)     
Summary: The paper focuses on counting the number of n-variable unate and monotone Boolean functions, and provides this count for n up to 6. It also provides the count for balanced 7-variable monotone Boolean functions.

Title: [Propagating Kernel Ambiguity Sets in Nonlinear Data-driven Dynamics Models](http://arxiv.org/pdf/2304.14057v1)     
Summary: This academic paper proposes an algorithm that propagates ambiguity sets through nonlinear data-driven models using the Koopman operator and CME, via the kernel maximum mean discrepancy geometry. The results show that their kernel ambiguity sets are the natural geometric structure for the learned data-driven dynamical system models. The paper is focused on addressing the problem of distributionally robust control and learning-based control of learned system models under data-distribution shift, and falls under the category of theory and data-driven modeling.

Title: [Convergence of Adam Under Relaxed Assumptions](http://arxiv.org/pdf/2304.13972v1)     
Summary: The paper provides a convergence proof for the Adam optimization algorithm, which is commonly used in deep learning, under more realistic assumptions than existing proofs. The proof shows that Adam converges to $\epsilon$-stationary points with $\mathcal{O}(\epsilon^{-4})$ gradient complexity. The key to the analysis is a new proof of boundedness of gradients along the optimization trajectory. A variance-reduced version of Adam with accelerated gradient complexity is also proposed.

Title: [Fairness Uncertainty Quantification: How certain are you that the model is fair?](http://arxiv.org/pdf/2304.13950v1)     
Summary: The paper introduces a method to construct confidence intervals for the fairness of learned models in fairness-aware machine learning, which is important for sensitive applications such as judiciary systems. The method extends theoretical guarantees for online bootstrap methods to constrained optimization and applies it to Disparate Impact and Disparate Mistreatment aware linear binary classifiers trained using online SGD-type algorithms. The results are demonstrated using synthetic and real datasets.

Title: [Improved Stabilizer Estimation via Bell Difference Sampling](http://arxiv.org/pdf/2304.13915v1)     
Summary: The paper presents results on the complexity of learning quantum states using stabilizer formalism, and uses Bell difference sampling as the underlying algorithmic primitive. The paper proves lower bounds on the number of gates required for preparing computationally pseudorandom quantum states, and gives an algorithm for estimating stabilizer fidelity of a given quantum state. The paper also improves the soundness analysis of stabilizer state property testing and exhibits a tolerant property testing algorithm for stabilizer states.

Title: [Typical and atypical solutions in non-convex neural networks with discrete and continuous weights](http://arxiv.org/pdf/2304.13871v1)     
Summary: The paper explores the geometry of the landscape of solutions in non-convex neural network models, specifically binary and continuous negative-margin perceptrons. It identifies the existence of subdominant minimizers that are extremely flat and wide and coexist with a background of dominant solutions. The study shows that when a certain threshold in constraint density is crossed, the local entropy of the wide flat minima becomes non-monotonic, indicating a break-up of the space of robust solutions into disconnected components. The paper also examines the impact of wide flat minimizers on the generalization performance as a learning device.

Title: [Adaptation to Misspecified Kernel Regularity in Kernelised Bandits](http://arxiv.org/pdf/2304.13830v1)     
Summary: The paper titled "Adaptation to Misspecified Kernel Regularity in Kernelised Bandits" discusses the adaptivity of learning algorithms to the regularity of associated kernel functions in continuum-armed bandit problems. The paper derives an adaptivity lower bound and connects the statistical difficulty for adaptivity in three fundamental types of function spaces: RKHS, Sobolev space, and H\"older space. This paper falls under the categories of Reinforcement learning and Theory.

Title: [Generalized generalized linear models: Convex estimation and online bounds](http://arxiv.org/pdf/2304.13793v1)     
Summary: The paper introduces a computational framework for estimating parameters in generalized generalized linear models (GGLM), a class of models that extends generalized linear models (GLM) to account for dependencies among observations in spatio-temporal data. The approach uses a monotone operator-based variational inequality method to overcome non-convexity in parameter estimation and provide guarantees for parameter recovery. The results can be applied to GLM and GGLM, focusing on spatio-temporal models. The paper also presents online instance-based bounds using martingale concentrations inequalities and demonstrates the performance of the algorithm using numerical simulations and a real data example for wildfire incidents.

Title: [Some Problems Concerning Quantum Channels and Entropies](http://arxiv.org/pdf/2304.13771v1)     
Summary: The paper explores fundamental limits on communication rates over quantum channels using entropic formulas, and discusses the challenges of computing these expressions. It also covers optimization and approximation of entropic formulas over subsets of quantum states, as well as progress made on a quantum erasure simulation problem in high noise environments.

Title: [Enhancing Robustness of Gradient-Boosted Decision Trees through One-Hot Encoding and Regularization](http://arxiv.org/pdf/2304.13761v1)     
Summary: The paper proposes a method to enhance the robustness of gradient-boosted decision trees (GBDT) by applying one-hot encoding to convert it into a linear framework, allowing for the use of linear regression techniques and a novel risk decomposition to assess the model's robustness against perturbations. The authors suggest enhancing the model's robustness by refitting the models with L1 or L2 regularization, and provide theoretical results on the effect of regularization on model performance and robustness. Numerical experiments demonstrate the proposed approach can enhance the robustness of one-hot-encoded GBDT models.

</details>
<details>
<summary>Natural Language Processing</summary>
    
Title: [ViMQ: A Vietnamese Medical Question Dataset for Healthcare Dialogue System Development](http://arxiv.org/pdf/2304.14405v1)     
Summary: The paper presents a Vietnamese dataset of medical questions from patients with sentence-level and entity-level annotations for the Intent Classification and Named Entity Recognition tasks. The dataset aims to facilitate the development of task-oriented healthcare chatbots with better comprehension of patient queries. The paper also proposes a self-supervised training strategy that improves the performance of baseline models. The dataset and code are publicly available.

Title: [LaMini-LM: A Diverse Herd of Distilled Models from Large-Scale Instructions](http://arxiv.org/pdf/2304.14402v1)     
Summary: The paper proposes a method called LaMini-LM that distills knowledge from instruction-trained Large Language Models (LLMs) to smaller ones. The authors developed a large set of diverse instructions and demonstrated that their LaMini-LM models of varying sizes are on par with competitive baselines while being nearly 10 times smaller in size. The proposed approach has applications in natural language processing tasks.

Title: [We're Afraid Language Models Aren't Modeling Ambiguity](http://arxiv.org/pdf/2304.14399v1)     
Summary: The paper discusses the importance of handling ambiguity in language models (LMs) and presents the AmbiEnt benchmark dataset for evaluating LM's ability to recognize and disentangle possible meanings. The authors find that even the latest state-of-the-art LM, GPT-4, struggles with this task, highlighting the need for more ambiguity-sensitive tools in NLP. The paper also demonstrates the potential practical applications of ambiguity detection in flagging misleading political claims.

Title: [string2string: A Modern Python Library for String-to-String Algorithms](http://arxiv.org/pdf/2304.14395v1)     
Summary: The paper introduces an open-source library called string2string, which offers a range of algorithms for string-to-string problems such as alignment, distance measurement, search, and similarity analysis. The library includes traditional and advanced neural approaches, as well as helpful visualization tools and metrics. The algorithms are implemented in Python and can be used for natural-language processing, bioinformatics, and computational social sciences applications. The library can increase flexibility and coverage compared to existing string libraries.

Title: [ZeroShotDataAug: Generating and Augmenting Training Data with ChatGPT](http://arxiv.org/pdf/2304.14334v1)     
Summary: The paper proposes using ChatGPT, a large generative language model, to generate synthetic training data with task-specific prompts for augmenting data in low-resource scenarios. The augmented data generated from ChatGPT outperforms existing approaches for data augmentation. Additionally, the paper investigates methodologies for evaluating the quality of the data generated.

Title: [Idioms, Probing and Dangerous Things: Towards Structural Probing for Idiomaticity in Vector Space](http://arxiv.org/pdf/2304.14333v1)     
Summary: This paper investigates how idiomatic information is structurally encoded in embeddings using a structural probing method. The authors perform a comparative study of static (GloVe) and contextual (BERT) embeddings on a repurposed English verbal multi-word expression dataset. The experiments reveal that both types of embeddings encode idiomatic information to varying degrees, but there is conflicting evidence as to whether idiomaticity is encoded in the vector norm. The study also identifies limitations of the dataset and suggests future directions for improving its suitability for a probing analysis.

Title: [AI, write an essay for me: A large-scale comparison of human-written versus ChatGPT-generated essays](http://arxiv.org/pdf/2304.14276v1)     
Summary: This paper compares human-written argumentative essays to those generated by the ChatGPT AI model. The study found that ChatGPT-generated essays were rated higher in quality than human-written essays and exhibited different linguistic characteristics. The paper argues that educators should incorporate AI models into the education system to free up time for other learning objectives.

Title: [Entity-Level Sentiment Analysis (ELSA): An exploratory task survey](http://arxiv.org/pdf/2304.14241v1)     
Summary: The paper investigates the task of Entity-Level Sentiment Analysis (ELSA) which is the identification of overall sentiment expressed towards volitional entities in longer texts. The authors annotate a set of professional reviews for their sentiment towards each volitional entity and evaluate existing models for document-level, sentence-level, and target-level sentiment analysis. The study shows that there is no single task that provides satisfactory performance for ELSA and calls for further research on the topic. The paper also provides a survey of previous relevant work.

Title: [The Intended Uses of Automated Fact-Checking Artefacts: Why, How and Who](http://arxiv.org/pdf/2304.14238v1)     
Summary: This academic paper discusses the intended uses of automated fact-checking artifacts and highlights the importance of thoroughly discussing the means, ends, and stakeholders involved. The analysis of 100 highly-cited papers reveals common vagueness and inconsistency in proposed strategies, hindering the technology from reaching its goals. The paper provides recommendations for thinking and writing about the use of fact-checking artifacts.

Title: [A Modular Approach for Multilingual Timex Detection and Normalization using Deep Learning and Grammar-based methods](http://arxiv.org/pdf/2304.14221v1)     
Summary: The paper presents a modular approach for multilingual temporal expression (timex) detection and normalization using deep learning and grammar-based methods. The system combines a fine-tuned Masked Language Model for detection and a grammar-based normalizer. The paper experiments in Spanish and English and compares with HeidelTime, the state-of-the-art in multilingual temporal processing. The results show the effectiveness of the proposed approach in gold timex normalization, timex detection, and type recognition. A detailed error analysis suggests the importance of detecting only those timexes for which it is feasible to provide normalization rules.

Title: [NAP at SemEval-2023 Task 3: Is Less Really More? (Back-)Translation as Data Augmentation Strategies for Detecting Persuasion Techniques](http://arxiv.org/pdf/2304.14179v1)     
Summary: The paper explores the use of (back-)translation as a data augmentation strategy for detecting persuasion techniques in news using multi-lingual transformer models. The results show that both data augmentation strategies boost performance, but balancing human-produced and machine-generated data is crucial.

Title: [ChatGPT vs State-of-the-Art Models: A Benchmarking Study in Keyphrase Generation Task](http://arxiv.org/pdf/2304.14177v1)     
Summary: This paper evaluates ChatGPT's keyphrase generation ability and compares its performance with state-of-the-art models on six publicly available datasets from scientific articles and news domains. The study finds that ChatGPT outperforms current state-of-the-art models in all tested datasets and environments, generating high-quality keyphrases that adapt well to diverse domains and document lengths.

Title: [Answering Uncertain, Under-Specified API Queries Assisted by Knowledge-Aware Human-AI Dialogue](http://arxiv.org/pdf/2304.14163v1)     
Summary: This paper presents a novel Knowledge-Aware Human-AI Dialogue (KAHAID) agent that assists developers in answering uncertain and under-specified API queries through multi-round question answering and API recommendations with relevance explanation and extended suggestions. The KAHAID agent was evaluated for its human-AI dialogue efficiency, API recommendation, and knowledge extension, and it outperformed existing state-of-the-art methods. The paper also includes a user study that shows how explainable API recommendations can help developers identify the best API approach more easily or confidently.

Title: [ChatLog: Recording and Analyzing ChatGPT Across Time](http://arxiv.org/pdf/2304.14106v1)     
Summary: This paper presents a temporal dataset called ChatLog, consisting of two parts - ChatLog-Monthly and ChatLog-Daily, to investigate how ChatGPT's behavior changes over time. The study conducts automatic and human evaluations to provide evidence for the existence of ChatGPT's evolving patterns and extracts its knowledge and linguistic features to analyze its unchanged characteristics over time. The paper also proposes stable features to improve the robustness of a RoBERTa-based detector on new versions of ChatGPT.

Title: [SweCTRL-Mini: a data-transparent Transformer-based large language model for controllable text generation in Swedish](http://arxiv.org/pdf/2304.13994v1)     
Summary: The paper presents SweCTRL-Mini, a large language model for controllable text generation in Swedish. The model is based on the CTRL architecture and can be fine-tuned and used for inference on a single GPU. The authors provide details on the training data and text pre-processing and evaluate the model's performance on discriminative and generative tasks. SweCTRL-Mini is open-source and available for download.

Title: [Controllable Data Augmentation for Context-Dependent Text-to-SQL](http://arxiv.org/pdf/2304.13902v1)     
Summary: The paper proposes a Controllable Data Augmentation method called ConDA to generate interactive questions and corresponding SQL results for context-dependent text-to-SQL. The proposed method enhances the diversity and quality of the augmented data by designing SQL dialogue state, filter method, and grounding model. The experiment shows that ConDA boosts the baseline model and generates high-quality data for SQL template hardness, types, turns, and question consistency.

Title: [Neural Keyphrase Generation: Analysis and Evaluation](http://arxiv.org/pdf/2304.13883v1)     
Summary: This paper focuses on analyzing and evaluating keyphrase generation using neural models. Three models, T5, CatSeq-Transformer, and ExHiRD, were analyzed for their performance and behavior during keyphrase generation. The paper also proposes a novel metric framework, SoftKeyScore, to evaluate keyphrase similarity. The study finds that SoftKeyScore is more suitable than the standard F1 metric for evaluating keyphrases.

Title: [MasonNLP+ at SemEval-2023 Task 8: Extracting Medical Questions, Experiences and Claims from Social Media using Knowledge-Augmented Pre-trained Language Models](http://arxiv.org/pdf/2304.13875v1)     
Summary: The paper describes the MasonNLP+ system developed for SemEval-2023 Task 8, which involves extracting medical questions, experiences, and claims from social media posts. The proposed system was based on language-model-based extraction and ranked third on both leaderboards. The paper also explores the use of domain-specific language models and external knowledge for automatic extraction.

Title: [Transferring Procedural Knowledge across Commonsense Tasks](http://arxiv.org/pdf/2304.13867v1)     
Summary: This paper proposes a framework called LEAP for transferring procedural knowledge across commonsense tasks in a transparent manner. The framework incorporates state-of-the-art modeling architectures, training regimes, and augmentation strategies based on both natural and synthetic stories. To address the lack of densely annotated training data, a robust automatic labeler based on few-shot prompting is devised for enhancing the augmented data. The experiments demonstrate insights into the interplay of different architectures, training regimes, and augmentation strategies. The LEAP's labeler positively impacts out-of-domain datasets, while the resulting dense annotation provides native explainability.

Title: [A Deep Learning Framework for Verilog Autocompletion Towards Design and Verification Automation](http://arxiv.org/pdf/2304.13840v1)     
Summary: The paper proposes a deep learning framework for Verilog autocompletion towards design and verification automation. The framework involves integrating models pretrained on general programming language data and finetuning them on a Verilog dataset of files and snippets obtained from open-source repositories. The proposed framework achieves better BLEU, ROUGE-L, and chrF scores by 9.5%, 6.7%, and 6.9%, respectively, compared to a model trained from scratch.

Title: [Translate to Disambiguate: Zero-shot Multilingual Word Sense Disambiguation with Pretrained Language Models](http://arxiv.org/pdf/2304.13803v1)     
Summary: The paper presents a study on how well Pretrained Language Models (PLMs) capture cross-lingual word sense knowledge with Contextual Word-Level Translation (C-WLT) and introduces a zero-shot approach for Word Sense Disambiguation (WSD) using PLMs. The study shows that as the model size increases, PLMs encode more cross-lingual word sense knowledge and better use context to improve WLT performance. The proposed zero-shot approach outperforms fully supervised baselines on recall for many evaluation languages without additional training or finetuning.

Title: [Fine Tuning with Abnormal Examples](http://arxiv.org/pdf/2304.13783v1)     
Summary: The paper proposes a methodology for pruning datasets in fine-tuning natural language processing models using abnormal examples, leading to better out of sample performance. The authors use the SQUAD dataset and identify 10,500 examples that create a more uniform distribution for training, resulting in improved performance when fine-tuning ELECTRA.

Title: [Evaluating Code Metrics in GitHub Repositories Related to Fake News and Misinformation](http://arxiv.org/pdf/2304.13769v1)     
Summary: The paper evaluates code metrics of Python repositories related to fake news and misinformation to improve awareness and understanding in the research community. The study found that more popular repositories and associated papers tend to have more maintainable code measures, more complex code paths, a larger number of lines of code, a higher Halstead effort, and fewer comments.

Title: [The Internal State of an LLM Knows When its Lying](http://arxiv.org/pdf/2304.13734v1)     
Summary: The paper proposes a method to detect the truthfulness of statements generated by Large Language Models (LLMs) using the LLM's internal state. They use the activation values in the hidden layer of LLM to determine if a statement is true or false. They compose a dataset of true and false statements and train a classifier that outperforms few-shot prompting methods. The paper has practical applicability in enhancing the reliability of LLM-generated content.

</details>
</details>