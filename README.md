
# ChatTodayPaperüìë

Subscribe to the topics you follow, and we'll send you the everyday relevant arxiv papers and summaries to your Email. [Subscription Links](http://chat.yunxiangli.top)

ËÆ¢ÈòÖ‰Ω†ÊâÄÂÖ≥Ê≥®ÁöÑ‰∏ªÈ¢òÔºåÊàë‰ª¨‰ºöÊääÊØèÂ§©Áõ∏ÂÖ≥ÁöÑarxivËÆ∫ÊñáÂíåÊëòË¶ÅÂèëÈÄÅÂà∞‰Ω†ÁöÑEmail„ÄÇ[ËÆ¢ÈòÖÈìæÊé•](http://chat.yunxiangli.top)


<div style="font-size: 1rem;">
  <a href="./README-zh.md">‰∏≠Êñá</a> |
  <a href="./README.md">English</a>   
</div>



<details>
<summary>Fri, 28 Apr 2023</summary>
    
<details>
<summary>Diffusion Model</summary>
    
Title: [Functional Diffusion Maps](http://arxiv.org/pdf/2304.14378v1)     
Summary: This paper introduces the use of Diffusion Maps, a non-linear manifold learning method, for functional data analysis. It compares its performance with the widely used functional PCA method in different simulated and real examples. The paper explains how to extend the multivariate Diffusion Maps method to functional data and highlights its advantages over linear methods when the data do not satisfy their assumptions.

Title: [Fast Sampling of $b$-Matchings and $b$-Edge Covers](http://arxiv.org/pdf/2304.14289v1)     
Summary: The paper proposes an efficient algorithm for sampling $b$-matchings and $b$-edge covers in bounded-degree graphs using the simple Glauber dynamics. The paper also proves spectral independence for a broad class of binary symmetric Holant problems with log-concave signatures, including $b$-matchings, $b$-edge covers, and antiferromagnetic $2$-spin edge models. The algorithm's mixing time is shown to be $O(n \log n)$, which significantly improves upon previous results that only worked for small values of $b$ and had worse running time. The paper's contributions are based on spectral graph theory and diffusion models.

Title: [Learning Neural PDE Solvers with Parameter-Guided Channel Attention](http://arxiv.org/pdf/2304.14118v1)     
Summary: The paper proposes a Channel Attention mechanism guided by PDE Parameter Embeddings (CAPE) component for neural surrogate models and a curriculum learning strategy to learn emulators of physical systems governed by partial differential equations (PDE). CAPE allows neural PDE solvers to adapt to unseen PDE parameters, resulting in consistent and significant improvements over baseline models on a popular PDE benchmark. The paper falls under the category of Diffusion Model and Scientific Machine Learning (SciML).

Title: [Linear and Nonlinear Parareal Methods for the Cahn-Hilliard Equation](http://arxiv.org/pdf/2304.14074v1)     
Summary: This paper proposes linear and nonlinear Parareal methods for efficient time parallel simulation of the Cahn-Hilliard equation. The CH equation is important in a range of applications and requires long simulation times, making parallelization desirable. The proposed methods are evaluated through numerical experiments.

Title: [Localized orthogonal decomposition for a multiscale parabolic stochastic partial differential equation](http://arxiv.org/pdf/2304.14049v1)     
Summary: The paper proposes a multiscale method based on the localized orthogonal decomposition (LOD) technique for a parabolic stochastic partial differential equation with highly oscillatory diffusion and additive noise. The method computes a coarse representation of the elliptic operator enriched by fine-scale information on the diffusion, and optimal order strong convergence is obtained. The paper combines LOD with a Monte-Carlo estimator, and numerical examples confirm the theoretical findings and the computational efficiency of the method.

Title: [Two kinds of numerical algorithms for ultra-slow diffusion equations](http://arxiv.org/pdf/2304.13966v1)     
Summary: The paper presents two numerical algorithms for the ultra-slow (or superslow) diffusion equation in one and two dimensions using Caputo-Hadamard fractional derivative of order $\alpha \in (0,1)$. The schemes use the Riesz fractional derivative and the fractional Laplacian to describe the spatial interaction and are discretized by L2-1$_{\sigma}$ and L1-2 methods. The derived numerical schemes are unconditionally stable with error estimates for all $\alpha \in (0, 1)$ and stable with error estimates for $\alpha \in (0, 0.3738)$. The paper includes illustrative examples that align with the theoretical analysis.

</details>
<details>
<summary>Large Language Models</summary>
    
Title: [Industrial Engineering with Large Language Models: A case study of ChatGPT's performance on Oil & Gas problems](http://arxiv.org/pdf/2304.14354v1)     
Summary: This academic paper discusses the potential of Large Language Models (LLMs) in solving complex problems in the field of industrial engineering, specifically in the context of oil and gas engineering. The limitations of LLM approaches, particularly ChatGPT, are identified and discussed. The paper also presents areas where LLMs are most effective in solving problems in this field.

Title: [The Dark Side of ChatGPT: Legal and Ethical Challenges from Stochastic Parrots and Hallucination](http://arxiv.org/pdf/2304.14347v1)     
Summary: The paper discusses the legal and ethical challenges posed by the emergence of Large Language Models like ChatGPT, particularly due to stochastic parrots and hallucination. It highlights the need for further evolution of the EU regulatory paradigm to mitigate these risks.

Title: [MarsEclipse at SemEval-2023 Task 3: Multi-Lingual and Multi-Label Framing Detection with Contrastive Learning](http://arxiv.org/pdf/2304.14339v1)     
Summary: The paper presents the MarsEclipse system for multi-lingual and multi-label framing detection using a contrastive loss function for fine-tuning large pre-trained language models. The system achieved first place on the official test set and leaderboard for five out of six languages in the SemEval-2023 Task 3 Subtask 2 on Framing Detection. The code is available on GitHub, and the paper details the experimental setup and includes various ablation studies.

Title: [q2d: Turning Questions into Dialogs to Teach Models How to Search](http://arxiv.org/pdf/2304.14318v1)     
Summary: The paper proposes a data generation pipeline, q2d, that generates information-seeking dialogs from questions to teach language models how to search. The pipeline uses a large language model to create conversational versions of question answering datasets and improve query generation models that communicate with external search APIs. The experiments show that the synthesized data achieves comparable performance to human-generated data for query generation and can be used to train dialog models in new domains without existing data. The paper falls under the categories of Large Language Models, Visual Question Answering (VQA), and Data Generation.

Title: [Large Language Models Are State-of-the-Art Evaluators of Code Generation](http://arxiv.org/pdf/2304.14317v1)     
Summary: This paper proposes a new evaluation framework, based on the GPT-3.5, for code generation assessments. The framework addresses the limitations of existing approaches by achieving superior correlations with functional correctness and human preferences, without the need for test oracles or references. The authors evaluate the efficacy of their framework on two different tasks and four programming languages, comparing its performance with the state-of-the-art CodeBERTScore metric, and demonstrate that their framework surpasses CodeBERTScore in delivering high levels of accuracy and consistency across various programming languages and tasks.

Title: [Controlled Text Generation with Natural Language Instructions](http://arxiv.org/pdf/2304.14293v1)     
Summary: This paper presents a framework for controlled text generation called InstructCTG that incorporates various constraints through natural language descriptions and demonstrations. It fine-tunes a pre-trained language model using weakly supervised training data and allows for adaptation to new constraints through few-shot task generalization and in-context learning abilities of instruction-tuned language models. The model is more flexible and has a smaller impact on generation quality and speed compared to existing methods that modify the decoding procedure. This paper falls under the categories of Controlled Text Generation, Large Language Models, and Few-Shot Learning.

Title: [AI, write an essay for me: A large-scale comparison of human-written versus ChatGPT-generated essays](http://arxiv.org/pdf/2304.14276v1)     
Summary: This paper compares human-written argumentative essays to those generated by the ChatGPT AI model. The study found that ChatGPT-generated essays were rated higher in quality than human-written essays and exhibited different linguistic characteristics. The paper argues that educators should incorporate AI models into the education system to free up time for other learning objectives.

Title: [What's in a Name? Evaluating Assembly-Part Semantic Knowledge in Language Models through User-Provided Names in CAD Files](http://arxiv.org/pdf/2304.14275v1)     
Summary: This paper proposes that natural language names used in Computer Aided Design (CAD) software contain valuable domain-specific information that can be used to improve Large Language Models' (LLMs) ability to understand assembly-part relationships. The authors extract a large corpus of natural language part, feature, and document names and show that fine-tuning a pre-trained LLM on this data improves its performance on self-supervised tasks, highlighting the value of text data in the CAD domain. The paper concludes by identifying limitations and calling for further work in multimodal text-geometry models.

Title: [Large Language Models are Strong Zero-Shot Retriever](http://arxiv.org/pdf/2304.14233v1)     
Summary: The paper proposes a method called Language model as Retriever (LameR) that utilizes large language models (LLMs) for zero-shot retrieval. The proposed method augments a query with its potential answers by prompting LLMs with a composition of the query and the query's in-domain candidates. This helps LLM generate more precise answers by pattern imitation or candidate summarization, making the retrieval procedure transparent to the LLM. The paper also suggests using a non-parametric lexicon-based method (e.g., BM25) as the retrieval module to capture query-document overlap in a literal fashion. The proposed method outperformed other state-of-the-art methods on benchmark datasets.

Title: [mPLUG-Owl: Modularization Empowers Large Language Models with Multimodality](http://arxiv.org/pdf/2304.14178v1)     
Summary: The paper introduces mPLUG-Owl, a training paradigm that equips LLMs with multi-modal abilities through modularized learning of foundation LLM, a visual knowledge module, and a visual abstractor module. The approach can support multiple modalities and facilitate diverse unimodal and multimodal abilities through modality collaboration. The model outperforms existing multi-modal models and demonstrates impressive instruction and visual understanding ability, multi-turn conversation ability, and knowledge reasoning ability. The paper is available along with code, pre-trained model, instruction-tuned models, and evaluation set on GitHub.

Title: [Origin Tracing and Detecting of LLMs](http://arxiv.org/pdf/2304.14072v1)     
Summary: The paper proposes a method to trace the origin of large language models (LLMs) and detect whether a given text context is generated by an AI system. The method is based on contrastive features between LLMs and extracts model-wise features to trace the text origins. The proposed approach works under both white-box and black-box settings and requires limited data compared to supervised learning methods. The paper provides valuable observations based on experimental results and calls for ethical concerns of LLM providers. The code and data are released as a toolkit and benchmark for future AI origin tracing and detecting studies.

Title: [SweCTRL-Mini: a data-transparent Transformer-based large language model for controllable text generation in Swedish](http://arxiv.org/pdf/2304.13994v1)     
Summary: The paper presents SweCTRL-Mini, a large language model for controllable text generation in Swedish. The model is based on the CTRL architecture and can be fine-tuned and used for inference on a single GPU. The authors provide details on the training data and text pre-processing and evaluate the model's performance on discriminative and generative tasks. SweCTRL-Mini is open-source and available for download.

Title: [Federated Prompting and Chain-of-Thought Reasoning for Improving LLMs Answering](http://arxiv.org/pdf/2304.13911v1)     
Summary: The paper proposes Fed-SP-SC and Fed-DP-CoT methods to enhance answer precision in frequently asked questions posed by distributed users using cloud-based Large Language Models (LLMs). The methods involve improving distributed synonymous questions using Self-Consistency and Chain-of-Thought techniques. Through extensive experiments, the proposed methods are demonstrated to significantly enhance question accuracy by fully exploring the synonymous nature of the questions and the consistency of the answers.

Title: [Is a prompt and a few samples all you need? Using GPT-4 for data augmentation in low-resource classification tasks](http://arxiv.org/pdf/2304.13861v1)     
Summary: The paper explores using GPT-4 and ChatGPT to augment small labeled datasets with synthetic data via simple prompts in low-resource classification tasks. They compare two augmentation strategies and find that synthetic data aids in identifying rare classes but human-annotated data exhibits a stronger predictive power in most cases. They also observe strong zero-shot performance across all tasks using GPT-4 and ChatGPT.

Title: [Translate to Disambiguate: Zero-shot Multilingual Word Sense Disambiguation with Pretrained Language Models](http://arxiv.org/pdf/2304.13803v1)     
Summary: The paper presents a study on how well Pretrained Language Models (PLMs) capture cross-lingual word sense knowledge with Contextual Word-Level Translation (C-WLT) and introduces a zero-shot approach for Word Sense Disambiguation (WSD) using PLMs. The study shows that as the model size increases, PLMs encode more cross-lingual word sense knowledge and better use context to improve WLT performance. The proposed zero-shot approach outperforms fully supervised baselines on recall for many evaluation languages without additional training or finetuning.

Title: [The Internal State of an LLM Knows When its Lying](http://arxiv.org/pdf/2304.13734v1)     
Summary: The paper proposes a method to detect the truthfulness of statements generated by Large Language Models (LLMs) using the LLM's internal state. They use the activation values in the hidden layer of LLM to determine if a statement is true or false. They compose a dataset of true and false statements and train a classifier that outperforms few-shot prompting methods. The paper has practical applicability in enhancing the reliability of LLM-generated content.

Title: [ChatGPT is all you need to decolonize sub-Saharan Vocational Education](http://arxiv.org/pdf/2304.13728v1)     
Summary: This paper argues for the use of Large Language Models in vocational and technical training to modernize educational systems in sub-Saharan African countries. The authors propose an educational policy framework to prioritize vocational education over academic education. Additionally, they provide historical examples of countries successfully implementing such policies, highlighting the potential for socioeconomic transformation.

Title: [Extracting Structured Seed-Mediated Gold Nanorod Growth Procedures from Literature with GPT-3](http://arxiv.org/pdf/2304.13846v1)     
Summary: This paper presents an approach using the GPT-3 language model to extract structured multi-step seed-mediated growth procedures and outcomes for gold nanorods from unstructured scientific literature text with an accuracy of 86%. By developing a tool to extract relevant structured data in an automated, high-throughput manner, the authors aim to better understand the pathways for controlling the shape and optical properties of gold nanorods.

Title: [Text-to-Audio Generation using Instruction-Tuned LLM and Latent Diffusion Model](http://arxiv.org/pdf/2304.13731v1)     
Summary: The paper presents a novel approach, TANGO, for text-to-audio (TTA) generation, utilizing an instruction-tuned LLM as the text encoder and a latent diffusion model (LDM) for audio generation. The proposed method outperforms the state-of-the-art AudioLDM and stays comparable on most metrics on the AudioCaps test set, despite being trained on a smaller dataset and keeping the text encoder frozen. The improvement in performance may also be attributed to the adoption of audio pressure level-based sound mixing for training set augmentation.

</details>
<details>
<summary>Image Reconstruction</summary>
    
Title: [A Probabilistic Attention Model with Occlusion-aware Texture Regression for 3D Hand Reconstruction from a Single RGB Image](http://arxiv.org/pdf/2304.14299v1)     
Summary: 
This paper proposes a novel probabilistic model for 3D hand reconstruction from a single RGB image. The model-based network estimates the prior probability distribution of joints and vertices, while the Attention-based Mesh Vertices Uncertainty Regression (AMVUR) model captures dependencies among vertices and correlation between joints and vertices. An occlusion-aware Hand Texture Regression model is also proposed for high-fidelity texture reconstruction. The proposed model achieves state-of-the-art accuracy in 3D hand and texture reconstruction from a single image in both supervised and weakly-supervised scenarios.

Title: [Contour Completion by Transformers and Its Application to Vector Font Data](http://arxiv.org/pdf/2304.13988v1)     
Summary: The paper proposes a Transformer-based method to solve the contour completion task where the missing points in a contour sequence need to be generated to complete the contour. The paper applies this method to vector font data and shows the results of typeface contour completion.

Title: [Optimization-Inspired Cross-Attention Transformer for Compressive Sensing](http://arxiv.org/pdf/2304.13986v1)     
Summary: The paper proposes an Optimization-inspired Cross-attention Transformer (OCT) module for compressive sensing (CS) in image reconstruction. The OCT is designed as an iterative process that improves visual quality with fewer parameters and reduces feature information loss. The OCT is integrated with a lightweight OCT-based Unfolding Framework (OCTUF) that achieves superior performance in CS compared to other methods while training lower complexity. The paper highlights a novel Dual Cross Attention sub-module that introduces multi-channel inertia forces and increases memory effect by a cross attention mechanism between adjacent iterations.

Title: [MIPI 2023 Challenge on RGB+ToF Depth Completion: Methods and Results](http://arxiv.org/pdf/2304.13916v1)     
Summary: This paper presents the results of an RGB+sparse ToF depth completion competition aimed at encouraging research in depth completion from RGB images and sparse ToF measurements. The paper discusses the strengths and weaknesses of the top-performing methods and their implications for future research in this area. The competition provided a standardized dataset and evaluation metrics to compare the accuracy of different approaches.

Title: [Do SSL Models Have D√©j√† Vu? A Case of Unintended Memorization in Self-supervised Learning](http://arxiv.org/pdf/2304.13850v1)     
Summary: The paper investigates the unintended memorization of SSL models, which can lead to the reconstruction of visual elements from a single image. The authors show that this phenomenon, referred to as "d√©j√† vu memorization," is common to different SSL algorithms and cannot be detected by conventional evaluation techniques. This reveals previously unknown privacy risks in SSL models and suggests potential mitigation strategies.

Title: [A Majorization-Minimization Gauss-Newton Method for 1-Bit Matrix Completion](http://arxiv.org/pdf/2304.13940v1)     
Summary: This paper proposes a novel method for 1-bit matrix completion using the majorization-minimization principle and Gauss-Newton method. The proposed method is compared to existing methods and is shown to output more accurate estimates, often faster, and less sensitive to the spikiness of the underlying matrix.

Title: [Automated Whole Slide Imaging for Label-Free Histology using Photon Absorption Remote Sensing Microscopy](http://arxiv.org/pdf/2304.13736v1)     
Summary: The paper proposes an automated whole slide imaging platform using Photon Absorption Remote Sensing microscopy for label-free histology. The system provides high-quality and high-resolution images of unstained tissue samples, while preserving the samples for other staining techniques. The study demonstrates the potential of this approach in label-free H&E emulation as well.

</details>
<details>
<summary>Medical Image</summary>
    
Title: [Learning Absorption Rates in Glucose-Insulin Dynamics from Meal Covariates](http://arxiv.org/pdf/2304.14300v1)     
Summary: The paper proposes a neural network approach to learn absorption rates in glucose-insulin dynamics from meal covariates. The approach is based on predicting an individual's glucose absorption rate using a neural network, which is then used as a control function in a differential equation of glucose dynamics, allowing for end-to-end training. The method is able to accurately approximate true absorption rates on simulated data, which can pave the way for personalized glucose dynamics models for individuals.

Title: [Deep Imitation Learning for Automated Drop-In Gamma Probe Manipulation](http://arxiv.org/pdf/2304.14294v1)     
Summary: This paper proposes the use of deep imitation learning to create an end-to-end vision-based gamma probe manipulation agent for automated radioactive node detection during sentinel lymph node biopsy. The proposed approach uses simulation data to train the agent, and evaluation results showed promising results for further improvement and extension to hardware setup.

Title: [Towards Medical Artificial General Intelligence via Knowledge-Enhanced Multimodal Pretraining](http://arxiv.org/pdf/2304.14204v1)     
Summary: This paper proposes a new paradigm called Medical-knOwledge-enhanced mulTimOdal pretRaining (MOTOR) for achieving Medical Artificial General Intelligence (MAGI) via knowledge-enhanced multimodal pretraining. The proposed method combines general and specific medical knowledge to boost the general pretraining process and learns compact representations from pretraining radiographic data for better cross-modal alignment. The method unifies the understanding and generation of medical tasks and constructs a comprehensive medical multimodal benchmark including tasks such as chest x-ray report generation and medical VQA. Experimental results on the benchmark demonstrate promising performance with excellent interpretability. Thus, this work makes a significant stride towards realizing MAGI.

Title: [Design of a multimodal device to improve well-being of autistic workers interacting with collaborative robots](http://arxiv.org/pdf/2304.14191v1)     
Summary: The paper describes the design and development of (A)MICO, a multimodal device aimed to improve the user experience of ASD workers interacting with collaborative robots in production lines. The device proposes a new intuitive mode of communication in which information about the cobot activity is transferred through acoustic and visual feedback. The design process involves a co-design process with users with high functioning autism to analyze the system from different perspectives, and Design for All principles were taken into consideration to develop a human-friendly device.

Title: [COSST: Multi-organ Segmentation with Partially Labeled Datasets Using Comprehensive Supervisions and Self-training](http://arxiv.org/pdf/2304.14030v1)     
Summary: This paper proposes a novel approach, called COSST, for multi-organ segmentation using partially labeled medical image datasets. The approach integrates three supervision signals, including pseudo-labels obtained via self-training, to achieve improved segmentation performance. The proposed method outperforms state-of-the-art partial-label segmentation methods on various segmentation tasks with different training data sizes.

Title: [Mimic-IV-ICD: A new benchmark for eXtreme MultiLabel Classification](http://arxiv.org/pdf/2304.13998v1)     
Summary: In this paper, the authors propose a public benchmark suite for ICD-10 and ICD-9 coding using a large EHR dataset derived from MIMIC-IV. They implement and compare several popular methods for ICD coding prediction tasks to standardize data preprocessing and establish a comprehensive ICD coding benchmark dataset. This approach fosters reproducibility and model comparison, accelerating progress toward employing automated ICD coding in future studies. Furthermore, they provide open-source code that offers easy access to data processing steps, benchmark creation, and experiment replication for those with MIMIC-IV access.

Title: [SkinSAM: Empowering Skin Cancer Segmentation with Segment Anything Model](http://arxiv.org/pdf/2304.13973v1)     
Summary: The paper presents SkinSAM, a fine-tuned model based on the Segment Anything Model for skin cancer segmentation on HAM10000 dataset. The model exhibited outstanding segmentation performance, with the finetuned model showing the greatest improvement. The research demonstrates the potential of adapting SAM to medical image segmentation tasks.

Title: [GazeSAM: What You See is What You Segment](http://arxiv.org/pdf/2304.13844v1)     
Summary: The paper proposes a collaborative human-computer interaction system called GazeSAM that utilizes eye-tracking technology and the Segment Anything Model (SAM) to automate medical image segmentation. The system enables radiologists to collect segmentation masks simply by looking at the region of interest during image diagnosis. GazeSAM tracks radiologists' eye movement and utilizes the eye-gaze data as the input prompt for SAM, which generates the segmentation mask in real-time. This study is the first work to leverage the power of eye-tracking technology and SAM to enhance the efficiency of daily clinical practice.

Title: [Customized Segment Anything Model for Medical Image Segmentation](http://arxiv.org/pdf/2304.13785v1)     
Summary: The paper proposes SAMed, a model for medical image segmentation built upon the Segment Anything Model. It applies the low-rank-based finetuning strategy and the AdamW optimizer to achieve successful convergence and lower loss. SAMed achieved competitive results on the Synapse multi-organ segmentation dataset with marginal deployment and storage costs. The paper introduces a new paradigm of customizing large-scale models for medical image segmentation.

Title: [Temporal and geographic analysis of the Hydroxychloroquine controversy in the French Twittosphere](http://arxiv.org/pdf/2304.14075v1)     
Summary: The paper discusses the controversies surrounding the use of Hydroxychloroquine as a treatment for COVID-19 and its spread on the French-speaking Twitter sphere. The study analyzes the geographic dimension of the debate, information flow, and Twitter's retweet hypergraph. Tensor decomposition of hashtag use concludes that the debates are linked to local political choices. The study finds its center in Europe, particularly France, while francophone Africa has a lower participation in the debates due to early acceptance of Hydroxychloroquine and rejection of WHO recommendations.

Title: [Automatically Segment the Left Atrium and Scars from LGE-MRIs Using a Boundary-focused nnU-Net](http://arxiv.org/pdf/2304.14071v1)     
Summary: The paper proposes an automated method for segmenting the left atrial cavity and scars in late gadolinium enhancement magnetic resonance imaging (LGE-MRI) scans. The approach uses nnU-Net as the baseline model and employs a boundary-focused loss function to improve boundary prediction accuracy. In addition, a distance map transformation of the predicted LA boundary is used to predict scar locations. The method achieves superior results on the LAScarQS 2022 dataset, with 88.98% and 64.08% Dice coefficient for LA cavity and scar segmentation, respectively.

Title: [Precise Few-shot Fat-free Thigh Muscle Segmentation in T1-weighted MRI](http://arxiv.org/pdf/2304.14053v1)     
Summary: This paper proposes a few-shot segmentation framework for precise thigh muscle segmentation in T1-weighted MRI images, excluding intra-muscular fat (IMF). The framework uses a novel pseudo-label correction and evaluation scheme, together with a noise robust loss to exploit high certainty areas. With only 1% of fine-annotated training data, the proposed method achieves comparable performance with fully supervised methods.

Title: [A Deep Registration Method for Accurate Quantification of Joint Space Narrowing Progression in Rheumatoid Arthritis](http://arxiv.org/pdf/2304.13938v1)     
Summary: This paper proposes a deep intra-subject rigid registration network to automatically quantify joint space narrowing progression in rheumatoid arthritis through image registration in radiographic images. The proposed method offers sub-pixel level accuracy and is equipped with immune to noise, rotation, and scaling of joints. The method provides loss visualization, aiding radiologists and rheumatologists to assess quantification reliability, with implications for future clinical applications.

Title: [Automated Classification of Stroke Blood Clot Origin using Whole-Slide Digital Pathology Images](http://arxiv.org/pdf/2304.13775v1)     
Summary: The paper presents a novel methodology to classify the origin of blood clots in ischemic stroke patients using whole-slide digital pathology images. The approach integrates data from multiple cutting-edge computer vision models and achieves an accuracy of 94.24% with the SwinTransformerV2 model outperforming all others. The proposed method offers a promising solution for improved diagnosis and management of ischemic stroke.

Title: [Phagocytosis Unveiled: A Scalable and Interpretable Deep learning Framework for Neurodegenerative Disease Analysis](http://arxiv.org/pdf/2304.13764v1)     
Summary: The paper presents a scalable and interpretable deep learning framework for analyzing phagocytic activity in neurodegenerative diseases. The pipeline includes a data quality verification module and an explainable cell segmentation module for improved interpretability. The framework is applied to analyze microglial cell phagocytosis in frontotemporal dementia, and the authors release an open-source pipeline and dataset for future research.

Title: [AIRIVA: A Deep Generative Model of Adaptive Immune Repertoires](http://arxiv.org/pdf/2304.13737v1)     
Summary: The paper presents a generative model called AIRIVA, which learns a low-dimensional, interpretable, and compositional representation of TCR repertoires from immune system data to disentangle systematic effects in repertoires. The model is applied to two infectious disease case-studies, COVID-19 and the Herpes Simplex Virus (HSV), and shows promising results in identifying disease-specific TCRs.

Title: [Automated Whole Slide Imaging for Label-Free Histology using Photon Absorption Remote Sensing Microscopy](http://arxiv.org/pdf/2304.13736v1)     
Summary: The paper proposes an automated whole slide imaging platform using Photon Absorption Remote Sensing microscopy for label-free histology. The system provides high-quality and high-resolution images of unstained tissue samples, while preserving the samples for other staining techniques. The study demonstrates the potential of this approach in label-free H&E emulation as well.

Title: [Ensemble CNNs for Breast Tumor Classification](http://arxiv.org/pdf/2304.13727v1)     
Summary: The paper presents an ensemble mechanism using state-of-the-art classification networks (XceptionNet, DenseNet, EfficientNet) for breast tumor classification among mammographic images. The proposed approach achieved an accuracy of 88% with a 5% improvement over individual models.

Title: [Prediction of brain tumor recurrence location based on multi-modal fusion and nonlinear correlation learning](http://arxiv.org/pdf/2304.13725v1)     
Summary: This paper proposes a deep learning-based brain tumor recurrence location prediction network that segments present brain tumor and predicts its future recurrence location. The method uses transfer learning, multi-modal fusion, and nonlinear correlation learning to extract effective features. The proposed method is effective in predicting brain tumor recurrence location from limited datasets.

</details>
<details>
<summary>Image Classification</summary>
    
Title: [Vision Conformer: Incorporating Convolutions into Vision Transformer Layers](http://arxiv.org/pdf/2304.13991v1)     
Summary: This paper proposes a new model called Vision Conformer (ViC) which incorporates convolutional layers within Vision Transformer (ViT) in order to address the lack of inductive bias towards image structures. ViC replaces the Multi-Layer Perceptron (MLP) in a ViT layer with a CNN and reconstructs the image data after self-attention using a reverse embedding layer. The paper demonstrates through evaluation that the use of convolutional layers improves the classification ability of ViT.

Title: [Human-machine knowledge hybrid augmentation method for surface defect detection based few-data learning](http://arxiv.org/pdf/2304.13963v1)     
Summary: The paper proposes a human-machine knowledge hybrid augmentation method for surface defect detection based on few-data learning. The proposed method utilizes experts' knowledge of abnormality to create data with rich features, positions, sizes, and backgrounds, which can be used as prior knowledge for the model. The method was evaluated on the magnetic tile dataset and achieved better results than the traditional augmentation method, demonstrating its feasibility and effectiveness in few-data industrial defect detection.

Title: [UCF: Uncovering Common Features for Generalizable Deepfake Detection](http://arxiv.org/pdf/2304.13949v1)     
Summary: The paper proposes a disentanglement framework that uncovers common forgery features to address the overfitting issue in deepfake detection. It employs a multi-task learning strategy and contrastive regularization technique to encourage the disentanglement of specific and common forgery features. The proposed framework outperforms current state-of-the-art methods in generalizable deepfake detection.

Title: [CNN based IoT Device Identification](http://arxiv.org/pdf/2304.13894v1)     
Summary: The paper proposes a CNN-based IoT device identification method to detect vulnerabilities in IoT devices. The study uses the Aalto dataset to identify and classify these devices based on the features obtained from the images. This paper falls under the category of Image Classification and CNNs.

Title: [Deep Learning Techniques for Hyperspectral Image Analysis in Agriculture: A Review](http://arxiv.org/pdf/2304.13880v1)     
Summary: This academic paper focuses on the use of deep learning techniques in analyzing hyperspectral images in agriculture. The paper discusses the high redundancy of spectral bands and limited training samples that make the classification of HSI a complex task. The authors review and evaluate the performance of various deep learning approaches, such as Autoencoders, Convolutional Neural Networks, Recurrent Neural Networks, and Generative Adversarial Networks, on well-known land cover datasets. The paper concludes that deep learning techniques show promising results in HSI analysis, especially in agriculture.

Title: [Categorising Products in an Online Marketplace: An Ensemble Approach](http://arxiv.org/pdf/2304.13852v1)     
Summary: This paper proposes an ensemble approach for categorizing products in an online marketplace using a combination of XGBoost and k-nearest neighbours models. The approach separately predicts categories, subcategories, and colors for each product and combines the results for an F1-score of 0.82.

Title: [Distance Weighted Supervised Learning for Offline Interaction Data](http://arxiv.org/pdf/2304.13774v1)     
Summary: The paper introduces a new supervised learning method called Distance Weighted Supervised Learning (DWSL) for learning goal-conditioned policies from offline data. DWSL models the distribution of time-steps between states in data to approximate shortest path distances and extract policies. The method bridges the gap between imitation learning and offline goal-conditioned reinforcement learning. The paper shows that DWSL outperforms prior goal-conditioned imitation learning and reinforcement learning algorithms in high-dimensional image domains. The code and visualizations are available at the provided link.

Title: [Automated Classification of Stroke Blood Clot Origin using Whole-Slide Digital Pathology Images](http://arxiv.org/pdf/2304.13775v1)     
Summary: The paper presents a novel methodology to classify the origin of blood clots in ischemic stroke patients using whole-slide digital pathology images. The approach integrates data from multiple cutting-edge computer vision models and achieves an accuracy of 94.24% with the SwinTransformerV2 model outperforming all others. The proposed method offers a promising solution for improved diagnosis and management of ischemic stroke.

Title: [Ensemble CNNs for Breast Tumor Classification](http://arxiv.org/pdf/2304.13727v1)     
Summary: The paper presents an ensemble mechanism using state-of-the-art classification networks (XceptionNet, DenseNet, EfficientNet) for breast tumor classification among mammographic images. The proposed approach achieved an accuracy of 88% with a 5% improvement over individual models.

</details>
<details>
<summary>Image Registration</summary>
    
Title: [A Deep Registration Method for Accurate Quantification of Joint Space Narrowing Progression in Rheumatoid Arthritis](http://arxiv.org/pdf/2304.13938v1)     
Summary: This paper proposes a deep intra-subject rigid registration network to automatically quantify joint space narrowing progression in rheumatoid arthritis through image registration in radiographic images. The proposed method offers sub-pixel level accuracy and is equipped with immune to noise, rotation, and scaling of joints. The method provides loss visualization, aiding radiologists and rheumatologists to assess quantification reliability, with implications for future clinical applications.

</details>
<details>
<summary>Reinforcement learning</summary>
    
Title: [SMAT: A Self-Reinforcing Framework for Simultaneous Mapping and Tracking in Unbounded Urban Environments](http://arxiv.org/pdf/2304.14356v1)     
Summary: The paper introduces the SMAT (Simultaneous Mapping and Tracking) framework for robots to construct a reliable map online and navigate in unbounded and changing environments. The framework integrates dynamic object detection and tracking with static mapping using a self-reinforcing mechanism, promoting mutual improvement of mapping and tracking performance. The experiments demonstrate the framework's effectiveness in real-world applications, achieving successful long-range navigation and mapping in urban environments using LiDAR, CPU-only onboard computer, and GPS.

Title: [A Best-of-Both-Worlds Algorithm for Constrained MDPs with Long-Term Constraints](http://arxiv.org/pdf/2304.14326v1)     
Summary: The paper presents a best-of-both-worlds algorithm for constrained Markov decision processes with long-term constraints, where the learner aims to maximize reward while satisfying the constraints during the learning process. The proposed algorithm can handle scenarios where rewards and constraints are selected stochastically or adversarially, without requiring knowledge of the underlying process. The algorithm achieves state-of-the-art regret and constraint violation bounds for settings where constraints are stochastic and provides guarantees for the first time in scenarios where they are adversarial.

Title: [Preference Inference from Demonstration in Multi-objective Multi-agent Decision Making](http://arxiv.org/pdf/2304.14126v1)     
Summary: The paper proposes an algorithm for inferring linear preference weights in multi-objective decision-making problems using optimal or near-optimal demonstrations. The algorithm is evaluated in three environments and compared to two baseline methods, showing significant improvements in time requirements and accuracy of the inferred preferences. The authors plan to evaluate the algorithm in a multi-agent system.

Title: [Inferring Preferences from Demonstrations in Multi-objective Reinforcement Learning: A Dynamic Weight-based Approach](http://arxiv.org/pdf/2304.14115v1)     
Summary: This paper proposes a Dynamic Weight-based Preference Inference (DWPI) algorithm that can infer the preferences of agents acting in multi-objective decision-making problems based on observed behavior trajectories in the environment. The proposed method shows significant improvement compared to two existing preference inference methods in terms of both time requirements and accuracy of inferred preferences, and maintains its performance when inferring preferences for sub-optimal behavior demonstrations.

Title: [SocNavGym: A Reinforcement Learning Gym for Social Navigation](http://arxiv.org/pdf/2304.14102v1)     
Summary: The paper introduces SocNavGym, a simulation environment for social navigation that enables the development of intelligent social agents using reinforcement learning algorithms. The environment can generate a wide range of social navigation scenarios and can be configured to work with different hand-crafted and data-driven social reward signals. The paper also includes a case study where a Dueling-DQN agent is trained to learn social-navigation policies using SocNavGym, and the results show improved social compliance compared to a heuristic-based reward function.

Title: [A Distributed Online Optimization Strategy for Cooperative Robotic Surveillance](http://arxiv.org/pdf/2304.14016v1)     
Summary: This paper proposes a distributed algorithm for controlling a team of cooperating robots to protect a target from intruders. The algorithm utilizes an online optimization problem within a distributed aggregative framework. The defending robots determine their positions based on the relative position between the intruders and the target, their contribution to the team barycenter, and collisions with other robots. The effectiveness of the algorithm is validated through simulations and experiments on a team of cooperating quadrotors.

Title: [Level Assembly as a Markov Decision Process](http://arxiv.org/pdf/2304.13922v1)     
Summary: The paper presents an approach to generate levels for players in games by formulating the problem as a Markov Decision Process (MDP) and using adaptive dynamic programming (ADP) to solve the MDP before assembling a level. The approach adapts to the player's performance and preferences and was tested with two case studies, outperforming two baselines. The paper also experiments with player proxies and shows that a simple modification prior to running ADP results in quick adaptation. By using ADP, the approach produces a dynamic progression of levels that adapts to the player.

Title: [Decision Making for Autonomous Vehicles](http://arxiv.org/pdf/2304.13908v1)     
Summary: This academic paper focuses on decision making for autonomous vehicles in roundabouts using reinforcement learning. The paper introduces different decision-making models such as Markov Decision Processes (MDP), Partially Observable Markov Decision Processes (POMDP), Object Oriented Partially Observable Markov Decision Process (OOPOMDP), and the Partially Observable Monte-Carlo Planning algorithm (POMCP). The paper formulates the decision-making problem as a POMDP and presents a penalty function, policy prediction, and augmented objective state to improve decision-making. Simulations are used to demonstrate the effectiveness of the proposed method.

Title: [Discovering Object-Centric Generalized Value Functions From Pixels](http://arxiv.org/pdf/2304.13892v1)     
Summary: The paper introduces a method for discovering object-centric generalized value functions from pixels using deep reinforcement learning. The approach translates meaningful object features to temporally coherent "question" functions and leverages the subsequent learned general value functions for control. The paper compares the approach with state-of-the-art techniques and shows competitive performance in both stationary and non-stationary settings. Through qualitative analysis, the paper shows that the learned representations are interpretable and centered around objects that are invariant to changes across tasks, facilitating fast adaptation.

Title: [Surrogate Assisted Generation of Human-Robot Interaction Scenarios](http://arxiv.org/pdf/2304.13787v1)     
Summary: This paper proposes a method for generating diverse scenarios for evaluating human-robot interaction systems by augmenting scenario generation with surrogate models that can predict both human and robot behaviors, thus efficiently synthesizing challenging scenarios without simulating robot policies and human actions. The proposed method is demonstrated in shared control teleoperation and shared workspace collaboration tasks, with reproducible failures in real-world interactions.

Title: [Distance Weighted Supervised Learning for Offline Interaction Data](http://arxiv.org/pdf/2304.13774v1)     
Summary: The paper introduces a new supervised learning method called Distance Weighted Supervised Learning (DWSL) for learning goal-conditioned policies from offline data. DWSL models the distribution of time-steps between states in data to approximate shortest path distances and extract policies. The method bridges the gap between imitation learning and offline goal-conditioned reinforcement learning. The paper shows that DWSL outperforms prior goal-conditioned imitation learning and reinforcement learning algorithms in high-dimensional image domains. The code and visualizations are available at the provided link.

Title: [Exploring the flavor structure of quarks and leptons with reinforcement learning](http://arxiv.org/pdf/2304.14176v1)     
Summary: The paper proposes a method to use reinforcement learning to explore the flavor structure of quarks and leptons based on a policy-based algorithm for models with $U(1)$ symmetry. The agent trained on the $U(1)$ charges of quarks and leptons identifies 21 models consistent with experimentally measured masses and mixing angles. The paper predicts specific values of effective mass for neutrinoless double beta decay and leptonic CP violation through an autonomous behavior of the agent.

Title: [Adaptation to Misspecified Kernel Regularity in Kernelised Bandits](http://arxiv.org/pdf/2304.13830v1)     
Summary: The paper titled "Adaptation to Misspecified Kernel Regularity in Kernelised Bandits" discusses the adaptivity of learning algorithms to the regularity of associated kernel functions in continuum-armed bandit problems. The paper derives an adaptivity lower bound and connects the statistical difficulty for adaptivity in three fundamental types of function spaces: RKHS, Sobolev space, and H\"older space. This paper falls under the categories of Reinforcement learning and Theory.

</details>
<details>
<summary>Image Segmentation</summary>
    
Title: [Analogy-Forming Transformers for Few-Shot 3D Parsing](http://arxiv.org/pdf/2304.14382v1)     
Summary: The paper presents a model called Analogical Networks that can segment 3D object scenes using few-shot learning. The model retrieves related scenes from memory and predicts analogous part structures for the input scene, conditioning on the appropriate set of memories. Analogical Networks outperforms state-of-the-art 3D segmentation transformers in few-shot settings and successfully segments instances of novel object categories by expanding its memory.

Title: [Zero-shot Unsupervised Transfer Instance Segmentation](http://arxiv.org/pdf/2304.14376v1)     
Summary: The paper introduces a framework called Zero-shot Unsupervised Transfer Instance Segmentation (ZUTIS) that can perform instance and semantic segmentations without requiring instance-level or pixel-level annotations. The model can also perform zero-shot transfer without assuming access to a target data distribution. The proposed framework achieves state-of-the-art performance on both instance and semantic segmentation tasks compared to previous unsupervised methods.

Title: [Instance Segmentation in the Dark](http://arxiv.org/pdf/2304.14298v1)     
Summary: This paper focuses on improving instance segmentation in low-light conditions. The proposed method includes an adaptive weighted downsampling layer, convolutional block, and disturbance suppression learning to reduce feature noise and improve image quality. Additionally, the use of high-bit-depth RAW images is explored for better preservation of scene information. A low-light RAW synthetic pipeline is used to generate realistic data for training, and a real-world low-light instance segmentation dataset is captured for further research. The proposed method achieves higher accuracy than state-of-the-art competitors in very low light conditions.

Title: [EDAPS: Enhanced Domain-Adaptive Panoptic Segmentation](http://arxiv.org/pdf/2304.14291v1)     
Summary: The paper proposes EDAPS, a novel architecture for domain-adaptive panoptic segmentation. EDAPS uses a shared, domain-robust transformer encoder, and task-specific decoders tailored for both domain-adaptive semantic and instance segmentation. The implementation of EDAPS improves the state-of-the-art performance for panoptic segmentation UDA by a large margin on challenging benchmarks. The paper falls under the categories of Image Segmentation and Domain Generalization/Adaptation.

Title: [Human Semantic Segmentation using Millimeter-Wave Radar Sparse Point Clouds](http://arxiv.org/pdf/2304.14132v1)     
Summary: The paper proposes a framework for human semantic segmentation on sparse millimeter-wave radar point clouds using graph structure and topological features. The framework includes a global and sequential feature-extracting module, an efficient loss function for better training and segmentation results, and achieves state-of-the-art performance on both custom and benchmark datasets. The paper falls under the categories of point cloud, image segmentation, graph neural networks, and transformer.

Title: [COSST: Multi-organ Segmentation with Partially Labeled Datasets Using Comprehensive Supervisions and Self-training](http://arxiv.org/pdf/2304.14030v1)     
Summary: This paper proposes a novel approach, called COSST, for multi-organ segmentation using partially labeled medical image datasets. The approach integrates three supervision signals, including pseudo-labels obtained via self-training, to achieve improved segmentation performance. The proposed method outperforms state-of-the-art partial-label segmentation methods on various segmentation tasks with different training data sizes.

Title: [A Review of Panoptic Segmentation for Mobile Mapping Point Clouds](http://arxiv.org/pdf/2304.13980v1)     
Summary: The paper reviews the state of panoptic segmentation of outdoor mobile-mapping data, which is the combined task of assigning semantic classes and separating them into object instances. The paper sets up a modular pipeline for comprehensive experiments and provides the first public dataset for the task, extending NPM3D dataset to include instance labels.

Title: [Adaptive-Mask Fusion Network for Segmentation of Drivable Road and Negative Obstacle With Untrustworthy Features](http://arxiv.org/pdf/2304.13979v1)     
Summary: The paper proposes an Adaptive-Mask Fusion Network for segmentation of drivable road and negative obstacles with untrustworthy features. The proposed network uses adaptive-weight masks to fuse features from RGB and depth images with inconsistency to overcome the issue caused by untrustworthy features. The authors also release a large-scale RGB-depth dataset with manually-labeled ground truth for drivable roads and negative obstacles segmentation. The proposed network achieves state-of-the-art performance compared to other networks.

Title: [SkinSAM: Empowering Skin Cancer Segmentation with Segment Anything Model](http://arxiv.org/pdf/2304.13973v1)     
Summary: The paper presents SkinSAM, a fine-tuned model based on the Segment Anything Model for skin cancer segmentation on HAM10000 dataset. The model exhibited outstanding segmentation performance, with the finetuned model showing the greatest improvement. The research demonstrates the potential of adapting SAM to medical image segmentation tasks.

Title: [GazeSAM: What You See is What You Segment](http://arxiv.org/pdf/2304.13844v1)     
Summary: The paper proposes a collaborative human-computer interaction system called GazeSAM that utilizes eye-tracking technology and the Segment Anything Model (SAM) to automate medical image segmentation. The system enables radiologists to collect segmentation masks simply by looking at the region of interest during image diagnosis. GazeSAM tracks radiologists' eye movement and utilizes the eye-gaze data as the input prompt for SAM, which generates the segmentation mask in real-time. This study is the first work to leverage the power of eye-tracking technology and SAM to enhance the efficiency of daily clinical practice.

Title: [Customized Segment Anything Model for Medical Image Segmentation](http://arxiv.org/pdf/2304.13785v1)     
Summary: The paper proposes SAMed, a model for medical image segmentation built upon the Segment Anything Model. It applies the low-rank-based finetuning strategy and the AdamW optimizer to achieve successful convergence and lower loss. SAMed achieved competitive results on the Synapse multi-organ segmentation dataset with marginal deployment and storage costs. The paper introduces a new paradigm of customizing large-scale models for medical image segmentation.

Title: [Automatically Segment the Left Atrium and Scars from LGE-MRIs Using a Boundary-focused nnU-Net](http://arxiv.org/pdf/2304.14071v1)     
Summary: The paper proposes an automated method for segmenting the left atrial cavity and scars in late gadolinium enhancement magnetic resonance imaging (LGE-MRI) scans. The approach uses nnU-Net as the baseline model and employs a boundary-focused loss function to improve boundary prediction accuracy. In addition, a distance map transformation of the predicted LA boundary is used to predict scar locations. The method achieves superior results on the LAScarQS 2022 dataset, with 88.98% and 64.08% Dice coefficient for LA cavity and scar segmentation, respectively.

Title: [Prediction of brain tumor recurrence location based on multi-modal fusion and nonlinear correlation learning](http://arxiv.org/pdf/2304.13725v1)     
Summary: This paper proposes a deep learning-based brain tumor recurrence location prediction network that segments present brain tumor and predicts its future recurrence location. The method uses transfer learning, multi-modal fusion, and nonlinear correlation learning to extract effective features. The proposed method is effective in predicting brain tumor recurrence location from limited datasets.

</details>
<details>
<summary>Object Detection</summary>
    
Title: [Learning Articulated Shape with Keypoint Pseudo-labels from Web Images](http://arxiv.org/pdf/2304.14396v1)     
Summary: The paper proposes an approach using as few as 50-150 images labeled with 2D keypoints to learn models for monocular 3D reconstruction of articulated objects. The approach involves training category-specific keypoint estimators, generating 2D keypoint pseudo-labels on unlabeled web images, and using both the labeled and self-labeled sets to train 3D reconstruction models. The results show that the approach can effectively utilize web images and improve 3D reconstruction performance for several articulated object categories beyond the fully-supervised baseline.

Title: [SMAT: A Self-Reinforcing Framework for Simultaneous Mapping and Tracking in Unbounded Urban Environments](http://arxiv.org/pdf/2304.14356v1)     
Summary: The paper introduces the SMAT (Simultaneous Mapping and Tracking) framework for robots to construct a reliable map online and navigate in unbounded and changing environments. The framework integrates dynamic object detection and tracking with static mapping using a self-reinforcing mechanism, promoting mutual improvement of mapping and tracking performance. The experiments demonstrate the framework's effectiveness in real-world applications, achieving successful long-range navigation and mapping in urban environments using LiDAR, CPU-only onboard computer, and GPS.

Title: [SparseFusion: Fusing Multi-Modal Sparse Representations for Multi-Sensor 3D Object Detection](http://arxiv.org/pdf/2304.14340v1)     
Summary: The paper proposes a novel multi-sensor 3D detection method called SparseFusion which exclusively uses sparse candidates and representations for efficient and accurate detections of objects in a scene. The proposed method utilizes the outputs of parallel detectors in the LiDAR and camera modalities as sparse candidates for fusion in a unified 3D space using a lightweight self-attention module. The paper achieves state-of-the-art performance on the nuScenes benchmark and is publicly available in GitHub.

Title: [Deep Imitation Learning for Automated Drop-In Gamma Probe Manipulation](http://arxiv.org/pdf/2304.14294v1)     
Summary: This paper proposes the use of deep imitation learning to create an end-to-end vision-based gamma probe manipulation agent for automated radioactive node detection during sentinel lymph node biopsy. The proposed approach uses simulation data to train the agent, and evaluation results showed promising results for further improvement and extension to hardware setup.

Title: [Towards Precise Weakly Supervised Object Detection via Interactive Contrastive Learning of Context Information](http://arxiv.org/pdf/2304.14114v1)     
Summary: This paper proposes a novel end-to-end weakly supervised object detection framework called JLWSOD, which utilizes two types of context information and an interactive graph contrastive learning mechanism to jointly optimize visual appearance and context information for better performance. The iGCL mechanism takes advantage of complementary interpretations of WSOD and forms a more comprehensive solution. Extensive experiments on benchmark datasets demonstrate JLWSOD's superior performance compared to state-of-the-art approaches and baseline models.

Title: [Automatic Localization and Detection Applicable to Robust Image Watermarking Resisting against Camera Shooting](http://arxiv.org/pdf/2304.13953v1)     
Summary: This paper proposes an automatic watermarking system that can resist camera shooting. The scheme deals with two important problems: automatic watermark localization (AWL) and automatic watermark detection (AWD). AWL automatically identifies the region of interest (RoI), which contains watermark information, in the camera-shooting image by analyzing the local statistical characteristics. Meanwhile, AWD extracts the hidden watermark from the identified RoI after applying perspective correction. Extensive experimental results demonstrate the superiority and applicability of the proposed approach.

</details>
<details>
<summary>Object Tracking</summary>
    
Title: [SeqTrack: Sequence to Sequence Learning for Visual Object Tracking](http://arxiv.org/pdf/2304.14394v1)     
Summary: The paper presents SeqTrack, a new sequence-to-sequence learning framework for visual object tracking. It uses a simple encoder-decoder transformer architecture to predict object bounding boxes in an autoregressive fashion instead of relying on complicated head networks. It achieves state-of-the-art performance on benchmarks like LaSOT, simplifying the tracking framework.

Title: [Co-SLAM: Joint Coordinate and Sparse Parametric Encodings for Neural Real-Time SLAM](http://arxiv.org/pdf/2304.14377v1)     
Summary: The paper presents Co-SLAM, a neural RGB-D SLAM system based on a hybrid representation that performs real-time camera tracking and high-fidelity surface reconstruction. Co-SLAM uses a multi-resolution hash-grid and one-blob encoding to enable fast convergence, surface hole filling, and surface coherence. It incorporates a ray sampling strategy that allows global bundle adjustment over all keyframes. Co-SLAM achieves state-of-the-art scene reconstruction results and competitive tracking performance in various datasets and benchmarks.

Title: [SMAT: A Self-Reinforcing Framework for Simultaneous Mapping and Tracking in Unbounded Urban Environments](http://arxiv.org/pdf/2304.14356v1)     
Summary: The paper introduces the SMAT (Simultaneous Mapping and Tracking) framework for robots to construct a reliable map online and navigate in unbounded and changing environments. The framework integrates dynamic object detection and tracking with static mapping using a self-reinforcing mechanism, promoting mutual improvement of mapping and tracking performance. The experiments demonstrate the framework's effectiveness in real-world applications, achieving successful long-range navigation and mapping in urban environments using LiDAR, CPU-only onboard computer, and GPS.

Title: [Direct Visual Servoing Based on Discrete Orthogonal Moments](http://arxiv.org/pdf/2304.14012v1)     
Summary: The paper proposes a new approach for Direct Visual Servoing (DVS) using discrete orthogonal moments (DOM), which helps in bypassing the feature-based visual servoing pipeline. The approach uses Tchebichef, Krawtchouk and Hahn moments as visual features and presents strategies for adaptive adjustment of parameters and orders of these features along with analytical formulation of associated interaction matrix. The proposed framework has been validated through simulations and real experiments, demonstrating its robustness and accuracy over state-of-the-art approaches.

</details>
<details>
<summary>Point Cloud</summary>
    
Title: [SMAT: A Self-Reinforcing Framework for Simultaneous Mapping and Tracking in Unbounded Urban Environments](http://arxiv.org/pdf/2304.14356v1)     
Summary: The paper introduces the SMAT (Simultaneous Mapping and Tracking) framework for robots to construct a reliable map online and navigate in unbounded and changing environments. The framework integrates dynamic object detection and tracking with static mapping using a self-reinforcing mechanism, promoting mutual improvement of mapping and tracking performance. The experiments demonstrate the framework's effectiveness in real-world applications, achieving successful long-range navigation and mapping in urban environments using LiDAR, CPU-only onboard computer, and GPS.

Title: [SparseFusion: Fusing Multi-Modal Sparse Representations for Multi-Sensor 3D Object Detection](http://arxiv.org/pdf/2304.14340v1)     
Summary: The paper proposes a novel multi-sensor 3D detection method called SparseFusion which exclusively uses sparse candidates and representations for efficient and accurate detections of objects in a scene. The proposed method utilizes the outputs of parallel detectors in the LiDAR and camera modalities as sparse candidates for fusion in a unified 3D space using a lightweight self-attention module. The paper achieves state-of-the-art performance on the nuScenes benchmark and is publicly available in GitHub.

Title: [Quadric Representations for LiDAR Odometry, Mapping and Localization](http://arxiv.org/pdf/2304.14190v1)     
Summary: The paper proposes a novel method for describing 3D scenes using quadric surfaces, which are more space-efficient representations than conventional point clouds. The method decomposes a scene into sparse quadric patches, fits each to a quadric implicit function, and describes each patch with additional geometric descriptors. The resulting quadric representations can be used in LiDAR odometry, mapping, and localization algorithms, and are shown to achieve competitive accuracy while maintaining low latency and memory usage.

Title: [ClusterNet: A Perception-Based Clustering Model for Scattered Data](http://arxiv.org/pdf/2304.14185v1)     
Summary: The paper proposes ClusterNet, a point-based deep learning model for cluster separation in scatterplots that is trained to reflect human perception of cluster separability. The authors crowdsourced a large-scale dataset of human annotations, used a PointNet++ architecture for inference on point clouds, and introduce a novel metric for measuring accuracy between clustering techniques and human annotators. The proposed approach is compared to existing state-of-the-art clustering techniques.

Title: [Human Semantic Segmentation using Millimeter-Wave Radar Sparse Point Clouds](http://arxiv.org/pdf/2304.14132v1)     
Summary: The paper proposes a framework for human semantic segmentation on sparse millimeter-wave radar point clouds using graph structure and topological features. The framework includes a global and sequential feature-extracting module, an efficient loss function for better training and segmentation results, and achieves state-of-the-art performance on both custom and benchmark datasets. The paper falls under the categories of point cloud, image segmentation, graph neural networks, and transformer.

Title: [Exploiting Inductive Bias in Transformer for Point Cloud Classification and Segmentation](http://arxiv.org/pdf/2304.14124v1)     
Summary: The paper presents a new Inductive Bias-aided Transformer (IBT) method for learning inter-point relations in point clouds. IBT considers both local and global attentions and incorporates the learned locality into the Transformer module to enhance self-attention mechanism with locality-based channel interaction. The paper demonstrates the superiority of the proposed method experimentally on classification and segmentation tasks.

Title: [RegHEC: Hand-Eye Calibration via Simultaneous Multi-view Point Clouds Registration of Arbitrary Object](http://arxiv.org/pdf/2304.14092v1)     
Summary: The paper presents a registration-based hand-eye calibration technique, RegHEC, that can calibrate the hand-eye relation without the need for an accurate calibration rig. The method uses multi-view point clouds of arbitrary scene and tries to bring them into simultaneous registration under a common reference frame. RegHEC is applicable for both eye-in-hand and eye-to-hand cases and has little requirement on calibration objects, making it suitable for most 3-D vision guided tasks. The technique is verified with extensive experiments using various arbitrary objects and a real hand-eye system. The paper presents an open-source C++ implementation of RegHEC.

Title: [A Review of Panoptic Segmentation for Mobile Mapping Point Clouds](http://arxiv.org/pdf/2304.13980v1)     
Summary: The paper reviews the state of panoptic segmentation of outdoor mobile-mapping data, which is the combined task of assigning semantic classes and separating them into object instances. The paper sets up a modular pipeline for comprehensive experiments and provides the first public dataset for the task, extending NPM3D dataset to include instance labels.

Title: [MIPI 2023 Challenge on RGB+ToF Depth Completion: Methods and Results](http://arxiv.org/pdf/2304.13916v1)     
Summary: This paper presents the results of an RGB+sparse ToF depth completion competition aimed at encouraging research in depth completion from RGB images and sparse ToF measurements. The paper discusses the strengths and weaknesses of the top-performing methods and their implications for future research in this area. The competition provided a standardized dataset and evaluation metrics to compare the accuracy of different approaches.

</details>
<details>
<summary>Neural Rendering</summary>
    
Title: [ActorsNeRF: Animatable Few-shot Human Rendering with Generalizable NeRFs](http://arxiv.org/pdf/2304.14401v1)     
Summary: The paper proposes a new animatable NeRF called ActorsNeRF that is pre-trained on diverse human subjects and adapts to new actors with few-shot video frames. ActorsNeRF uses two human priors to capture human appearance, shape, and pose variations and aligns humans in a category-level canonical space and instance-level canonical space for rendering. The proposed method outperforms existing state-of-the-art methods on few-shot generalization to new people and poses on multiple datasets.

Title: [Co-SLAM: Joint Coordinate and Sparse Parametric Encodings for Neural Real-Time SLAM](http://arxiv.org/pdf/2304.14377v1)     
Summary: The paper presents Co-SLAM, a neural RGB-D SLAM system based on a hybrid representation that performs real-time camera tracking and high-fidelity surface reconstruction. Co-SLAM uses a multi-resolution hash-grid and one-blob encoding to enable fast convergence, surface hole filling, and surface coherence. It incorporates a ray sampling strategy that allows global bundle adjustment over all keyframes. Co-SLAM achieves state-of-the-art scene reconstruction results and competitive tracking performance in various datasets and benchmarks.

Title: [Combining HoloLens with Instant-NeRFs: Advanced Real-Time 3D Mobile Mapping](http://arxiv.org/pdf/2304.14301v1)     
Summary: The paper presents a method of 3D reconstruction using a Microsoft HoloLens 2 as a multisensor platform that includes an RGB camera and an inertial measurement unit for SLAM-based camera-pose determination. The method utilizes a Neural Radiance Field (NeRF) as a neural scene representation in real-time with the acquired data from the HoloLens. The paper shows that the proposed method outperforms grid point sampling with NeRFs by multiple orders of magnitude and can be regarded as a complete real-time 3D reconstruction method in a mobile mapping setup.

Title: [Compositional 3D Human-Object Neural Animation](http://arxiv.org/pdf/2304.14070v1)     
Summary: This paper proposes a compositional approach for animating human-object interactions (HOIs) from a novel perspective by using neural human-object deformation to model and render HOI dynamics based on implicit neural representations. Additionally, the authors devise a new compositional conditional neural radiance field (CC-NeRF) to enable interaction pose transferring among different persons and objects to allow for compositionally animated control of novel HOIs. Their experiments show that this method can generalize well to various novel HOI animation settings.

Title: [ContraNeRF: 3D-Aware Generative Model via Contrastive Learning with Unsupervised Implicit Pose Embedding](http://arxiv.org/pdf/2304.14005v1)     
Summary: The paper proposes a novel 3D-aware GAN optimization technique, called ContraNeRF, that uses contrastive learning with implicit pose embeddings to capture complex 3D scene structures more effectively without relying on ground-truth camera poses. Experimental results show that ContraNeRF outperforms existing methods on datasets with multiple object categories and inconsistent camera poses.

</details>
<details>
<summary>Domain Generalization/Adaptation</summary>
    
Title: [ActorsNeRF: Animatable Few-shot Human Rendering with Generalizable NeRFs](http://arxiv.org/pdf/2304.14401v1)     
Summary: The paper proposes a new animatable NeRF called ActorsNeRF that is pre-trained on diverse human subjects and adapts to new actors with few-shot video frames. ActorsNeRF uses two human priors to capture human appearance, shape, and pose variations and aligns humans in a category-level canonical space and instance-level canonical space for rendering. The proposed method outperforms existing state-of-the-art methods on few-shot generalization to new people and poses on multiple datasets.

Title: [Maximizing Model Generalization for Manufacturing with Self-Supervised Learning and Federated Learning](http://arxiv.org/pdf/2304.14398v1)     
Summary: The paper proposes a method for maximizing model generalization for fault diagnosis in manufacturing using self-supervised learning and federated learning. The approach focuses on maximizing feature generality on the source domain and transferring the model to the target domain via weight transfer. Self-supervised learning with Barlow Twins produces more discriminative features, and federated learning expands the effective training data by sharing information across multiple machines. Results show that the proposed method outperforms traditional supervised learning and domain adaptation methods in an unlabeled target domain with emerging motor faults.

Title: [EDAPS: Enhanced Domain-Adaptive Panoptic Segmentation](http://arxiv.org/pdf/2304.14291v1)     
Summary: The paper proposes EDAPS, a novel architecture for domain-adaptive panoptic segmentation. EDAPS uses a shared, domain-robust transformer encoder, and task-specific decoders tailored for both domain-adaptive semantic and instance segmentation. The implementation of EDAPS improves the state-of-the-art performance for panoptic segmentation UDA by a large margin on challenging benchmarks. The paper falls under the categories of Image Segmentation and Domain Generalization/Adaptation.

Title: [ChatGPT vs State-of-the-Art Models: A Benchmarking Study in Keyphrase Generation Task](http://arxiv.org/pdf/2304.14177v1)     
Summary: This paper evaluates ChatGPT's keyphrase generation ability and compares its performance with state-of-the-art models on six publicly available datasets from scientific articles and news domains. The study finds that ChatGPT outperforms current state-of-the-art models in all tested datasets and environments, generating high-quality keyphrases that adapt well to diverse domains and document lengths.

Title: [Moderately Distributional Exploration for Domain Generalization](http://arxiv.org/pdf/2304.13976v1)     
Summary: This paper proposes a moderately distributional exploration (MODE) approach for domain generalization. It performs distribution exploration in a semantic subset of the uncertainty set to address low-confidence prediction issues. Experimental results show MODE achieves competitive performance compared to state-of-the-art baselines.

</details>
<details>
<summary>Few-Shot/Zero-Shot Learning</summary>
    
Title: [ActorsNeRF: Animatable Few-shot Human Rendering with Generalizable NeRFs](http://arxiv.org/pdf/2304.14401v1)     
Summary: The paper proposes a new animatable NeRF called ActorsNeRF that is pre-trained on diverse human subjects and adapts to new actors with few-shot video frames. ActorsNeRF uses two human priors to capture human appearance, shape, and pose variations and aligns humans in a category-level canonical space and instance-level canonical space for rendering. The proposed method outperforms existing state-of-the-art methods on few-shot generalization to new people and poses on multiple datasets.

Title: [Analogy-Forming Transformers for Few-Shot 3D Parsing](http://arxiv.org/pdf/2304.14382v1)     
Summary: The paper presents a model called Analogical Networks that can segment 3D object scenes using few-shot learning. The model retrieves related scenes from memory and predicts analogous part structures for the input scene, conditioning on the appropriate set of memories. Analogical Networks outperforms state-of-the-art 3D segmentation transformers in few-shot settings and successfully segments instances of novel object categories by expanding its memory.

Title: [ZeroShotDataAug: Generating and Augmenting Training Data with ChatGPT](http://arxiv.org/pdf/2304.14334v1)     
Summary: The paper proposes using ChatGPT, a large generative language model, to generate synthetic training data with task-specific prompts for augmenting data in low-resource scenarios. The augmented data generated from ChatGPT outperforms existing approaches for data augmentation. Additionally, the paper investigates methodologies for evaluating the quality of the data generated.

Title: [Adaptive manifold for imbalanced transductive few-shot learning](http://arxiv.org/pdf/2304.14281v1)     
Summary: The paper proposes a novel algorithm called Adaptive Manifold for imbalanced transductive few-shot learning. The method leverages the underlying manifold of labeled support examples and unlabeled queries by using manifold similarity to predict the class probability distribution per query. It outperforms other state-of-the-art methods on three benchmark datasets and three different backbones. The algorithm is parameterized by one centroid per class and a set of graph-specific parameters that determine the manifold. The parameters are optimized through a loss function that can be tuned towards class-balanced or imbalanced distributions.

Title: [Human-machine knowledge hybrid augmentation method for surface defect detection based few-data learning](http://arxiv.org/pdf/2304.13963v1)     
Summary: The paper proposes a human-machine knowledge hybrid augmentation method for surface defect detection based on few-data learning. The proposed method utilizes experts' knowledge of abnormality to create data with rich features, positions, sizes, and backgrounds, which can be used as prior knowledge for the model. The method was evaluated on the magnetic tile dataset and achieved better results than the traditional augmentation method, demonstrating its feasibility and effectiveness in few-data industrial defect detection.

Title: [Transferring Procedural Knowledge across Commonsense Tasks](http://arxiv.org/pdf/2304.13867v1)     
Summary: This paper proposes a framework called LEAP for transferring procedural knowledge across commonsense tasks in a transparent manner. The framework incorporates state-of-the-art modeling architectures, training regimes, and augmentation strategies based on both natural and synthetic stories. To address the lack of densely annotated training data, a robust automatic labeler based on few-shot prompting is devised for enhancing the augmented data. The experiments demonstrate insights into the interplay of different architectures, training regimes, and augmentation strategies. The LEAP's labeler positively impacts out-of-domain datasets, while the resulting dense annotation provides native explainability.

Title: [Is a prompt and a few samples all you need? Using GPT-4 for data augmentation in low-resource classification tasks](http://arxiv.org/pdf/2304.13861v1)     
Summary: The paper explores using GPT-4 and ChatGPT to augment small labeled datasets with synthetic data via simple prompts in low-resource classification tasks. They compare two augmentation strategies and find that synthetic data aids in identifying rare classes but human-annotated data exhibits a stronger predictive power in most cases. They also observe strong zero-shot performance across all tasks using GPT-4 and ChatGPT.

Title: [Translate to Disambiguate: Zero-shot Multilingual Word Sense Disambiguation with Pretrained Language Models](http://arxiv.org/pdf/2304.13803v1)     
Summary: The paper presents a study on how well Pretrained Language Models (PLMs) capture cross-lingual word sense knowledge with Contextual Word-Level Translation (C-WLT) and introduces a zero-shot approach for Word Sense Disambiguation (WSD) using PLMs. The study shows that as the model size increases, PLMs encode more cross-lingual word sense knowledge and better use context to improve WLT performance. The proposed zero-shot approach outperforms fully supervised baselines on recall for many evaluation languages without additional training or finetuning.

Title: [TR0N: Translator Networks for 0-Shot Plug-and-Play Conditional Generation](http://arxiv.org/pdf/2304.13742v1)     
Summary: The paper proposes a framework called TR0N, which can turn pre-trained unconditional generative models into conditional models without any training data. It learns a stochastic mapping between the space of conditions and the latent space of the generative model, enabling the generation of data samples satisfying the desired conditions. The proposed TR0N framework achieves zero-shot FID of 10.9 on MS-COCO and outperforms its competitors in terms of sampling speed and generality.

Title: [The Internal State of an LLM Knows When its Lying](http://arxiv.org/pdf/2304.13734v1)     
Summary: The paper proposes a method to detect the truthfulness of statements generated by Large Language Models (LLMs) using the LLM's internal state. They use the activation values in the hidden layer of LLM to determine if a statement is true or false. They compose a dataset of true and false statements and train a classifier that outperforms few-shot prompting methods. The paper has practical applicability in enhancing the reliability of LLM-generated content.

Title: [Precise Few-shot Fat-free Thigh Muscle Segmentation in T1-weighted MRI](http://arxiv.org/pdf/2304.14053v1)     
Summary: This paper proposes a few-shot segmentation framework for precise thigh muscle segmentation in T1-weighted MRI images, excluding intra-muscular fat (IMF). The framework uses a novel pseudo-label correction and evaluation scheme, together with a noise robust loss to exploit high certainty areas. With only 1% of fine-annotated training data, the proposed method achieves comparable performance with fully supervised methods.

</details>
<details>
<summary>Visual Question Answering(VQA)</summary>
    
</details>
<details>
<summary>Image-to-Image Translation</summary>
    
Title: [Automated Whole Slide Imaging for Label-Free Histology using Photon Absorption Remote Sensing Microscopy](http://arxiv.org/pdf/2304.13736v1)     
Summary: The paper proposes an automated whole slide imaging platform using Photon Absorption Remote Sensing microscopy for label-free histology. The system provides high-quality and high-resolution images of unstained tissue samples, while preserving the samples for other staining techniques. The study demonstrates the potential of this approach in label-free H&E emulation as well.

</details>
<details>
<summary>Transformer</summary>
    
Title: [IconShop: Text-Based Vector Icon Synthesis with Autoregressive Transformers](http://arxiv.org/pdf/2304.14400v1)     
Summary: The paper proposes IconShop, a text-guided vector icon synthesis method using an autoregressive transformer to sequence and tokenize SVG paths into a command sequence. The proposed method consistently exhibits better icon synthesis performance than existing methods in terms of quality, diversity, and speed. The paper also demonstrates the flexibility of IconShop with two novel icon manipulation tasks.

Title: [SeqTrack: Sequence to Sequence Learning for Visual Object Tracking](http://arxiv.org/pdf/2304.14394v1)     
Summary: The paper presents SeqTrack, a new sequence-to-sequence learning framework for visual object tracking. It uses a simple encoder-decoder transformer architecture to predict object bounding boxes in an autoregressive fashion instead of relying on complicated head networks. It achieves state-of-the-art performance on benchmarks like LaSOT, simplifying the tracking framework.

Title: [Analogy-Forming Transformers for Few-Shot 3D Parsing](http://arxiv.org/pdf/2304.14382v1)     
Summary: The paper presents a model called Analogical Networks that can segment 3D object scenes using few-shot learning. The model retrieves related scenes from memory and predicts analogous part structures for the input scene, conditioning on the appropriate set of memories. Analogical Networks outperforms state-of-the-art 3D segmentation transformers in few-shot settings and successfully segments instances of novel object categories by expanding its memory.

Title: [NAP at SemEval-2023 Task 3: Is Less Really More? (Back-)Translation as Data Augmentation Strategies for Detecting Persuasion Techniques](http://arxiv.org/pdf/2304.14179v1)     
Summary: The paper explores the use of (back-)translation as a data augmentation strategy for detecting persuasion techniques in news using multi-lingual transformer models. The results show that both data augmentation strategies boost performance, but balancing human-produced and machine-generated data is crucial.

Title: [ChatGPT vs State-of-the-Art Models: A Benchmarking Study in Keyphrase Generation Task](http://arxiv.org/pdf/2304.14177v1)     
Summary: This paper evaluates ChatGPT's keyphrase generation ability and compares its performance with state-of-the-art models on six publicly available datasets from scientific articles and news domains. The study finds that ChatGPT outperforms current state-of-the-art models in all tested datasets and environments, generating high-quality keyphrases that adapt well to diverse domains and document lengths.

Title: [Human Semantic Segmentation using Millimeter-Wave Radar Sparse Point Clouds](http://arxiv.org/pdf/2304.14132v1)     
Summary: The paper proposes a framework for human semantic segmentation on sparse millimeter-wave radar point clouds using graph structure and topological features. The framework includes a global and sequential feature-extracting module, an efficient loss function for better training and segmentation results, and achieves state-of-the-art performance on both custom and benchmark datasets. The paper falls under the categories of point cloud, image segmentation, graph neural networks, and transformer.

Title: [Exploiting Inductive Bias in Transformer for Point Cloud Classification and Segmentation](http://arxiv.org/pdf/2304.14124v1)     
Summary: The paper presents a new Inductive Bias-aided Transformer (IBT) method for learning inter-point relations in point clouds. IBT considers both local and global attentions and incorporates the learned locality into the Transformer module to enhance self-attention mechanism with locality-based channel interaction. The paper demonstrates the superiority of the proposed method experimentally on classification and segmentation tasks.

Title: [Deeply-Coupled Convolution-Transformer with Spatial-temporal Complementary Learning for Video-based Person Re-identification](http://arxiv.org/pdf/2304.14122v1)     
Summary: The paper proposes a novel spatial-temporal complementary learning framework for video-based person re-identification called Deeply-Coupled Convolution-Transformer (DCCT). The framework includes coupling CNNs and Transformers to extract visual features, Complementary Content Attention (CCA) to guide spatial learning, Hierarchical Temporal Aggregation (HTA) to capture inter-frame dependencies and gated attention to deliver aggregated temporal information for temporal learning. The proposed framework outperforms most state-of-the-art methods on public Re-ID benchmarks.

Title: [Lightweight, Pre-trained Transformers for Remote Sensing Timeseries](http://arxiv.org/pdf/2304.14065v1)     
Summary: The paper presents a pre-trained transformer-based model, Pretrained Remote Sensing Transformer (Presto), trained on remote sensing pixel-timeseries data. The model is designed specifically for remote sensing data and outperforms larger models. It can be used for transfer learning or feature extraction for simple models, enabling efficient deployment at scale. This paper falls under the categories of Remote Sensing/Satellite Image, Self-supervised learning, and Transformer.

Title: [SweCTRL-Mini: a data-transparent Transformer-based large language model for controllable text generation in Swedish](http://arxiv.org/pdf/2304.13994v1)     
Summary: The paper presents SweCTRL-Mini, a large language model for controllable text generation in Swedish. The model is based on the CTRL architecture and can be fine-tuned and used for inference on a single GPU. The authors provide details on the training data and text pre-processing and evaluate the model's performance on discriminative and generative tasks. SweCTRL-Mini is open-source and available for download.

Title: [Vision Conformer: Incorporating Convolutions into Vision Transformer Layers](http://arxiv.org/pdf/2304.13991v1)     
Summary: This paper proposes a new model called Vision Conformer (ViC) which incorporates convolutional layers within Vision Transformer (ViT) in order to address the lack of inductive bias towards image structures. ViC replaces the Multi-Layer Perceptron (MLP) in a ViT layer with a CNN and reconstructs the image data after self-attention using a reverse embedding layer. The paper demonstrates through evaluation that the use of convolutional layers improves the classification ability of ViT.

Title: [Contour Completion by Transformers and Its Application to Vector Font Data](http://arxiv.org/pdf/2304.13988v1)     
Summary: The paper proposes a Transformer-based method to solve the contour completion task where the missing points in a contour sequence need to be generated to complete the contour. The paper applies this method to vector font data and shows the results of typeface contour completion.

Title: [Optimization-Inspired Cross-Attention Transformer for Compressive Sensing](http://arxiv.org/pdf/2304.13986v1)     
Summary: The paper proposes an Optimization-inspired Cross-attention Transformer (OCT) module for compressive sensing (CS) in image reconstruction. The OCT is designed as an iterative process that improves visual quality with fewer parameters and reduces feature information loss. The OCT is integrated with a lightweight OCT-based Unfolding Framework (OCTUF) that achieves superior performance in CS compared to other methods while training lower complexity. The paper highlights a novel Dual Cross Attention sub-module that introduces multi-channel inertia forces and increases memory effect by a cross attention mechanism between adjacent iterations.

Title: [Neural Keyphrase Generation: Analysis and Evaluation](http://arxiv.org/pdf/2304.13883v1)     
Summary: This paper focuses on analyzing and evaluating keyphrase generation using neural models. Three models, T5, CatSeq-Transformer, and ExHiRD, were analyzed for their performance and behavior during keyphrase generation. The paper also proposes a novel metric framework, SoftKeyScore, to evaluate keyphrase similarity. The study finds that SoftKeyScore is more suitable than the standard F1 metric for evaluating keyphrases.

Title: [TR0N: Translator Networks for 0-Shot Plug-and-Play Conditional Generation](http://arxiv.org/pdf/2304.13742v1)     
Summary: The paper proposes a framework called TR0N, which can turn pre-trained unconditional generative models into conditional models without any training data. It learns a stochastic mapping between the space of conditions and the latent space of the generative model, enabling the generation of data samples satisfying the desired conditions. The proposed TR0N framework achieves zero-shot FID of 10.9 on MS-COCO and outperforms its competitors in terms of sampling speed and generality.

Title: [Distinguishing a planetary transit from false positives: a Transformer-based classification for planetary transit signals](http://arxiv.org/pdf/2304.14283v1)     
Summary: This paper proposes a new architecture for automatic classification of planetary transit signals using the self-attention mechanism inspired by the Transformer architecture. The proposed model achieves competitive results compared to previous methods and offers a level of interpretability through attention map inspection. The paper falls into the Transformer category because it uses this architecture and into Image Classification category because it classifies transit signals.

Title: [TempEE: Temporal-Spatial Parallel Transformer for Radar Echo Extrapolation Beyond Auto-Regression](http://arxiv.org/pdf/2304.14131v1)     
Summary: This paper proposes a novel radar echo extrapolation algorithm that utilizes temporal-spatial correlation features and the Transformer technology. The algorithm extracts features from multi-frame echo images to accurately represent non-stationary motion processes for precipitation prediction. The proposed algorithm uses a novel parallel encoder based on Transformer technology and a Multi-level Temporal-Spatial attention mechanism. The proposed method's effectiveness has been validated on the classic radar echo extrapolation task using the real-world dataset.

Title: [Phenotyping with Positive Unlabelled Learning for Genome-Wide Association Studies](http://arxiv.org/pdf/2202.07451v1)     
Summary: The paper proposes a model called AnchorBERT, which uses a combination of anchor learning and transformer architectures for phenotyping in genome-wide association studies (GWAS). The proposed model outperforms standard phenotype definitions and can detect significant genomic associations that were previously found only in large consortium studies with 5x more cases. The paper highlights the importance of reducing noise and phenotypic misclassification in GWAS, and the potential of machine learning in phenotypic discovery.

</details>
<details>
<summary>Semi-supervised learning</summary>
    
Title: [Learning Articulated Shape with Keypoint Pseudo-labels from Web Images](http://arxiv.org/pdf/2304.14396v1)     
Summary: The paper proposes an approach using as few as 50-150 images labeled with 2D keypoints to learn models for monocular 3D reconstruction of articulated objects. The approach involves training category-specific keypoint estimators, generating 2D keypoint pseudo-labels on unlabeled web images, and using both the labeled and self-labeled sets to train 3D reconstruction models. The results show that the approach can effectively utilize web images and improve 3D reconstruction performance for several articulated object categories beyond the fully-supervised baseline.

Title: [Cluster Flow: how a hierarchical clustering layer make allows deep-NNs more resilient to hacking, more human-like and easily implements relational reasoning](http://arxiv.org/pdf/2304.14081v1)     
Summary: The paper introduces a semi-supervised hierarchical clustering framework called ClusterFlow that operates on trained deep convolutional neural networks (NNs), utilizing multi-dimensional class and feature data. This framework adds more human-like functionality, improves the resilience of NNs against hacking, and allows for relational reasoning over sets of images. The paper suggests that ClusterFlow can be used as a tool to make modern NNs more human-like without re-training them.

Title: [Mimic-IV-ICD: A new benchmark for eXtreme MultiLabel Classification](http://arxiv.org/pdf/2304.13998v1)     
Summary: In this paper, the authors propose a public benchmark suite for ICD-10 and ICD-9 coding using a large EHR dataset derived from MIMIC-IV. They implement and compare several popular methods for ICD coding prediction tasks to standardize data preprocessing and establish a comprehensive ICD coding benchmark dataset. This approach fosters reproducibility and model comparison, accelerating progress toward employing automated ICD coding in future studies. Furthermore, they provide open-source code that offers easy access to data processing steps, benchmark creation, and experiment replication for those with MIMIC-IV access.

</details>
<details>
<summary>Self-supervised learning</summary>
    
Title: [Putting People in Their Place: Affordance-Aware Human Insertion into Scenes](http://arxiv.org/pdf/2304.14406v1)     
Summary: The paper presents a self-supervised method for realistically inserting humans into scene images while respecting scene affordances. The method involves a large-scale diffusion model trained on a dataset of 2.4M video clips to produce diverse and plausible poses while considering the scene context. The model can also hallucinate realistic people and scenes and enable interactive editing. The approach outperforms prior work in synthesizing more realistic human appearance and natural human-scene interactions.

Title: [Maximizing Model Generalization for Manufacturing with Self-Supervised Learning and Federated Learning](http://arxiv.org/pdf/2304.14398v1)     
Summary: The paper proposes a method for maximizing model generalization for fault diagnosis in manufacturing using self-supervised learning and federated learning. The approach focuses on maximizing feature generality on the source domain and transferring the model to the target domain via weight transfer. Self-supervised learning with Barlow Twins produces more discriminative features, and federated learning expands the effective training data by sharing information across multiple machines. Results show that the proposed method outperforms traditional supervised learning and domain adaptation methods in an unlabeled target domain with emerging motor faults.

Title: [Lightweight, Pre-trained Transformers for Remote Sensing Timeseries](http://arxiv.org/pdf/2304.14065v1)     
Summary: The paper presents a pre-trained transformer-based model, Pretrained Remote Sensing Transformer (Presto), trained on remote sensing pixel-timeseries data. The model is designed specifically for remote sensing data and outperforms larger models. It can be used for transfer learning or feature extraction for simple models, enabling efficient deployment at scale. This paper falls under the categories of Remote Sensing/Satellite Image, Self-supervised learning, and Transformer.

Title: [MAPConNet: Self-supervised 3D Pose Transfer with Mesh and Point Contrastive Learning](http://arxiv.org/pdf/2304.13819v1)     
Summary: The paper presents a self-supervised framework for 3D pose transfer which can be trained in unsupervised, semi-supervised, or fully supervised settings without any correspondence labels. The framework uses two contrastive learning constraints in the latent space (a mesh-level loss for disentangling global patterns and a point-level loss for discriminating local semantics) and achieves state-of-the-art results in supervised 3D pose transfer, with comparable results in unsupervised and semi-supervised settings. The method is also generalizable to unseen human and animal data with complex topologies.

</details>
<details>
<summary>UAV/Remote Sensing/Satellite Image</summary>
    
Title: [Fault Tolerant Super Twisting Sliding Mode Control of a Quadrotor UAV Using Control Allocation](http://arxiv.org/pdf/2304.14350v1)     
Summary: This paper proposes a fault-tolerant super-twisting sliding mode controller for a quadrotor UAV using control allocation. The proposed controller increases accuracy and reduces chattering while the control allocation algorithm optimizes trajectory tracking performance in the presence of an actuator fault. Simulation results show the effectiveness of the proposed approach in stabilizing the quadrotor in case of an actuator fault.

Title: [Density Invariant Contrast Maximization for Neuromorphic Earth Observations](http://arxiv.org/pdf/2304.14125v1)     
Summary: This paper proposes a solution to the problem of multiple extrema and noise-intolerance in contrast maximization techniques used in event-based vision systems for neuromorphic earth observation. The proposed solution corrects the warped events before calculating the contrast, making it insensitive to event data and does not require any prior knowledge of the camera motion. The approach enables the creation of better motion-compensated maps through an analytical compensation technique using a novel dataset from the International Space Station.

Title: [Securing Autonomous Air Traffic Management: Blockchain Networks Driven by Explainable AI](http://arxiv.org/pdf/2304.14095v1)     
Summary: The paper proposes the development of a secure network that leverages blockchain technology and explainable AI for autonomous air traffic management in the UAV sector. The authors review research in blockchain development, self-learning networking architectures, and explainable AI, and present a case study of federated learning UTM that uses real air traffic and weather data. The proposed system requires further research and development to enable future autonomous air mobility.

Title: [Improved path planning algorithms for non-holonomic autonomous vehicles in industrial environments with narrow corridors: Roadmap Hybrid A* and Waypoints Hybrid B*. Roadmap hybrid A* and Waypoints hybrid A* Pseudocodes](http://arxiv.org/pdf/2304.14043v1)     
Summary: This paper proposes two new path planning algorithms, Roadmap Hybrid A* and Waypoints Hybrid A*, specifically designed for navigating narrow industrial corridors with obstacles. These algorithms outperform the standard Hybrid A* in terms of computational speed and other metrics. The algorithms utilize a static roadmap and waypoints generated from a topological map of the environment to guide Hybrid A*. The simulation study conducted in an industrial plant demonstrates the effectiveness of these algorithms in servicing machines.

Title: [A Distributed Online Optimization Strategy for Cooperative Robotic Surveillance](http://arxiv.org/pdf/2304.14016v1)     
Summary: This paper proposes a distributed algorithm for controlling a team of cooperating robots to protect a target from intruders. The algorithm utilizes an online optimization problem within a distributed aggregative framework. The defending robots determine their positions based on the relative position between the intruders and the target, their contribution to the team barycenter, and collisions with other robots. The effectiveness of the algorithm is validated through simulations and experiments on a team of cooperating quadrotors.

Title: [Learning and Reasoning Multifaceted and Longitudinal Data for Poverty Estimates and Livelihood Capabilities of Lagged Regions in Rural India](http://arxiv.org/pdf/2304.13958v1)     
Summary: The paper proposes a project to examine poverty in rural India from 1990-2022 using artificial intelligence and multiple data sources, including satellite images and communication networks. The study aims to classify districts into different types based on poverty indicators and examine causation and longitudinal analysis. The paper emphasizes the importance of targeting lagging regions and vulnerable populations to eradicate poverty.

Title: [Deep Learning Techniques for Hyperspectral Image Analysis in Agriculture: A Review](http://arxiv.org/pdf/2304.13880v1)     
Summary: This academic paper focuses on the use of deep learning techniques in analyzing hyperspectral images in agriculture. The paper discusses the high redundancy of spectral bands and limited training samples that make the classification of HSI a complex task. The authors review and evaluate the performance of various deep learning approaches, such as Autoencoders, Convolutional Neural Networks, Recurrent Neural Networks, and Generative Adversarial Networks, on well-known land cover datasets. The paper concludes that deep learning techniques show promising results in HSI analysis, especially in agriculture.

Title: [Hybrid Genetic Algorithm and Mixed Integer Linear Programming for Flying Sidekick TSP](http://arxiv.org/pdf/2304.13832v1)     
Summary: The paper proposes a hybrid genetic algorithm and mixed integer linear programming approach for optimizing the Flying Sidekick TSP problem, wherein trucks and drones work in cooperation. The proposed algorithm (HGenFS) incorporates specific heuristics and a local search phase, and is capable of finding optimal solutions in a matter of seconds. The mathematical formulations presented are suitable for solving problems up to ten customers. This paper falls under the category of UAV/Remote Sensing/Satellite Image as it focuses on optimizing the use of drones for logistics delivery.

Title: [Green UAV-enabled Internet-of-Things Network with AI-assisted NOMA for Disaster Management](http://arxiv.org/pdf/2304.13802v1)     
Summary: This paper proposes a UAV-assisted wireless IoT network using NOMA and AI-assisted resource allocation to maximize energy efficiency in emergency-based IoT applications. The proposed scheme outperforms other methods in terms of energy consumption and complexity.

Title: [A Method for Classifying Snow Using Ski-Mounted Strain Sensors](http://arxiv.org/pdf/2304.14307v1)     
Summary: The paper proposes a method for classifying snow types using strain sensors mounted on ski surfaces. The method can accurately distinguish between three snow types with 97% accuracy using two strain gauges and an inertial measurement unit. The study suggests optimal placement of strain gauges halfway between the binding and the tip/tail of the ski. The proposed method can have various applications, including citizen science efforts to map snow surface characteristics in the backcountry and developing skis with automated stiffness tuning based on snow type.

</details>
<details>
<summary>Image Synthesis/Generation</summary>
    
Title: [Putting People in Their Place: Affordance-Aware Human Insertion into Scenes](http://arxiv.org/pdf/2304.14406v1)     
Summary: The paper presents a self-supervised method for realistically inserting humans into scene images while respecting scene affordances. The method involves a large-scale diffusion model trained on a dataset of 2.4M video clips to produce diverse and plausible poses while considering the scene context. The model can also hallucinate realistic people and scenes and enable interactive editing. The approach outperforms prior work in synthesizing more realistic human appearance and natural human-scene interactions.

Title: [Motion-Conditioned Diffusion Model for Controllable Video Synthesis](http://arxiv.org/pdf/2304.14404v1)     
Summary: The paper introduces MCDiff, a motion-conditioned diffusion model for controllable video synthesis that generates a video from a starting image frame and a set of strokes. MCDiff utilizes a flow completion model to predict the dense video motion based on the semantic understanding of the video frame and the sparse motion control. The diffusion model synthesizes high-quality future frames to form the output video. The paper showcases the effectiveness of MCDiff in stroke-guided controllable video synthesis and exhibits its capability on diverse content and motion synthesis.

Title: [Make It So: Steering StyleGAN for Any Image Inversion and Editing](http://arxiv.org/pdf/2304.14403v1)     
Summary: The paper proposes a novel GAN inversion method called Make It So, which operates in the noise space instead of the latent style space, and preserves editing capabilities even for out-of-domain images. The proposed method outperforms the state-of-the-art method by a significant margin in inversion accuracy and edit quality for complex indoor scenes.

Title: [IconShop: Text-Based Vector Icon Synthesis with Autoregressive Transformers](http://arxiv.org/pdf/2304.14400v1)     
Summary: The paper proposes IconShop, a text-guided vector icon synthesis method using an autoregressive transformer to sequence and tokenize SVG paths into a command sequence. The proposed method consistently exhibits better icon synthesis performance than existing methods in terms of quality, diversity, and speed. The paper also demonstrates the flexibility of IconShop with two novel icon manipulation tasks.

Title: [ZeroShotDataAug: Generating and Augmenting Training Data with ChatGPT](http://arxiv.org/pdf/2304.14334v1)     
Summary: The paper proposes using ChatGPT, a large generative language model, to generate synthetic training data with task-specific prompts for augmenting data in low-resource scenarios. The augmented data generated from ChatGPT outperforms existing approaches for data augmentation. Additionally, the paper investigates methodologies for evaluating the quality of the data generated.

Title: [Edit Everything: A Text-Guided Generative System for Images Editing](http://arxiv.org/pdf/2304.14006v1)     
Summary: The paper introduces Edit Everything, a generative system that takes image and text inputs and produces image outputs for editing images using simple text instructions. The system utilizes prompts to guide the visual module in generating requested images and incorporates Stable Diffusion with the use of Segment Anything model and CLIP. The system is publicly available on GitHub.

Title: [TR0N: Translator Networks for 0-Shot Plug-and-Play Conditional Generation](http://arxiv.org/pdf/2304.13742v1)     
Summary: The paper proposes a framework called TR0N, which can turn pre-trained unconditional generative models into conditional models without any training data. It learns a stochastic mapping between the space of conditions and the latent space of the generative model, enabling the generation of data samples satisfying the desired conditions. The proposed TR0N framework achieves zero-shot FID of 10.9 on MS-COCO and outperforms its competitors in terms of sampling speed and generality.

Title: [ganX -- generate artificially new XRF a python library to generate MA-XRF raw data out of RGB images](http://arxiv.org/pdf/2304.14078v1)     
Summary: The paper presents ganX, a Python library that can convert a coloured RGB image to X-ray fluorescence Macro maps (MA-XRF) using a Monte Carlo method. The probability function used for the conversion is computed using a database of pigment XRF signals and their corresponding RGB values. The library is available open source and released to PyPi.

</details>
<details>
<summary>Graph Neural Networks</summary>
    
Title: [A Simple and Efficient Parallel Laplacian Solver](http://arxiv.org/pdf/2304.14345v1)     
Summary: The paper introduces a simple and efficient parallel Laplacian solver based on random sampling and block Cholesky factorization. The solver achieves better depth and work than the best-known parallel Laplacian solvers for dense graphs. The Laplacian matrices are commonly used in graph neural networks for deep learning tasks on graph-structured data.

Title: [Fast Sampling of $b$-Matchings and $b$-Edge Covers](http://arxiv.org/pdf/2304.14289v1)     
Summary: The paper proposes an efficient algorithm for sampling $b$-matchings and $b$-edge covers in bounded-degree graphs using the simple Glauber dynamics. The paper also proves spectral independence for a broad class of binary symmetric Holant problems with log-concave signatures, including $b$-matchings, $b$-edge covers, and antiferromagnetic $2$-spin edge models. The algorithm's mixing time is shown to be $O(n \log n)$, which significantly improves upon previous results that only worked for small values of $b$ and had worse running time. The paper's contributions are based on spectral graph theory and diffusion models.

Title: [Adaptive manifold for imbalanced transductive few-shot learning](http://arxiv.org/pdf/2304.14281v1)     
Summary: The paper proposes a novel algorithm called Adaptive Manifold for imbalanced transductive few-shot learning. The method leverages the underlying manifold of labeled support examples and unlabeled queries by using manifold similarity to predict the class probability distribution per query. It outperforms other state-of-the-art methods on three benchmark datasets and three different backbones. The algorithm is parameterized by one centroid per class and a set of graph-specific parameters that determine the manifold. The parameters are optimized through a loss function that can be tuned towards class-balanced or imbalanced distributions.

Title: [When Do Graph Neural Networks Help with Node Classification: Investigating the Homophily Principle on Node Distinguishability](http://arxiv.org/pdf/2304.14274v1)     
Summary: The paper investigates the role of homophily in the performance of Graph Neural Networks (GNNs) on Node Classification (NC) tasks. It demonstrates the insufficiency of considering only intra-class Node Distinguishability (ND) and proposes a Contextual Stochastic Block Model for Homophily (CSBM-H) to better understand the effect of homophily. Two metrics, Probabilistic Bayes Error (PBE) and Expected Negative KL-divergence (ENKL), are defined to quantify ND and visualize the results. The paper verifies that the superiority of GNNs is closely related to both intra- and inter-class ND regardless of homophily levels and proposes a new Kernel Performance Metric (KPM) to reveal the advantage and disadvantage of GNNs on synthetic and real-world datasets.

Title: [Graphlet and Orbit Computation on Heterogeneous Graphs](http://arxiv.org/pdf/2304.14268v1)     
Summary: The paper explores the computation of graphlets and orbits on heterogeneous graphs, which can be treated as colored graphs. The canonical label technique is used to determine graph isomorphism with multiple states on nodes and edges. The authors provide a Python package to generate orbits for colored directed graphs and determine orbit occurrence frequency. The paper provides examples to illustrate the use of the package.

Title: [Compact Distance Oracles with Large Sensitivity and Low Stretch](http://arxiv.org/pdf/2304.14184v1)     
Summary: The paper introduces a new type of data structure called an $f$-edge fault-tolerant distance sensitive oracle, which provides an estimate of the distance between two nodes in a graph even when some edges are removed. The paper presents an $f$-DSO with large sensitivity, low stretch, and subquadratic space complexity. The authors use approximate distance oracles and derandomization techniques to achieve their results. The paper falls under the categories of Graph Neural Networks and Theory.

Title: [Human Semantic Segmentation using Millimeter-Wave Radar Sparse Point Clouds](http://arxiv.org/pdf/2304.14132v1)     
Summary: The paper proposes a framework for human semantic segmentation on sparse millimeter-wave radar point clouds using graph structure and topological features. The framework includes a global and sequential feature-extracting module, an efficient loss function for better training and segmentation results, and achieves state-of-the-art performance on both custom and benchmark datasets. The paper falls under the categories of point cloud, image segmentation, graph neural networks, and transformer.

Title: [Universal Obstructions of Graph Parameters](http://arxiv.org/pdf/2304.14121v1)     
Summary: The paper introduces a graph-parametric framework for obtaining obstruction characterizations of graph parameters. The framework defines the notions of class obstruction, parametric obstruction, and universal obstruction as combinatorial objects that determine the asymptotic behavior of graph parameters. The paper surveys existing graph-theoretic results on most known graph parameters and provides some unifying results on their classification.

Title: [Interweaved Graph and Attention Network for 3D Human Pose Estimation](http://arxiv.org/pdf/2304.14045v1)     
Summary: The paper proposes a novel Interweaved Graph and Attention Network (IGANet) for 3D human pose estimation. The network allows bidirectional communications between graph convolutional networks and attentions to capture global and local correlations for better representation learning of human skeleton. The proposed method achieves state-of-the-art performance on two benchmark datasets.

Title: [Bitcoin Double-Spending Attack Detection using Graph Neural Network](http://arxiv.org/pdf/2304.13935v1)     
Summary: The paper proposes a graph neural network (GNN) approach for detecting Bitcoin double-spending attacks. The GNN model predicts whether all nodes in the network contain a given payment transaction in their own memory pool (mempool) using information only obtained from some observer nodes in the network. The proposed model can detect double-spending with an accuracy of at least 0.95 when more than about 1% of the entire nodes in the network are observer nodes.

Title: [Network Analysis as a Tool for Shaping Conservation and Development Policy: A Case Study of Timber Market Optimization in India](http://arxiv.org/pdf/2304.13907v1)     
Summary: This paper discusses the potential for using network analysis as a tool for shaping conservation and development policy in the context of optimizing the timber market between farmers and traders in India. The authors formulate the commercial tree market as a transportation problem and optimize the transactions using a model based on a detailed dataset of market interactions between farmers and timber traders. They find a high potential to increase efficiency of market transactions within this region through a maximum-flow-minimum-cost optimization. The paper proposes that using this network flow optimization model to strategically distribute permits can reduce costs associated with market transactions and establish tree planting programs to support a long-term sustainable tree market, benefiting farmers, traders, and industries.

Title: [highway2vec -- representing OpenStreetMap microregions with respect to their road network characteristics](http://arxiv.org/pdf/2304.13865v1)     
Summary: The paper proposes a method for generating embeddings of OpenStreetMap microregions based on their road network characteristics using the H3 spatial index. The obtained vector representations allow detection of similarity between map hexagons in their road networks, and an arithmetic in the latent space yields meaningful results. The contribution aids data scientists in infrastructure-related prediction tasks with spatial variables.

Title: [Revisiting Network Value: Sublinear Knowledge Law](http://arxiv.org/pdf/2304.14084v1)     
Summary: This paper introduces a novel concept called the sublinear knowledge law, which examines knowledge growth in citation networks and demonstrates that it is notably slower than traditional network growth as outlined by established laws such as Sarnoff's Law, Metcalfe's Law, and Reed's Law. The authors utilized the Deep-time Digital Earth academic literature to demonstrate the coexistence of these laws in citation networks. The results offer an innovative perspective on network value while also filling a gap in network research.

</details>
<details>
<summary>Vision-Language (Multimodality)</summary>
    
Title: [Energy-based Models as Zero-Shot Planners for Compositional Scene Rearrangement](http://arxiv.org/pdf/2304.14391v1)     
Summary: This paper proposes a language-instructed spatial concept representation using energy functions to rearrange scenes. The instruction is mapped to corresponding energy functions using a language parser, and a visual-language model grounds their arguments to relevant objects in the scene. The goal scene configurations are generated by gradient descent on the energy functions, and local vision-based policies relocate objects to inferred goal locations. The model outperforms language-to-action reactive policies and Large Language Model planners for long instructions that involve compositions of multiple spatial concepts. The paper tests the model on established instruction-guided manipulation benchmarks and introduces compositional instruction benchmarks.

Title: [$œÄ$-Tuning: Transferring Multimodal Foundation Models with Optimal Multi-task Interpolation](http://arxiv.org/pdf/2304.14381v1)     
Summary: The paper introduces a transfer learning method called Predict-Interpolate Tuning ($\pi$-Tuning) for vision, language, and vision-language tasks. It utilizes the parameters of lightweight task-specific experts learned from similar tasks to aid the target downstream task, with task similarities predicted in a modality-independent space. $\pi$-Tuning offers benefits such as intra- and inter-modal transferability exploration and compatibility with diverse types of parameter-efficient experts. The paper demonstrates through experiments on 14 unimodal and 6 multimodal datasets that $\pi$-Tuning surpasses fine-tuning and other parameter-efficient transfer learning methods in full-shot and low-shot regimes.

Title: [Design of a multimodal device to improve well-being of autistic workers interacting with collaborative robots](http://arxiv.org/pdf/2304.14191v1)     
Summary: The paper describes the design and development of (A)MICO, a multimodal device aimed to improve the user experience of ASD workers interacting with collaborative robots in production lines. The device proposes a new intuitive mode of communication in which information about the cobot activity is transferred through acoustic and visual feedback. The design process involves a co-design process with users with high functioning autism to analyze the system from different perspectives, and Design for All principles were taken into consideration to develop a human-friendly device.

Title: [mPLUG-Owl: Modularization Empowers Large Language Models with Multimodality](http://arxiv.org/pdf/2304.14178v1)     
Summary: The paper introduces mPLUG-Owl, a training paradigm that equips LLMs with multi-modal abilities through modularized learning of foundation LLM, a visual knowledge module, and a visual abstractor module. The approach can support multiple modalities and facilitate diverse unimodal and multimodal abilities through modality collaboration. The model outperforms existing multi-modal models and demonstrates impressive instruction and visual understanding ability, multi-turn conversation ability, and knowledge reasoning ability. The paper is available along with code, pre-trained model, instruction-tuned models, and evaluation set on GitHub.

Title: [Figments and Misalignments: A Framework for Fine-grained Crossmodal Misinformation Detection](http://arxiv.org/pdf/2304.14133v1)     
Summary: This paper proposes a framework for fine-grained crossmodal misinformation detection by introducing a benchmark dataset named FIGMENTS and a synthetic data generation method called Crossmodal HArd Synthetic MisAlignment (CHASMA). The authors conducted an extensive study using a Transformer-based architecture, and the results showed that incorporating CHASMA in conjunction with other generated datasets consistently improved the overall performance on FIGMENTS in both binary and multiclass settings.

Title: [A sensemaking system for grouping and suggesting stories from multiple affective viewpoints in museums](http://arxiv.org/pdf/2304.14117v1)     
Summary: The paper presents a sensemaking system that utilizes affective-based reasoning to group and suggest stories created by users in a museum context. The system is designed to promote inclusive and empathy-based interpretations of cultural content by recommending stories with different emotional stances. The system is tested on the collection of the Gallery of Modern Art in Turin and is integrated with an app called GAMGame.

Title: [DataComp: In search of the next generation of multimodal datasets](http://arxiv.org/pdf/2304.14108v1)     
Summary: The paper introduces DataComp, a benchmark for improving multimodal datasets. The benchmark entails proposing new training sets by designing new filtering techniques or curating new data sources and testing them on a standardized CLIP training code and evaluating on downstream test sets. The benchmark consists of various scales, facilitating the study of scaling trends and making the benchmark accessible to researchers with different resources. The paper also introduces DataComp-1B, a dataset that shows promising results by curating the training sets, enabling training CLIP ViT-L/14 from scratch to 79.2% zero-shot accuracy on ImageNet.

Title: [Learning Human-Human Interactions in Images from Weak Textual Supervision](http://arxiv.org/pdf/2304.14104v1)     
Summary: The paper proposes a new paradigm for learning human-human interactions in images as free text from a single still image using knowledge distillation applied to synthetic caption data produced by a large language model without explicit supervision. The pseudo-labels produced by this procedure are used to train a captioning model to effectively understand human-human interactions in images. The approach outperforms SOTA image captioning and situation recognition models on this task.

Title: [Edit Everything: A Text-Guided Generative System for Images Editing](http://arxiv.org/pdf/2304.14006v1)     
Summary: The paper introduces Edit Everything, a generative system that takes image and text inputs and produces image outputs for editing images using simple text instructions. The system utilizes prompts to guide the visual module in generating requested images and incorporates Stable Diffusion with the use of Segment Anything model and CLIP. The system is publicly available on GitHub.

Title: [Retrieval-based Knowledge Augmented Vision Language Pre-training](http://arxiv.org/pdf/2304.13923v1)     
Summary: The paper proposes a retrieval-based knowledge augmented vision language pre-training model (REAVL) that retrieves world knowledge from knowledge graphs and incorporates it into vision-language pre-training. The model promotes the mutual integration of multi-modal data and knowledge by fusing explicit knowledge with vision-language pairs. The experiments show that REAVL achieves state-of-the-art results on knowledge-based vision-language understanding and multimodal entity linking tasks, as well as competitive results on general vision-language tasks.

Title: [Programmatically Grounded, Compositionally Generalizable Robotic Manipulation](http://arxiv.org/pdf/2304.13826v1)     
Summary: The paper proposes a modular approach, ProgramPort, to leverage pre-trained vision-language models for robotic manipulation. It disentangles domain-specific action information and domain-general visual information, resulting in improved zero-shot and compositional generalization in a variety of manipulation behaviors. The entire modular network can be trained with end-to-end imitation learning objectives.

Title: [Towards ethical multimodal systems](http://arxiv.org/pdf/2304.13765v1)     
Summary: The paper discusses the ethical evaluation of multimodal artificial intelligence systems that take both text and an image as input and output text. The authors propose creating a multimodal ethical database through human feedback and using this database to construct morality-evaluating algorithms. The models tested are a RoBERTa-large classifier and a multilayer perceptron classifier. The paper addresses the ethical concerns surrounding generative AI systems and the growing field of AI alignment.

</details>
<details>
<summary>Model Compression/Knowledge Distillation/Pruning</summary>
    
Title: [LaMini-LM: A Diverse Herd of Distilled Models from Large-Scale Instructions](http://arxiv.org/pdf/2304.14402v1)     
Summary: The paper proposes a method called LaMini-LM that distills knowledge from instruction-trained Large Language Models (LLMs) to smaller ones. The authors developed a large set of diverse instructions and demonstrated that their LaMini-LM models of varying sizes are on par with competitive baselines while being nearly 10 times smaller in size. The proposed approach has applications in natural language processing tasks.

Title: [CONSCENDI: A Contrastive and Scenario-Guided Distillation Approach to Guardrail Models for Virtual Assistants](http://arxiv.org/pdf/2304.14364v1)     
Summary: The paper proposes a contrastive and scenario-guided distillation approach, named CONSCENDI, for creating a guardrail model to monitor the output of large language models in virtual assistants. The paper outlines two critical steps, scenario-augmented generation, and contrastive training examples, which lead to a diverse training set of rule-violating conversations and greater control over the classification process. The approach results in guardrail models that outperform baselines, making it a promising technique for knowledge distillation and model compression in virtual assistants.

Title: [Self-discipline on multiple channels](http://arxiv.org/pdf/2304.14224v1)     
Summary: The paper proposes a self-distillation method called Self-discipline on multiple channels (SMC) which combines consistency regularization with self-distillation using the concept of multiple channels to improve the generalization ability and robustness of models. SMC-2, containing only two channels, outperforms existing methods on various models and datasets and can also curb the negative effects of label noise interference. The paper falls under the category of Model Compression/Knowledge Distillation/Pruning.

Title: [Learning Human-Human Interactions in Images from Weak Textual Supervision](http://arxiv.org/pdf/2304.14104v1)     
Summary: The paper proposes a new paradigm for learning human-human interactions in images as free text from a single still image using knowledge distillation applied to synthetic caption data produced by a large language model without explicit supervision. The pseudo-labels produced by this procedure are used to train a captioning model to effectively understand human-human interactions in images. The approach outperforms SOTA image captioning and situation recognition models on this task.

Title: [JaxPruner: A concise library for sparsity research](http://arxiv.org/pdf/2304.14082v1)     
Summary: This paper introduces JaxPruner, a JAX-based library for pruning and sparse training of neural networks. The library provides concise implementations of popular algorithms with minimal memory and latency overhead, using a common API and integrating seamlessly with the Optimax optimization library. The paper demonstrates easy integration with four different codebases and provides baseline experiments on popular benchmarks.

Title: [Guaranteed Quantization Error Computation for Neural Network Model Compression](http://arxiv.org/pdf/2304.13812v1)     
Summary: The paper addresses the problem of guaranteed output error computation for neural network compression with quantization. The proposed approach involves building a merged neural network from a feedforward neural network and its quantized version, and then applying optimization-based and reachability analysis methods to compute the guaranteed quantization error. A numerical example is also presented to validate the effectiveness of the approach.

Title: [Fine Tuning with Abnormal Examples](http://arxiv.org/pdf/2304.13783v1)     
Summary: The paper proposes a methodology for pruning datasets in fine-tuning natural language processing models using abnormal examples, leading to better out of sample performance. The authors use the SQUAD dataset and identify 10,500 examples that create a more uniform distribution for training, resulting in improved performance when fine-tuning ELECTRA.

</details>
<details>
<summary>Contrastive Learning</summary>
    
Title: [CONSCENDI: A Contrastive and Scenario-Guided Distillation Approach to Guardrail Models for Virtual Assistants](http://arxiv.org/pdf/2304.14364v1)     
Summary: The paper proposes a contrastive and scenario-guided distillation approach, named CONSCENDI, for creating a guardrail model to monitor the output of large language models in virtual assistants. The paper outlines two critical steps, scenario-augmented generation, and contrastive training examples, which lead to a diverse training set of rule-violating conversations and greater control over the classification process. The approach results in guardrail models that outperform baselines, making it a promising technique for knowledge distillation and model compression in virtual assistants.

Title: [MarsEclipse at SemEval-2023 Task 3: Multi-Lingual and Multi-Label Framing Detection with Contrastive Learning](http://arxiv.org/pdf/2304.14339v1)     
Summary: The paper presents the MarsEclipse system for multi-lingual and multi-label framing detection using a contrastive loss function for fine-tuning large pre-trained language models. The system achieved first place on the official test set and leaderboard for five out of six languages in the SemEval-2023 Task 3 Subtask 2 on Framing Detection. The code is available on GitHub, and the paper details the experimental setup and includes various ablation studies.

Title: [Origin Tracing and Detecting of LLMs](http://arxiv.org/pdf/2304.14072v1)     
Summary: The paper proposes a method to trace the origin of large language models (LLMs) and detect whether a given text context is generated by an AI system. The method is based on contrastive features between LLMs and extracts model-wise features to trace the text origins. The proposed approach works under both white-box and black-box settings and requires limited data compared to supervised learning methods. The paper provides valuable observations based on experimental results and calls for ethical concerns of LLM providers. The code and data are released as a toolkit and benchmark for future AI origin tracing and detecting studies.

Title: [ContraNeRF: 3D-Aware Generative Model via Contrastive Learning with Unsupervised Implicit Pose Embedding](http://arxiv.org/pdf/2304.14005v1)     
Summary: The paper proposes a novel 3D-aware GAN optimization technique, called ContraNeRF, that uses contrastive learning with implicit pose embeddings to capture complex 3D scene structures more effectively without relying on ground-truth camera poses. Experimental results show that ContraNeRF outperforms existing methods on datasets with multiple object categories and inconsistent camera poses.

Title: [UCF: Uncovering Common Features for Generalizable Deepfake Detection](http://arxiv.org/pdf/2304.13949v1)     
Summary: The paper proposes a disentanglement framework that uncovers common forgery features to address the overfitting issue in deepfake detection. It employs a multi-task learning strategy and contrastive regularization technique to encourage the disentanglement of specific and common forgery features. The proposed framework outperforms current state-of-the-art methods in generalizable deepfake detection.

</details>
<details>
<summary>Continual Learning</summary>
    
Title: [Incremental Generalized Category Discovery](http://arxiv.org/pdf/2304.14310v1)     
Summary: The paper explores the problem of Incremental Generalized Category Discovery (IGCD), where the model needs to categorize images from previously seen and novel categories, over a series of time steps. The proposed method uses non-parametric categorization with efficient image sampling to mitigate catastrophic forgetting and outperforms existing related methods. A new benchmark dataset named iNatIGCD is proposed for performance evaluation.

</details>
<details>
<summary>Adversarial Learning</summary>
    
Title: [Boosting Big Brother: Attacking Search Engines with Encodings](http://arxiv.org/pdf/2304.14031v1)     
Summary: The paper presents an attack on search engines by manipulating text encodings, which is successful against major commercial search engines and chatbots. The authors also demonstrate a variant of the attack targeting text summarization and plagiarism detection models, which are closely tied to search. The paper provides defenses against these techniques and highlights the need for security patches to prevent disinformation campaigns launched by adversaries.

Title: [Attacks on Robust Distributed Learning Schemes via Sensitivity Curve Maximization](http://arxiv.org/pdf/2304.14024v1)     
Summary: The paper introduces a new attack on robust distributed learning schemes used in federated or decentralized learning paradigms. The attack is based on sensitivity curve maximization (SCM) and is able to disrupt existing robust aggregation schemes by injecting small but effective perturbations. The paper is focused on the vulnerability of aggregation schemes based on robust variations of the mean in distributed learning and proposes a new attack method to overcome them. Thus, the paper falls under both the categories of Adversarial Learning and Federated Learning.

Title: [Detection of Adversarial Physical Attacks in Time-Series Image Data](http://arxiv.org/pdf/2304.13919v1)     
Summary: The paper proposes a real-time detector called VisionGuard* (VG) for detecting adversarial physical attacks in time-series image data. VG utilizes majority-vote mechanisms and is evaluated on videos of traffic signs with physical attacks. The paper investigates how majority-vote mechanisms can be leveraged to enhance the performance of adversarial detectors. The proposed method provides comparative experiments against detectors designed for out-of-distribution data and digitally attacked images.

</details>
<details>
<summary>Federated Learning</summary>
    
Title: [Maximizing Model Generalization for Manufacturing with Self-Supervised Learning and Federated Learning](http://arxiv.org/pdf/2304.14398v1)     
Summary: The paper proposes a method for maximizing model generalization for fault diagnosis in manufacturing using self-supervised learning and federated learning. The approach focuses on maximizing feature generality on the source domain and transferring the model to the target domain via weight transfer. Self-supervised learning with Barlow Twins produces more discriminative features, and federated learning expands the effective training data by sharing information across multiple machines. Results show that the proposed method outperforms traditional supervised learning and domain adaptation methods in an unlabeled target domain with emerging motor faults.

Title: [Attacks on Robust Distributed Learning Schemes via Sensitivity Curve Maximization](http://arxiv.org/pdf/2304.14024v1)     
Summary: The paper introduces a new attack on robust distributed learning schemes used in federated or decentralized learning paradigms. The attack is based on sensitivity curve maximization (SCM) and is able to disrupt existing robust aggregation schemes by injecting small but effective perturbations. The paper is focused on the vulnerability of aggregation schemes based on robust variations of the mean in distributed learning and proposes a new attack method to overcome them. Thus, the paper falls under both the categories of Adversarial Learning and Federated Learning.

Title: [Federated Prompting and Chain-of-Thought Reasoning for Improving LLMs Answering](http://arxiv.org/pdf/2304.13911v1)     
Summary: The paper proposes Fed-SP-SC and Fed-DP-CoT methods to enhance answer precision in frequently asked questions posed by distributed users using cloud-based Large Language Models (LLMs). The methods involve improving distributed synonymous questions using Self-Consistency and Chain-of-Thought techniques. Through extensive experiments, the proposed methods are demonstrated to significantly enhance question accuracy by fully exploring the synonymous nature of the questions and the consistency of the answers.

</details>
<details>
<summary>Video</summary>
    
Title: [ChatVideo: A Tracklet-centric Multimodal and Versatile Video Understanding System](http://arxiv.org/pdf/2304.14407v1)     
Summary: The paper presents a prototype system called ChatVideo that aims to address the limitations of existing deep video models by employing a tracklet-centric paradigm and various Video Foundation Models to annotate tracklet properties. The system stores all detected tracklets in a database and interacts with the user through a database manager. The effectiveness of the method is demonstrated through case studies on different types of in-the-wild videos.

Title: [Motion-Conditioned Diffusion Model for Controllable Video Synthesis](http://arxiv.org/pdf/2304.14404v1)     
Summary: The paper introduces MCDiff, a motion-conditioned diffusion model for controllable video synthesis that generates a video from a starting image frame and a set of strokes. MCDiff utilizes a flow completion model to predict the dense video motion based on the semantic understanding of the video frame and the sparse motion control. The diffusion model synthesizes high-quality future frames to form the output video. The paper showcases the effectiveness of MCDiff in stroke-guided controllable video synthesis and exhibits its capability on diverse content and motion synthesis.

Title: [Deeply-Coupled Convolution-Transformer with Spatial-temporal Complementary Learning for Video-based Person Re-identification](http://arxiv.org/pdf/2304.14122v1)     
Summary: The paper proposes a novel spatial-temporal complementary learning framework for video-based person re-identification called Deeply-Coupled Convolution-Transformer (DCCT). The framework includes coupling CNNs and Transformers to extract visual features, Complementary Content Attention (CCA) to guide spatial learning, Hierarchical Temporal Aggregation (HTA) to capture inter-frame dependencies and gated attention to deliver aggregated temporal information for temporal learning. The proposed framework outperforms most state-of-the-art methods on public Re-ID benchmarks.

Title: [SeeHow: Workflow Extraction from Programming Screencasts through Action-Aware Video Analytics](http://arxiv.org/pdf/2304.14042v1)     
Summary: The paper presents a method called SeeHow, which uses computer vision techniques to automatically extract editing steps and code snippets from programming screencasts, resulting in a programming workflow. The proposed method accurately extracts code-line editing steps and allows for better accessibility and interaction with screencast content for developers. The evaluation on 41 hours of tutorial videos and live coding screencasts demonstrated promising results.

Title: [Detection of Adversarial Physical Attacks in Time-Series Image Data](http://arxiv.org/pdf/2304.13919v1)     
Summary: The paper proposes a real-time detector called VisionGuard* (VG) for detecting adversarial physical attacks in time-series image data. VG utilizes majority-vote mechanisms and is evaluated on videos of traffic signs with physical attacks. The paper investigates how majority-vote mechanisms can be leveraged to enhance the performance of adversarial detectors. The proposed method provides comparative experiments against detectors designed for out-of-distribution data and digitally attacked images.

</details>
<details>
<summary>3D</summary>
    
Title: [Learning Articulated Shape with Keypoint Pseudo-labels from Web Images](http://arxiv.org/pdf/2304.14396v1)     
Summary: The paper proposes an approach using as few as 50-150 images labeled with 2D keypoints to learn models for monocular 3D reconstruction of articulated objects. The approach involves training category-specific keypoint estimators, generating 2D keypoint pseudo-labels on unlabeled web images, and using both the labeled and self-labeled sets to train 3D reconstruction models. The results show that the approach can effectively utilize web images and improve 3D reconstruction performance for several articulated object categories beyond the fully-supervised baseline.

Title: [Analogy-Forming Transformers for Few-Shot 3D Parsing](http://arxiv.org/pdf/2304.14382v1)     
Summary: The paper presents a model called Analogical Networks that can segment 3D object scenes using few-shot learning. The model retrieves related scenes from memory and predicts analogous part structures for the input scene, conditioning on the appropriate set of memories. Analogical Networks outperforms state-of-the-art 3D segmentation transformers in few-shot settings and successfully segments instances of novel object categories by expanding its memory.

Title: [Co-SLAM: Joint Coordinate and Sparse Parametric Encodings for Neural Real-Time SLAM](http://arxiv.org/pdf/2304.14377v1)     
Summary: The paper presents Co-SLAM, a neural RGB-D SLAM system based on a hybrid representation that performs real-time camera tracking and high-fidelity surface reconstruction. Co-SLAM uses a multi-resolution hash-grid and one-blob encoding to enable fast convergence, surface hole filling, and surface coherence. It incorporates a ray sampling strategy that allows global bundle adjustment over all keyframes. Co-SLAM achieves state-of-the-art scene reconstruction results and competitive tracking performance in various datasets and benchmarks.

Title: [Occ3D: A Large-Scale 3D Occupancy Prediction Benchmark for Autonomous Driving](http://arxiv.org/pdf/2304.14365v1)     
Summary: This paper introduces Occ3D, a large-scale 3D occupancy prediction benchmark for autonomous driving. The paper proposes a Coarse-to-Fine Occupancy (CTF-Occ) network that demonstrates superior performance in the 3D occupancy prediction task. The paper includes a label generation pipeline that produces dense, visibility-aware labels for a given scene, and constructs benchmarks based on the Waymo Open Dataset and the nuScenes Dataset. The paper addresses the need for finer geometric understanding in a coarse-to-fine fashion.

Title: [SparseFusion: Fusing Multi-Modal Sparse Representations for Multi-Sensor 3D Object Detection](http://arxiv.org/pdf/2304.14340v1)     
Summary: The paper proposes a novel multi-sensor 3D detection method called SparseFusion which exclusively uses sparse candidates and representations for efficient and accurate detections of objects in a scene. The proposed method utilizes the outputs of parallel detectors in the LiDAR and camera modalities as sparse candidates for fusion in a unified 3D space using a lightweight self-attention module. The paper achieves state-of-the-art performance on the nuScenes benchmark and is publicly available in GitHub.

Title: [Combining HoloLens with Instant-NeRFs: Advanced Real-Time 3D Mobile Mapping](http://arxiv.org/pdf/2304.14301v1)     
Summary: The paper presents a method of 3D reconstruction using a Microsoft HoloLens 2 as a multisensor platform that includes an RGB camera and an inertial measurement unit for SLAM-based camera-pose determination. The method utilizes a Neural Radiance Field (NeRF) as a neural scene representation in real-time with the acquired data from the HoloLens. The paper shows that the proposed method outperforms grid point sampling with NeRFs by multiple orders of magnitude and can be regarded as a complete real-time 3D reconstruction method in a mobile mapping setup.

Title: [A Probabilistic Attention Model with Occlusion-aware Texture Regression for 3D Hand Reconstruction from a Single RGB Image](http://arxiv.org/pdf/2304.14299v1)     
Summary: 
This paper proposes a novel probabilistic model for 3D hand reconstruction from a single RGB image. The model-based network estimates the prior probability distribution of joints and vertices, while the Attention-based Mesh Vertices Uncertainty Regression (AMVUR) model captures dependencies among vertices and correlation between joints and vertices. An occlusion-aware Hand Texture Regression model is also proposed for high-fidelity texture reconstruction. The proposed model achieves state-of-the-art accuracy in 3D hand and texture reconstruction from a single image in both supervised and weakly-supervised scenarios.

Title: [What's in a Name? Evaluating Assembly-Part Semantic Knowledge in Language Models through User-Provided Names in CAD Files](http://arxiv.org/pdf/2304.14275v1)     
Summary: This paper proposes that natural language names used in Computer Aided Design (CAD) software contain valuable domain-specific information that can be used to improve Large Language Models' (LLMs) ability to understand assembly-part relationships. The authors extract a large corpus of natural language part, feature, and document names and show that fine-tuning a pre-trained LLM on this data improves its performance on self-supervised tasks, highlighting the value of text data in the CAD domain. The paper concludes by identifying limitations and calling for further work in multimodal text-geometry models.

Title: [Compositional 3D Human-Object Neural Animation](http://arxiv.org/pdf/2304.14070v1)     
Summary: This paper proposes a compositional approach for animating human-object interactions (HOIs) from a novel perspective by using neural human-object deformation to model and render HOI dynamics based on implicit neural representations. Additionally, the authors devise a new compositional conditional neural radiance field (CC-NeRF) to enable interaction pose transferring among different persons and objects to allow for compositionally animated control of novel HOIs. Their experiments show that this method can generalize well to various novel HOI animation settings.

Title: [Interweaved Graph and Attention Network for 3D Human Pose Estimation](http://arxiv.org/pdf/2304.14045v1)     
Summary: The paper proposes a novel Interweaved Graph and Attention Network (IGANet) for 3D human pose estimation. The network allows bidirectional communications between graph convolutional networks and attentions to capture global and local correlations for better representation learning of human skeleton. The proposed method achieves state-of-the-art performance on two benchmark datasets.

Title: [ContraNeRF: 3D-Aware Generative Model via Contrastive Learning with Unsupervised Implicit Pose Embedding](http://arxiv.org/pdf/2304.14005v1)     
Summary: The paper proposes a novel 3D-aware GAN optimization technique, called ContraNeRF, that uses contrastive learning with implicit pose embeddings to capture complex 3D scene structures more effectively without relying on ground-truth camera poses. Experimental results show that ContraNeRF outperforms existing methods on datasets with multiple object categories and inconsistent camera poses.

Title: [Provably Stabilizing Global-Position Tracking Control for Hybrid Models of Multi-Domain Bipedal Walking via Multiple Lyapunov Analysis](http://arxiv.org/pdf/2304.13943v1)     
Summary: This paper proposes a time-based nonlinear control method for achieving accurate global position tracking (GPT) for multi-domain bipedal walking. The paper introduces a GPT control law for multi-domain walking that provably ensures exponential convergence of the entire error state within the full and over actuation domains and the directly regulated error state within the underactuation domain. The paper also constructs sufficient multiple-Lyapunov stability conditions for the hybrid multi-domain tracking error system under the proposed GPT control law. The proposed control approach is demonstrated on a ROBOTIS OP3 bipedal humanoid robot through simulations of three-domain walking with all motors activated and two-domain gait with inactive ankle motors.

Title: [Open Metaverse: Issues, Evolution, and Future](http://arxiv.org/pdf/2304.13931v1)     
Summary: This academic paper discusses the evolution, issues, and future prospects of the Open Metaverse, a space where real and virtual worlds are combined. It provides a comprehensive survey of the Metaverse, including related concepts such as trusted Metaverse, AI-enabled Metaverse, personalized Metaverse, and Metaverse-as-a-service. The paper presents challenges faced by the Metaverse such as limited resources and ethical issues. It explores promising directions such as autonomous Metaverse and lightweight Metaverse.

Title: [MAPConNet: Self-supervised 3D Pose Transfer with Mesh and Point Contrastive Learning](http://arxiv.org/pdf/2304.13819v1)     
Summary: The paper presents a self-supervised framework for 3D pose transfer which can be trained in unsupervised, semi-supervised, or fully supervised settings without any correspondence labels. The framework uses two contrastive learning constraints in the latent space (a mesh-level loss for disentangling global patterns and a point-level loss for discriminating local semantics) and achieves state-of-the-art results in supervised 3D pose transfer, with comparable results in unsupervised and semi-supervised settings. The method is also generalizable to unseen human and animal data with complex topologies.

Title: [Metal Inter-layer Via Keep-out-zone in M3D IC: A Critical Process-aware Design Consideration](http://arxiv.org/pdf/2304.13808v1)     
Summary: This paper discusses the impact of Metal Inter-layer Via (MIV) on the performance of adjacent devices in Monolithic Three-Dimensional Integrated Circuits (M3D-IC) and the need for a keep-out-zone (KOZ) to ensure reliability. The study uses simulations to analyze the performance changes of transistors placed near MIV and shows that there can be an increase in leakage current, which can be reduced significantly by having a KOZ. The paper falls under the 3D category as it focuses on the impact of MIV on adjacent devices in M3D-IC technology.

</details>
<details>
<summary>Sound</summary>
    
Title: [XAI-based Comparison of Input Representations for Audio Event Classification](http://arxiv.org/pdf/2304.14019v1)     
Summary: This paper explores the effect of different input representations for Audio Event Classification using eXplainable AI (XAI) to understand the underlying classification strategies of models. Two model architectures are compared - one directly processes the raw waveform, while the other takes in its time-frequency spectrogram representation. The use of relevance heatmaps obtained via "Siren" helps uncover representation-dependent decision strategies. The paper confirms that the model's classification strategies align with human requirements and identifies the best input representation in terms of robustness and representativity.

Title: [Data-driven Balanced Truncation for Predictive Model Order Reduction of Aeroacoustic Response](http://arxiv.org/pdf/2304.13900v1)     
Summary: The paper proposes a data-driven model reduction approach for the rapid prediction of aeroacoustic response in aircraft and turbomachinery. The technique uses the eigensystem realization algorithm (ERA) as a balanced truncation method and compares ERA reduced-order models (ROMs) based on training data generated by solving the linearized and nonlinear Euler equations. The authors address the computational bottleneck of operating on a large Hankel matrix by proposing a multi-fidelity gappy POD method and using tangential interpolation at the ROM level. The proposed methods enable highly accurate online acoustic response prediction and reduce the offline computation cost of ROMs.

Title: [Text-to-Audio Generation using Instruction-Tuned LLM and Latent Diffusion Model](http://arxiv.org/pdf/2304.13731v1)     
Summary: The paper presents a novel approach, TANGO, for text-to-audio (TTA) generation, utilizing an instruction-tuned LLM as the text encoder and a latent diffusion model (LDM) for audio generation. The proposed method outperforms the state-of-the-art AudioLDM and stays comparable on most metrics on the AudioCaps test set, despite being trained on a smaller dataset and keeping the text encoder frozen. The improvement in performance may also be attributed to the adoption of audio pressure level-based sound mixing for training set augmentation.

</details>
<details>
<summary>Dataset</summary>
    
Title: [A transparent approach to data representation](http://arxiv.org/pdf/2304.14209v1)     
Summary: The paper proposes a binary attribute representation (BAR) model for describing a dataset of Netflix viewers' ratings of movies. This representation uses discrete bits to classify viewers and requires fewer attributes than similar methods to achieve the same level of error. The nonuniform distribution of ratings among the movies in the dataset is also taken advantage of in training on a small selection of movies without compromising performance on the rest of the movies.

Title: [DataComp: In search of the next generation of multimodal datasets](http://arxiv.org/pdf/2304.14108v1)     
Summary: The paper introduces DataComp, a benchmark for improving multimodal datasets. The benchmark entails proposing new training sets by designing new filtering techniques or curating new data sources and testing them on a standardized CLIP training code and evaluating on downstream test sets. The benchmark consists of various scales, facilitating the study of scaling trends and making the benchmark accessible to researchers with different resources. The paper also introduces DataComp-1B, a dataset that shows promising results by curating the training sets, enabling training CLIP ViT-L/14 from scratch to 79.2% zero-shot accuracy on ImageNet.

Title: [Mimic-IV-ICD: A new benchmark for eXtreme MultiLabel Classification](http://arxiv.org/pdf/2304.13998v1)     
Summary: In this paper, the authors propose a public benchmark suite for ICD-10 and ICD-9 coding using a large EHR dataset derived from MIMIC-IV. They implement and compare several popular methods for ICD coding prediction tasks to standardize data preprocessing and establish a comprehensive ICD coding benchmark dataset. This approach fosters reproducibility and model comparison, accelerating progress toward employing automated ICD coding in future studies. Furthermore, they provide open-source code that offers easy access to data processing steps, benchmark creation, and experiment replication for those with MIMIC-IV access.

Title: [A Review of Panoptic Segmentation for Mobile Mapping Point Clouds](http://arxiv.org/pdf/2304.13980v1)     
Summary: The paper reviews the state of panoptic segmentation of outdoor mobile-mapping data, which is the combined task of assigning semantic classes and separating them into object instances. The paper sets up a modular pipeline for comprehensive experiments and provides the first public dataset for the task, extending NPM3D dataset to include instance labels.

Title: [Adaptive-Mask Fusion Network for Segmentation of Drivable Road and Negative Obstacle With Untrustworthy Features](http://arxiv.org/pdf/2304.13979v1)     
Summary: The paper proposes an Adaptive-Mask Fusion Network for segmentation of drivable road and negative obstacles with untrustworthy features. The proposed network uses adaptive-weight masks to fuse features from RGB and depth images with inconsistency to overcome the issue caused by untrustworthy features. The authors also release a large-scale RGB-depth dataset with manually-labeled ground truth for drivable roads and negative obstacles segmentation. The proposed network achieves state-of-the-art performance compared to other networks.

Title: [The Structurally Complex with Additive Parent Causality (SCARY) Dataset](http://arxiv.org/pdf/2304.14109v1)     
Summary: The paper proposes a new synthetic causal dataset, the Structurally Complex with Additive paRent causalitY (SCARY) dataset, which includes 40 scenarios generated with two different data generation mechanisms for generating the causal relationship between parent and child nodes. The dataset has a Varsortability of 0.5 and offers a valuable resource for researchers to explore causal discovery under more realistic scenarios. The dataset is available at https://github.com/JayJayc/SCARY.

</details>
<details>
<summary>Theory</summary>
    
Title: [Generalized Automorphisms of Channel Codes: Properties, Code Design, and a Decoder](http://arxiv.org/pdf/2304.14379v1)     
Summary: The paper proposes a Generalized Automorphism Ensemble Decoder (GAED) based on the Definition of automorphisms from linear algebra. The paper presents an explicit joint construction of codes and automorphisms, which can improve the decoding performance of low-density parity-check codes in the short block length regime. The paper also demonstrates a code construction of parity-check codes for designing suitable automorphisms.

Title: [Universal Algebra for Generalised Metric Spaces](http://arxiv.org/pdf/2304.14361v1)     
Summary: The paper investigates a generalization of the quantitative algebra framework to include generalised metric spaces and operations that need not be non-expansive. The authors introduce a sound and complete deductive system and show that equationally defined classes of quantitative algebras have free objects, proving monadicity theorems. The paper falls under the category of theory.

Title: [On the Generalization Error of Meta Learning for the Gibbs Algorithm](http://arxiv.org/pdf/2304.14332v1)     
Summary: The paper analyzes the generalization error of joint-training meta learning algorithms, specifically the Gibbs algorithm, using symmetrized KL information. The authors provide an exact characterization of the expected meta generalization error for the meta Gibbs algorithm and derive a similar characterization for the super-task Gibbs algorithm. The results also enable the authors to provide distribution-free generalization error upper bounds for these Gibbs algorithms applicable to meta learning.

Title: [Pushing the Boundaries of Tractable Multiperspective Reasoning: A Deduction Calculus for Standpoint EL+](http://arxiv.org/pdf/2304.14323v1)     
Summary: This paper introduces Standpoint EL+, an extended logic that allows for the integrated representation of domain knowledge relative to diverse standpoints or perspectives while maintaining tractability. The paper achieves this by designing a satisfiability-checking deduction calculus that addresses the need for practical algorithms. Overall, the paper pushes the boundaries of tractable multiperspective reasoning.

Title: [Empirical Individual State Observability](http://arxiv.org/pdf/2304.14313v1)     
Summary: The paper introduces a new empirical approach called Empirical Individual State Observability (E-ISO) to determine the level of observability of individual state variables in a dynamical system. The approach involves building an empirical observability matrix via simulation, applying convex optimization to efficiently determine the subset of its rows required to estimate each state variable individually, and calculating (un)observability measures for these subsets. The paper provides multiple example applications of E-ISO on linear and nonlinear systems and shows that the results are consistent with analytical results. E-ISO can be useful for designing active sensing control laws or optimizing sensor placement to increase the observability of individual state variables for engineered systems and analyzing trajectory decisions made by organisms.

Title: [On Solution Discovery via Reconfiguration](http://arxiv.org/pdf/2304.14295v1)     
Summary: The paper proposes a new framework for constructing feasible solutions for a given problem by making small modifications starting from a given state. The framework integrates different aspects of classical local search, reoptimization, and combinatorial reconfiguration and is exemplified on several combinatorial problems. The paper also studies the complexity of solution discovery variants of those problems and explores the boundary between tractable and intractable instances.

Title: [Structured interpolation for multivariate transfer functions of quadratic-bilinear systems](http://arxiv.org/pdf/2304.14292v1)     
Summary: This paper proposes a method for constructing multivariate interpolants in the frequency domain for structured quadratic-bilinear systems. The goal is to reduce the computational cost of simulating large-scale nonlinear systems by constructing accurate reduced-order surrogates. The proposed method is based on interpolation-based model reduction and preserves the internal structure of weakly nonlinear systems. The theoretical results are demonstrated with two numerical examples, including the simulation of molecular dynamics in crystal structures.

Title: [A posteriori error estimates of Darcy flows with Robin-type jump interface conditions](http://arxiv.org/pdf/2304.14287v1)     
Summary: The paper presents an a posteriori error estimator for mixed finite element methods of Darcy flow problems with Robin-type jump interface conditions. The estimator is constructed using Stenberg post-processing and interface-adapted Helmholtz-type decomposition and interpolation operator. The paper proves the reliability of the estimator, and includes numerical results illustrating adaptivity algorithms using the estimator.

Title: [LDPC Decoders Prefer More Reliable Parity Bits: Unequal Data Protection Over BSC](http://arxiv.org/pdf/2304.14278v1)     
Summary: The paper investigates the value of engineering parity bits in LDPC decoders and measures them to be more reliable than message bits. It studies the impact of unequal data protection on the threshold of a regular LDPC code over binary symmetric channel (BSC) with different types of decoders. The analysis includes non-equiprobable inputs and doping of parity bits. The paper shows that unequal data protection leads to significant improvements in threshold and convergence speed, even with a simple decoder.

Title: [When Do Graph Neural Networks Help with Node Classification: Investigating the Homophily Principle on Node Distinguishability](http://arxiv.org/pdf/2304.14274v1)     
Summary: The paper investigates the role of homophily in the performance of Graph Neural Networks (GNNs) on Node Classification (NC) tasks. It demonstrates the insufficiency of considering only intra-class Node Distinguishability (ND) and proposes a Contextual Stochastic Block Model for Homophily (CSBM-H) to better understand the effect of homophily. Two metrics, Probabilistic Bayes Error (PBE) and Expected Negative KL-divergence (ENKL), are defined to quantify ND and visualize the results. The paper verifies that the superiority of GNNs is closely related to both intra- and inter-class ND regardless of homophily levels and proposes a new Kernel Performance Metric (KPM) to reveal the advantage and disadvantage of GNNs on synthetic and real-world datasets.

Title: [Variational Bayes Made Easy](http://arxiv.org/pdf/2304.14251v1)     
Summary: The paper presents a 3-step recipe for simplifying the derivation of Variational Bayes, a popular method for approximate inference. The recipe involves identifying the posterior form by looking for linearity with respect to expectations of well-known distributions and then writing the update by "reading-off" the terms in front of those expectations. This simplifies and speeds up the derivation process while also making it more general.

Title: [Standpoint Linear Temporal Logic](http://arxiv.org/pdf/2304.14243v1)     
Summary: The paper presents a new logic called Standpoint Linear Temporal Logic (SLTL) by combining the multi-perspective modelling capacity of Standpoint Logic (SL) with the temporal features of Linear Temporal Logic (LTL). SLTL is a formalism that enables temporal reasoning in multi-perspective settings by allowing one to reason with diverse and potentially conflicting viewpoints by means of indexed modalities. The paper defines the syntax and semantics of SLTL, establishes its decidability and complexity, and provides a terminating tableau calculus to automate SLTL reasoning. The paper also presents a clear path to extend existing LTL reasoners with practical reasoning support for temporal reasoning in multi-perspective settings.

Title: [The Mutual Information In The Vicinity of Capacity-Achieving Input Distributions](http://arxiv.org/pdf/2304.14219v1)     
Summary: This paper analyzes the mutual information in the vicinity of capacity-achieving input distributions using linear cost constraints and finite input/output sets. The mutual information is bounded above by a quadratic function and closed-form expressions for the threshold and coefficient of the quadratic decrease are derived. Implications for the channel coding problem and related problems are discussed.

Title: [A particle method for non-local advection-selection-mutation equations](http://arxiv.org/pdf/2304.14210v1)     
Summary: This academic paper proposes a particle method for non-local advection-selection-mutation equations, which is shown to have well-posedness for a wide range of initial data. The method approximates the solution by a regularised sum of weighted Dirac masses, with characteristics solving a defined ODE system. The paper proves the convergence of the particle method over any finite interval and investigates its asymptotic-preserving properties in large times. The paper also provides examples of the method's application in two cases from the literature.

Title: [Compact Distance Oracles with Large Sensitivity and Low Stretch](http://arxiv.org/pdf/2304.14184v1)     
Summary: The paper introduces a new type of data structure called an $f$-edge fault-tolerant distance sensitive oracle, which provides an estimate of the distance between two nodes in a graph even when some edges are removed. The paper presents an $f$-DSO with large sensitivity, low stretch, and subquadratic space complexity. The authors use approximate distance oracles and derandomization techniques to achieve their results. The paper falls under the categories of Graph Neural Networks and Theory.

Title: [Tractability of sampling recovery on unweighted function classes](http://arxiv.org/pdf/2304.14169v1)     
Summary: The paper discusses the tractability of sampling recovery on unweighted function classes, focusing on the curse of dimensionality problem in the $L_2$-norm on certain spaces. The authors show that intersecting these classes with the Wiener algebra of functions with summable Fourier coefficients can make the problem tractable, but nonlinear algorithms are required. The paper relies on previous work by Rauhut and Ward.

Title: [Hypothesis Testing for Adversarial Channels: Chernoff-Stein Exponents](http://arxiv.org/pdf/2304.14166v1)     
Summary: The paper focuses on studying the Chernoff-Stein exponent for binary hypothesis testing problem in the presence of adversarial channels with different types of randomness. The authors investigate the cases where the transmitter is deterministic, may privately randomize, and shares randomness with the detector that is unavailable to the adversary. The analysis shows that a memoryless transmission strategy is optimal under shared randomness but suboptimal when the transmitter has private randomness.

Title: [An Algorithm for Computing with Brauer's Group Equivariant Neural Network Layers](http://arxiv.org/pdf/2304.14165v1)     
Summary: This paper presents an algorithm for computing with Brauer's Group Equivariant Neural Network Layers. The algorithm uses category theoretic constructions and Kronecker product matrices to perform multiplication for the orthogonal group, special orthogonal group, symplectic group, and symmetric group. The approach is shown to extend to the symmetric group, recovering the algorithm of arXiv:2303.06208. The paper achieves a significant reduction in computational cost compared to a naive implementation.

Title: [Traced Types for Safe Strategic Rewriting](http://arxiv.org/pdf/2304.14154v1)     
Summary: The paper proposes a static type system for strategy languages to assist with correct composition of rewrite strategies. The system combines a structural type system with a novel tracing system to detect potential errors in strategy execution paths. The paper presents a formalization of the language and tracing type system, and proves its type soundness.

Title: [Multiplicity Problems on Algebraic Series and Context-Free Grammars](http://arxiv.org/pdf/2304.14145v1)     
Summary: The paper presents complexity bounds for computational problems on algebraic power series over several commuting variables, specified by systems of polynomial equations related to weighted context-free grammars. Three problems - identifying an algebraic series as identically zero, determining if only finitely many coefficients are zero, and computing the coefficient of a specific monomial - are related to well-known computational problems on arithmetic circuits and shown to lie in the counting hierarchy. The paper also covers new complexity bounds on various language models and image processing techniques.

Title: [Categorification of Group Equivariant Neural Networks](http://arxiv.org/pdf/2304.14144v1)     
Summary: This paper explores the use of category theory to understand and improve group equivariant neural networks. The authors develop a new algorithm for computing the results of vector passing through an equivariant, linear layer for different groups using category theoretic constructions. The success of this approach shows that category theory can be beneficial for other fields of deep learning.

Title: [Improved Online Scheduling of Moldable Task Graphs under Common Speedup Models](http://arxiv.org/pdf/2304.14127v1)     
Summary: The paper proposes a new online scheduling algorithm for moldable task graphs on multiprocessor systems to minimize the overall completion time (makespan), and derive constant competitive ratios under four common speedup models. The paper also provides lower bounds on the competitiveness of any online list scheduling algorithm, matching the competitive ratio of the proposed algorithm for three speedup models, and close to the ratio for the general model.

Title: [Universal Obstructions of Graph Parameters](http://arxiv.org/pdf/2304.14121v1)     
Summary: The paper introduces a graph-parametric framework for obtaining obstruction characterizations of graph parameters. The framework defines the notions of class obstruction, parametric obstruction, and universal obstruction as combinatorial objects that determine the asymptotic behavior of graph parameters. The paper surveys existing graph-theoretic results on most known graph parameters and provides some unifying results on their classification.

Title: [A Linearized L1-Galerkin FEM for Non-smooth Solutions of Kirchhoff type Quasilinear Time-fractional Integro-differential Equation](http://arxiv.org/pdf/2304.14100v1)     
Summary: The paper proposes a linearized numerical scheme for a Kirchhoff type quasilinear time-fractional integro-differential equation, which has a weak singularity near time t=0. The scheme is semi-discrete and fully discrete, and uses a weighted H1 norm to derive a priori bounds on the solution. Accuracy rates in L‚àû(0,T;L2(Œ©)) and L‚àû(0,T;H10(Œ©)) are proven, and the scheme is demonstrated to be efficient through numerical examples.

Title: [Optimal Covariance Cleaning for Heavy-Tailed Distributions: Insights from Information Theory](http://arxiv.org/pdf/2304.14098v1)     
Summary: The paper explores the relationship between optimal covariance cleaning theory and information theory for normal and Student's t distributions. While the minimal Frobenius norm is equivalent to minimizing the loss of information for normal distributions, this is not necessarily true for Student's t distributions. However, in the asymptotic regime of large matrices, this deviation disappears, which has implications for extending the applicability of random matrix theory to heavy-tailed distributions often encountered in real-world applications.

Title: [Categorical Foundations of Explainable AI: A Unifying Formalism of Structures and Semantics](http://arxiv.org/pdf/2304.14094v1)     
Summary: This paper proposes a formal and unifying theory of Explainable AI (XAI) using the framework of category theory and feedback monoidal categories. The authors provide formal definitions for all essential terms in XAI and propose a taxonomy of the field following the introduced structure. The proposed foundation represents a significant tool to properly frame future research lines and a precious guidance for new researchers approaching the field.

Title: [Structured level-2 condition numbers of matrix functions](http://arxiv.org/pdf/2304.14077v1)     
Summary: The paper investigates the structured level-2 condition numbers of matrix functions, specifically in cases where the perturbation matrix is restricted to certain groups or spaces. The study compares unstructured and structured condition numbers for specific matrix functions through numerical experiments.

Title: [A Parameterized Theory of PAC Learning](http://arxiv.org/pdf/2304.14058v1)     
Summary: The paper introduces a parameterized theory of PAC learning, filling a gap in the domain of sample complexity that did not have an analogue in the parameterized complexity paradigm. The theory identifies two distinct notions of fixed-parameter learnability that form counterparts to the class FPT, and develops the machinery required to exclude fixed-parameter learnability. The theory is applied to refine tractability boundaries for CNF and DNF learning, and for learning problems on graphs.

Title: [Unification of Lagrangian staggered-grid hydrodynamics and cell-centered hydrodynamics in one dimension](http://arxiv.org/pdf/2304.14054v1)     
Summary: This academic paper proposes a novel scheme to unify Lagrangian staggered-grid and cell-centered hydrodynamic methods in one dimension. The paper does not fall into any of the provided categories.

Title: [Localized orthogonal decomposition for a multiscale parabolic stochastic partial differential equation](http://arxiv.org/pdf/2304.14049v1)     
Summary: The paper proposes a multiscale method based on the localized orthogonal decomposition (LOD) technique for a parabolic stochastic partial differential equation with highly oscillatory diffusion and additive noise. The method computes a coarse representation of the elliptic operator enriched by fine-scale information on the diffusion, and optimal order strong convergence is obtained. The paper combines LOD with a Monte-Carlo estimator, and numerical examples confirm the theoretical findings and the computational efficiency of the method.

Title: [Discrete Weber inequalities and related Maxwell compactness for hybrid spaces over polyhedral partitions of domains with general topology](http://arxiv.org/pdf/2304.14041v1)     
Summary: This academic paper presents a proof for discrete versions of the first and second Weber inequalities on $\boldsymbol{H}(\mathbf{curl})\cap\boldsymbol{H}(\mathrm{div}_{\eta})$-like hybrid spaces over polyhedral partitions of domains with general topology. The results are optimal in terms of being formulated in $\boldsymbol{H}(\mathbf{curl})$- and $\boldsymbol{H}(\mathrm{div}_{\eta})$-like hybrid semi-norms and being valid for face polynomials in the smallest possible stability-compatible spaces. The paper also proves related discrete Maxwell compactness properties in a general topological setting.

Title: [communication of information in systems of heterogenious agents and systems' dynamics](http://arxiv.org/pdf/2304.14013v1)     
Summary: The paper discusses the communication of information in complex systems consisting of heterogeneous agents and its impact on the dynamics of the system. The study shows that the mechanisms of meaning and information processing can be evaluated analytically in a model framework, and the results accurately fit observed data from systems of different origins.

Title: [Explicit Constructions of Optimal $(r,Œ¥)$-Locally Repairable Codes](http://arxiv.org/pdf/2304.14011v1)     
Summary: The paper proposes a more general construction of locally repairable codes (LRCs) with $(r,\delta)$-locality, which have practical applications in distributed storage systems. The authors use MDS codes to give three classes of explicit constructions of optimal $(r,\delta)$-LRCs with block length beyond $q$. The paper extends the results of a previous work on optimal minimum distance LRCs and presents new LRCs with optimal parameters.

Title: [A barrier for further approximating Sorting By Transpositions](http://arxiv.org/pdf/2304.13996v1)     
Summary: This paper focuses on the Transposition Distance Problem (TDP) which seeks to determine the minimum number of transpositions needed to transform a linear chromosome into another represented by permutations. The paper investigates properties of palisades, a family of permutations that are "hard" to sort and determines their transposition distance. It provides the exact transposition diameter for a special subset of the Symmetric Group essential for the study of approximate solutions using the simplification technique. The paper also shows the implications of the transposition distance of palisades for the study of Sorting By Transpositions (SBT), implying that it is impossible to guarantee approximation ratios lower than 1.375 when approximating SBT.

Title: [An FPTAS for Budgeted Laminar Matroid Independent Set](http://arxiv.org/pdf/2304.13984v1)     
Summary: The paper presents an FPTAS (Fully Polynomial-Time Approximation Scheme) for the budgeted laminar matroid independent set problem, improving the previous EPTAS (Efficient Polynomial-Time Approximation Scheme) for this matroid family. The problem involves selecting a maximum profit independent set of a laminar matroid while keeping the total cost bounded by a given budget. The proposed scheme is based on a dynamic program utilizing the tree-like structure of laminar matroids and generalizes the FPTAS known for knapsack problems with a cardinality constraint and multiple-choice knapsack.

Title: [Noise Is Not the Main Factor Behind the Gap Between SGD and Adam on Transformers, but Sign Descent Might Be](http://arxiv.org/pdf/2304.13960v1)     
Summary: The paper investigates the performance gap between stochastic gradient descent (SGD) and Adam optimizer on language tasks. While previous work attributed the gap to heavy-tailed noise, the paper shows that stochasticity and heavy-tailed noise are not major factors in the performance gap. Instead, Adam outperforms SGD as batch size increases, while SGD is less effective at taking advantage of noise reduction. Further investigation suggests that the behavior of Adam with large batches is similar to sign descent with momentum.

Title: [A central scheme for coupled hyperbolic systems](http://arxiv.org/pdf/2304.13946v1)     
Summary: The paper presents a novel numerical scheme for solving coupled systems of conservation laws that is derived based on a relaxation approach. The coupling condition for the underlying relaxation system is discussed and well-posedness is analyzed. The scheme is validated using the p-system of gas dynamics as a case study.

Title: [A One-Dimensional Symmetric Force-Based Blending Method for Atomistic-to-Continuum Coupling](http://arxiv.org/pdf/2304.13939v1)     
Summary: This paper presents a new symmetric and consistent blended force-based Atomistic-to-Continuum (a/c) scheme for the atomistic chain in one-dimensional space. The paper analyzes the conditions for the well-posedness of the underlying model and establishes an optimal blending size and type to ensure the semi-norm stability for the blended force-based operator. Several numerical experiments are presented to test and confirm the theoretical findings.

Title: [Tight Upper Bounds on the Error Probability of Spinal Codes over Fading Channels](http://arxiv.org/pdf/2304.13910v1)     
Summary: The paper provides explicit and tight upper bounds on the error probability of Spinal codes under maximum-likelihood decoding and perfect channel state information over three fading channels. The derived upper bounds are verified to be tight through simulation results. The focus of the paper is on theoretical analysis rather than practical implementation or application in a specific field. Hence, it falls under the Theory category.

Title: [Proving Logical Atomicity using Lock Invariants](http://arxiv.org/pdf/2304.13898v1)     
Summary: This paper explores the use of older lock-invariant-based specifications for locks in proving logically atomic specifications for data structures with fine-grained locking. The authors compare this approach with one based on atomic specifications for locks and show that logical atomicity can still be proven using the older specs, but the proofs are more complex. The technique is implemented in the Verified Software Toolchain and applied to C implementations of lock-based concurrent data structures.

Title: [Structure-Aware Lower Bounds and Broadening the Horizon of Tractability for QBF](http://arxiv.org/pdf/2304.13896v1)     
Summary: The paper presents a study of the quantified Boolean formula (QBF) problem, which is a fundamental problem in computational complexity theory. The authors develop structure-aware reductions to obtain nearly tight lower bounds for highly restricted instances of QBF and complement these with novel algorithms that establish the problem's complexity under standard graph-theoretic parameterizations. The study broadens the understanding of the complexity of QBF under different representations of instances and provides implications for other natural graph representations.

Title: [The $n_s$-step Interpolatory (Quasi)-Stationary Subdivision Schemes and Their Interpolating Refinable Functions](http://arxiv.org/pdf/2304.13824v1)     
Summary: This paper introduces and studies $n_s$-step interpolatory M-subdivision schemes and their interpolating M-refinable functions with convergence and smoothness properties characterized. The paper also introduces the concept of $n_s$-step interpolatory quasi-stationary subdivision schemes and provides examples of convergent $n_s$-step interpolatory M-subdivision schemes with dilation factors $M=2,3,4$.

Title: [Backpropagation and F-adjoint](http://arxiv.org/pdf/2304.13820v1)     
Summary: The paper proposes a mathematical framework for studying feed-forward and backward propagation processes in deep neural networks. Based on the two-step rule for back-propagation, the authors introduce the F-adjoint concept aimed at better describing the backpropagation process. The study shows that the F-adjoint of the corresponding F-propagation characterizes the backpropagation process associated with any cost/loss function.

Title: [Verifying linear temporal specifications of constant-rate multi-mode systems](http://arxiv.org/pdf/2304.13816v1)     
Summary: The paper introduces a variant of linear temporal logic (LTL) for constant-rate multi-mode systems (MMS) and investigates the complexity of the model-checking problem for syntactic fragments of LTL. The paper obtains a complexity landscape where each fragment is either P-complete, NP-complete, or undecidable. The results generalize and unify several results on MMS and continuous counter systems.

Title: [The Hellan-Herrmann-Johnson and TDNNS method for linear and nonlinear shells](http://arxiv.org/pdf/2304.13806v1)     
Summary: The paper proposes an extension to the mixed Hellan-Herrmann-Johnson (HHJ) method for nonlinear Koiter shells to nonlinear Naghdi shells by a hierarchical approach. The proposed method is locking-free and can be applied to structures with kinks and branched shells. The method is validated through numerical examples and experiments. The paper falls under the category of theory.

Title: [Resampling Gradients Vanish in Differentiable Sequential Monte Carlo Samplers](http://arxiv.org/pdf/2304.14390v1)     
Summary: The paper proposes an extension to Differentiable AIS by adding a resampling step inspired by Sequential Monte Carlo to address the issue of low effective sample size and degenerate distributions in DAIS. The authors find that it is not necessary to differentiate through the resampling step, which avoids gradient variance issues observed in similar approaches for Particle Filters.

Title: [Detection of a very serious error in the paper: "On identifiability of nonlinear ODE models and applications in viral dynamics"](http://arxiv.org/pdf/2304.14288v1)     
Summary: The paper identifies a serious error in a highly cited article on the identifiability of nonlinear ODE models and its applications in viral dynamics. The paper proves the non-uniqueness of the three unidentifiable parameters and details the error made by the authors. It is important to notify this error to correct the false claim of local identifiability of all model parameters.

Title: [Comparison of Stochastic Parametrization Schemes using Data Assimilation on Triad Models](http://arxiv.org/pdf/2304.14216v1)     
Summary: The paper examines two stochastic parametrization schemes, namely Stochastic Advection by Lie Transport (SALT) and Location Uncertainty (LU), which are commonly used in modeling uncertainty in fluid dynamics models. The authors then compare reduced-order versions of these schemes, termed helicity-preserving stochastic triad (HST) and energy-preserving stochastic triad (EST), respectively. The models are considered as ideal benchmark models for testing new data assimilation algorithms, exhibiting diverse behaviors depending on the coefficients used and coming with natural physical properties such as the conservation of energy and helicity.

Title: [Exploring the flavor structure of quarks and leptons with reinforcement learning](http://arxiv.org/pdf/2304.14176v1)     
Summary: The paper proposes a method to use reinforcement learning to explore the flavor structure of quarks and leptons based on a policy-based algorithm for models with $U(1)$ symmetry. The agent trained on the $U(1)$ charges of quarks and leptons identifies 21 models consistent with experimentally measured masses and mixing angles. The paper predicts specific values of effective mass for neutrinoless double beta decay and leptonic CP violation through an autonomous behavior of the agent.

Title: [On the Discrete Logarithm Problem for elliptic curves over local fields](http://arxiv.org/pdf/2304.14150v1)     
Summary: The paper discusses an attack on the Discrete Logarithm Problem (DLP) for elliptic curves, which is the core of security for cryptosystems such as Elliptic Curve Cryptography (ECC). The attack is based on a connection between the DLP and lifting, using the exponential map for elliptic curves and its inverse over $ \mathbb{Z} / p^k \mathbb{Z} $. The paper also shows that hyperelliptic curves are resistant to this attack, offering a higher level of security compared to classic elliptic curves used in cryptography.

Title: [Revisiting Network Value: Sublinear Knowledge Law](http://arxiv.org/pdf/2304.14084v1)     
Summary: This paper introduces a novel concept called the sublinear knowledge law, which examines knowledge growth in citation networks and demonstrates that it is notably slower than traditional network growth as outlined by established laws such as Sarnoff's Law, Metcalfe's Law, and Reed's Law. The authors utilized the Deep-time Digital Earth academic literature to demonstrate the coexistence of these laws in citation networks. The results offer an innovative perspective on network value while also filling a gap in network research.

Title: [Counting unate and balanced monotone Boolean functions](http://arxiv.org/pdf/2304.14069v1)     
Summary: The paper focuses on counting the number of n-variable unate and monotone Boolean functions, and provides this count for n up to 6. It also provides the count for balanced 7-variable monotone Boolean functions.

Title: [Propagating Kernel Ambiguity Sets in Nonlinear Data-driven Dynamics Models](http://arxiv.org/pdf/2304.14057v1)     
Summary: This academic paper proposes an algorithm that propagates ambiguity sets through nonlinear data-driven models using the Koopman operator and CME, via the kernel maximum mean discrepancy geometry. The results show that their kernel ambiguity sets are the natural geometric structure for the learned data-driven dynamical system models. The paper is focused on addressing the problem of distributionally robust control and learning-based control of learned system models under data-distribution shift, and falls under the category of theory and data-driven modeling.

Title: [Convergence of Adam Under Relaxed Assumptions](http://arxiv.org/pdf/2304.13972v1)     
Summary: The paper provides a convergence proof for the Adam optimization algorithm, which is commonly used in deep learning, under more realistic assumptions than existing proofs. The proof shows that Adam converges to $\epsilon$-stationary points with $\mathcal{O}(\epsilon^{-4})$ gradient complexity. The key to the analysis is a new proof of boundedness of gradients along the optimization trajectory. A variance-reduced version of Adam with accelerated gradient complexity is also proposed.

Title: [Fairness Uncertainty Quantification: How certain are you that the model is fair?](http://arxiv.org/pdf/2304.13950v1)     
Summary: The paper introduces a method to construct confidence intervals for the fairness of learned models in fairness-aware machine learning, which is important for sensitive applications such as judiciary systems. The method extends theoretical guarantees for online bootstrap methods to constrained optimization and applies it to Disparate Impact and Disparate Mistreatment aware linear binary classifiers trained using online SGD-type algorithms. The results are demonstrated using synthetic and real datasets.

Title: [Improved Stabilizer Estimation via Bell Difference Sampling](http://arxiv.org/pdf/2304.13915v1)     
Summary: The paper presents results on the complexity of learning quantum states using stabilizer formalism, and uses Bell difference sampling as the underlying algorithmic primitive. The paper proves lower bounds on the number of gates required for preparing computationally pseudorandom quantum states, and gives an algorithm for estimating stabilizer fidelity of a given quantum state. The paper also improves the soundness analysis of stabilizer state property testing and exhibits a tolerant property testing algorithm for stabilizer states.

Title: [Typical and atypical solutions in non-convex neural networks with discrete and continuous weights](http://arxiv.org/pdf/2304.13871v1)     
Summary: The paper explores the geometry of the landscape of solutions in non-convex neural network models, specifically binary and continuous negative-margin perceptrons. It identifies the existence of subdominant minimizers that are extremely flat and wide and coexist with a background of dominant solutions. The study shows that when a certain threshold in constraint density is crossed, the local entropy of the wide flat minima becomes non-monotonic, indicating a break-up of the space of robust solutions into disconnected components. The paper also examines the impact of wide flat minimizers on the generalization performance as a learning device.

Title: [Adaptation to Misspecified Kernel Regularity in Kernelised Bandits](http://arxiv.org/pdf/2304.13830v1)     
Summary: The paper titled "Adaptation to Misspecified Kernel Regularity in Kernelised Bandits" discusses the adaptivity of learning algorithms to the regularity of associated kernel functions in continuum-armed bandit problems. The paper derives an adaptivity lower bound and connects the statistical difficulty for adaptivity in three fundamental types of function spaces: RKHS, Sobolev space, and H\"older space. This paper falls under the categories of Reinforcement learning and Theory.

Title: [Generalized generalized linear models: Convex estimation and online bounds](http://arxiv.org/pdf/2304.13793v1)     
Summary: The paper introduces a computational framework for estimating parameters in generalized generalized linear models (GGLM), a class of models that extends generalized linear models (GLM) to account for dependencies among observations in spatio-temporal data. The approach uses a monotone operator-based variational inequality method to overcome non-convexity in parameter estimation and provide guarantees for parameter recovery. The results can be applied to GLM and GGLM, focusing on spatio-temporal models. The paper also presents online instance-based bounds using martingale concentrations inequalities and demonstrates the performance of the algorithm using numerical simulations and a real data example for wildfire incidents.

Title: [Some Problems Concerning Quantum Channels and Entropies](http://arxiv.org/pdf/2304.13771v1)     
Summary: The paper explores fundamental limits on communication rates over quantum channels using entropic formulas, and discusses the challenges of computing these expressions. It also covers optimization and approximation of entropic formulas over subsets of quantum states, as well as progress made on a quantum erasure simulation problem in high noise environments.

Title: [Enhancing Robustness of Gradient-Boosted Decision Trees through One-Hot Encoding and Regularization](http://arxiv.org/pdf/2304.13761v1)     
Summary: The paper proposes a method to enhance the robustness of gradient-boosted decision trees (GBDT) by applying one-hot encoding to convert it into a linear framework, allowing for the use of linear regression techniques and a novel risk decomposition to assess the model's robustness against perturbations. The authors suggest enhancing the model's robustness by refitting the models with L1 or L2 regularization, and provide theoretical results on the effect of regularization on model performance and robustness. Numerical experiments demonstrate the proposed approach can enhance the robustness of one-hot-encoded GBDT models.

</details>
<details>
<summary>Natural Language Processing</summary>
    
Title: [ViMQ: A Vietnamese Medical Question Dataset for Healthcare Dialogue System Development](http://arxiv.org/pdf/2304.14405v1)     
Summary: The paper presents a Vietnamese dataset of medical questions from patients with sentence-level and entity-level annotations for the Intent Classification and Named Entity Recognition tasks. The dataset aims to facilitate the development of task-oriented healthcare chatbots with better comprehension of patient queries. The paper also proposes a self-supervised training strategy that improves the performance of baseline models. The dataset and code are publicly available.

Title: [LaMini-LM: A Diverse Herd of Distilled Models from Large-Scale Instructions](http://arxiv.org/pdf/2304.14402v1)     
Summary: The paper proposes a method called LaMini-LM that distills knowledge from instruction-trained Large Language Models (LLMs) to smaller ones. The authors developed a large set of diverse instructions and demonstrated that their LaMini-LM models of varying sizes are on par with competitive baselines while being nearly 10 times smaller in size. The proposed approach has applications in natural language processing tasks.

Title: [We're Afraid Language Models Aren't Modeling Ambiguity](http://arxiv.org/pdf/2304.14399v1)     
Summary: The paper discusses the importance of handling ambiguity in language models (LMs) and presents the AmbiEnt benchmark dataset for evaluating LM's ability to recognize and disentangle possible meanings. The authors find that even the latest state-of-the-art LM, GPT-4, struggles with this task, highlighting the need for more ambiguity-sensitive tools in NLP. The paper also demonstrates the potential practical applications of ambiguity detection in flagging misleading political claims.

Title: [string2string: A Modern Python Library for String-to-String Algorithms](http://arxiv.org/pdf/2304.14395v1)     
Summary: The paper introduces an open-source library called string2string, which offers a range of algorithms for string-to-string problems such as alignment, distance measurement, search, and similarity analysis. The library includes traditional and advanced neural approaches, as well as helpful visualization tools and metrics. The algorithms are implemented in Python and can be used for natural-language processing, bioinformatics, and computational social sciences applications. The library can increase flexibility and coverage compared to existing string libraries.

Title: [ZeroShotDataAug: Generating and Augmenting Training Data with ChatGPT](http://arxiv.org/pdf/2304.14334v1)     
Summary: The paper proposes using ChatGPT, a large generative language model, to generate synthetic training data with task-specific prompts for augmenting data in low-resource scenarios. The augmented data generated from ChatGPT outperforms existing approaches for data augmentation. Additionally, the paper investigates methodologies for evaluating the quality of the data generated.

Title: [Idioms, Probing and Dangerous Things: Towards Structural Probing for Idiomaticity in Vector Space](http://arxiv.org/pdf/2304.14333v1)     
Summary: This paper investigates how idiomatic information is structurally encoded in embeddings using a structural probing method. The authors perform a comparative study of static (GloVe) and contextual (BERT) embeddings on a repurposed English verbal multi-word expression dataset. The experiments reveal that both types of embeddings encode idiomatic information to varying degrees, but there is conflicting evidence as to whether idiomaticity is encoded in the vector norm. The study also identifies limitations of the dataset and suggests future directions for improving its suitability for a probing analysis.

Title: [AI, write an essay for me: A large-scale comparison of human-written versus ChatGPT-generated essays](http://arxiv.org/pdf/2304.14276v1)     
Summary: This paper compares human-written argumentative essays to those generated by the ChatGPT AI model. The study found that ChatGPT-generated essays were rated higher in quality than human-written essays and exhibited different linguistic characteristics. The paper argues that educators should incorporate AI models into the education system to free up time for other learning objectives.

Title: [Entity-Level Sentiment Analysis (ELSA): An exploratory task survey](http://arxiv.org/pdf/2304.14241v1)     
Summary: The paper investigates the task of Entity-Level Sentiment Analysis (ELSA) which is the identification of overall sentiment expressed towards volitional entities in longer texts. The authors annotate a set of professional reviews for their sentiment towards each volitional entity and evaluate existing models for document-level, sentence-level, and target-level sentiment analysis. The study shows that there is no single task that provides satisfactory performance for ELSA and calls for further research on the topic. The paper also provides a survey of previous relevant work.

Title: [The Intended Uses of Automated Fact-Checking Artefacts: Why, How and Who](http://arxiv.org/pdf/2304.14238v1)     
Summary: This academic paper discusses the intended uses of automated fact-checking artifacts and highlights the importance of thoroughly discussing the means, ends, and stakeholders involved. The analysis of 100 highly-cited papers reveals common vagueness and inconsistency in proposed strategies, hindering the technology from reaching its goals. The paper provides recommendations for thinking and writing about the use of fact-checking artifacts.

Title: [A Modular Approach for Multilingual Timex Detection and Normalization using Deep Learning and Grammar-based methods](http://arxiv.org/pdf/2304.14221v1)     
Summary: The paper presents a modular approach for multilingual temporal expression (timex) detection and normalization using deep learning and grammar-based methods. The system combines a fine-tuned Masked Language Model for detection and a grammar-based normalizer. The paper experiments in Spanish and English and compares with HeidelTime, the state-of-the-art in multilingual temporal processing. The results show the effectiveness of the proposed approach in gold timex normalization, timex detection, and type recognition. A detailed error analysis suggests the importance of detecting only those timexes for which it is feasible to provide normalization rules.

Title: [NAP at SemEval-2023 Task 3: Is Less Really More? (Back-)Translation as Data Augmentation Strategies for Detecting Persuasion Techniques](http://arxiv.org/pdf/2304.14179v1)     
Summary: The paper explores the use of (back-)translation as a data augmentation strategy for detecting persuasion techniques in news using multi-lingual transformer models. The results show that both data augmentation strategies boost performance, but balancing human-produced and machine-generated data is crucial.

Title: [ChatGPT vs State-of-the-Art Models: A Benchmarking Study in Keyphrase Generation Task](http://arxiv.org/pdf/2304.14177v1)     
Summary: This paper evaluates ChatGPT's keyphrase generation ability and compares its performance with state-of-the-art models on six publicly available datasets from scientific articles and news domains. The study finds that ChatGPT outperforms current state-of-the-art models in all tested datasets and environments, generating high-quality keyphrases that adapt well to diverse domains and document lengths.

Title: [Answering Uncertain, Under-Specified API Queries Assisted by Knowledge-Aware Human-AI Dialogue](http://arxiv.org/pdf/2304.14163v1)     
Summary: This paper presents a novel Knowledge-Aware Human-AI Dialogue (KAHAID) agent that assists developers in answering uncertain and under-specified API queries through multi-round question answering and API recommendations with relevance explanation and extended suggestions. The KAHAID agent was evaluated for its human-AI dialogue efficiency, API recommendation, and knowledge extension, and it outperformed existing state-of-the-art methods. The paper also includes a user study that shows how explainable API recommendations can help developers identify the best API approach more easily or confidently.

Title: [ChatLog: Recording and Analyzing ChatGPT Across Time](http://arxiv.org/pdf/2304.14106v1)     
Summary: This paper presents a temporal dataset called ChatLog, consisting of two parts - ChatLog-Monthly and ChatLog-Daily, to investigate how ChatGPT's behavior changes over time. The study conducts automatic and human evaluations to provide evidence for the existence of ChatGPT's evolving patterns and extracts its knowledge and linguistic features to analyze its unchanged characteristics over time. The paper also proposes stable features to improve the robustness of a RoBERTa-based detector on new versions of ChatGPT.

Title: [SweCTRL-Mini: a data-transparent Transformer-based large language model for controllable text generation in Swedish](http://arxiv.org/pdf/2304.13994v1)     
Summary: The paper presents SweCTRL-Mini, a large language model for controllable text generation in Swedish. The model is based on the CTRL architecture and can be fine-tuned and used for inference on a single GPU. The authors provide details on the training data and text pre-processing and evaluate the model's performance on discriminative and generative tasks. SweCTRL-Mini is open-source and available for download.

Title: [Controllable Data Augmentation for Context-Dependent Text-to-SQL](http://arxiv.org/pdf/2304.13902v1)     
Summary: The paper proposes a Controllable Data Augmentation method called ConDA to generate interactive questions and corresponding SQL results for context-dependent text-to-SQL. The proposed method enhances the diversity and quality of the augmented data by designing SQL dialogue state, filter method, and grounding model. The experiment shows that ConDA boosts the baseline model and generates high-quality data for SQL template hardness, types, turns, and question consistency.

Title: [Neural Keyphrase Generation: Analysis and Evaluation](http://arxiv.org/pdf/2304.13883v1)     
Summary: This paper focuses on analyzing and evaluating keyphrase generation using neural models. Three models, T5, CatSeq-Transformer, and ExHiRD, were analyzed for their performance and behavior during keyphrase generation. The paper also proposes a novel metric framework, SoftKeyScore, to evaluate keyphrase similarity. The study finds that SoftKeyScore is more suitable than the standard F1 metric for evaluating keyphrases.

Title: [MasonNLP+ at SemEval-2023 Task 8: Extracting Medical Questions, Experiences and Claims from Social Media using Knowledge-Augmented Pre-trained Language Models](http://arxiv.org/pdf/2304.13875v1)     
Summary: The paper describes the MasonNLP+ system developed for SemEval-2023 Task 8, which involves extracting medical questions, experiences, and claims from social media posts. The proposed system was based on language-model-based extraction and ranked third on both leaderboards. The paper also explores the use of domain-specific language models and external knowledge for automatic extraction.

Title: [Transferring Procedural Knowledge across Commonsense Tasks](http://arxiv.org/pdf/2304.13867v1)     
Summary: This paper proposes a framework called LEAP for transferring procedural knowledge across commonsense tasks in a transparent manner. The framework incorporates state-of-the-art modeling architectures, training regimes, and augmentation strategies based on both natural and synthetic stories. To address the lack of densely annotated training data, a robust automatic labeler based on few-shot prompting is devised for enhancing the augmented data. The experiments demonstrate insights into the interplay of different architectures, training regimes, and augmentation strategies. The LEAP's labeler positively impacts out-of-domain datasets, while the resulting dense annotation provides native explainability.

Title: [A Deep Learning Framework for Verilog Autocompletion Towards Design and Verification Automation](http://arxiv.org/pdf/2304.13840v1)     
Summary: The paper proposes a deep learning framework for Verilog autocompletion towards design and verification automation. The framework involves integrating models pretrained on general programming language data and finetuning them on a Verilog dataset of files and snippets obtained from open-source repositories. The proposed framework achieves better BLEU, ROUGE-L, and chrF scores by 9.5%, 6.7%, and 6.9%, respectively, compared to a model trained from scratch.

Title: [Translate to Disambiguate: Zero-shot Multilingual Word Sense Disambiguation with Pretrained Language Models](http://arxiv.org/pdf/2304.13803v1)     
Summary: The paper presents a study on how well Pretrained Language Models (PLMs) capture cross-lingual word sense knowledge with Contextual Word-Level Translation (C-WLT) and introduces a zero-shot approach for Word Sense Disambiguation (WSD) using PLMs. The study shows that as the model size increases, PLMs encode more cross-lingual word sense knowledge and better use context to improve WLT performance. The proposed zero-shot approach outperforms fully supervised baselines on recall for many evaluation languages without additional training or finetuning.

Title: [Fine Tuning with Abnormal Examples](http://arxiv.org/pdf/2304.13783v1)     
Summary: The paper proposes a methodology for pruning datasets in fine-tuning natural language processing models using abnormal examples, leading to better out of sample performance. The authors use the SQUAD dataset and identify 10,500 examples that create a more uniform distribution for training, resulting in improved performance when fine-tuning ELECTRA.

Title: [Evaluating Code Metrics in GitHub Repositories Related to Fake News and Misinformation](http://arxiv.org/pdf/2304.13769v1)     
Summary: The paper evaluates code metrics of Python repositories related to fake news and misinformation to improve awareness and understanding in the research community. The study found that more popular repositories and associated papers tend to have more maintainable code measures, more complex code paths, a larger number of lines of code, a higher Halstead effort, and fewer comments.

Title: [The Internal State of an LLM Knows When its Lying](http://arxiv.org/pdf/2304.13734v1)     
Summary: The paper proposes a method to detect the truthfulness of statements generated by Large Language Models (LLMs) using the LLM's internal state. They use the activation values in the hidden layer of LLM to determine if a statement is true or false. They compose a dataset of true and false statements and train a classifier that outperforms few-shot prompting methods. The paper has practical applicability in enhancing the reliability of LLM-generated content.

</details>
</details>


<details>
<summary>Thu, 27 Apr 2023</summary>
    
<details>
<summary>Diffusion Model</summary>
    
Title: [Fully Discrete Pointwise Smoothing Error Estimates for Measure Valued Initial Data](http://arxiv.org/pdf/2304.13694v1)     
Summary: The paper analyzes a homogeneous parabolic problem with initial data in the space of regular Borel measures. The problem is discretized in time with a discontinuous Galerkin scheme of arbitrary degree and in space with continuous finite elements of orders one or two. The main results are interior $L^\infty$ error estimates for the evaluation at the endtime, in cases where the initial data is supported in a subdomain.

Title: [Heuristic Barycenter Modeling of Fully Absorbing Receivers in Diffusive Molecular Communication Channels](http://arxiv.org/pdf/2304.13640v1)     
Summary: The paper presents a heuristic barycenter modeling approach to simulate diffusive molecular communication channels with multiple fully absorbing receivers by utilizing the concept of negative particle sources. The position of the barycenter is obtained from the mean of molecules reaching the surface of each receiver and can simplify further modeling of such systems. The approach is verified by comparing analytical results with particle-based simulation data.

Title: [DiffuseExpand: Expanding dataset for 2D medical image segmentation using diffusion models](http://arxiv.org/pdf/2304.13416v1)     
Summary: This paper proposes an approach called DiffuseExpand for expanding datasets for 2D medical image segmentation using Diffusion Probabilistic Models (DPMs). DiffuseExpand first samples a variety of masks from Gaussian noise to ensure diversity and then synthesizes images to ensure the alignment of images and masks. The effectiveness of DiffuseExpand is demonstrated through comparison and ablation experiments on COVID-19 and CGMH Pelvis datasets.

Title: [Event-triggered Boundary Control of a Class of Reaction-Diffusion PDEs with Time-dependent Reactivity](http://arxiv.org/pdf/2304.13322v1)     
Summary: This academic paper proposes an event-triggered boundary control strategy for a class of reaction-diffusion PDEs with time-varying reactivity under Robin actuation. The proposed approach includes a backstepping full-state feedback boundary controller and a dynamic event-triggering condition. The paper also establishes the well-posedness and global exponential convergence of the closed-loop system to zero in $L^2$-sense.

Title: [Score-based Generative Modeling Through Backward Stochastic Differential Equations: Inversion and Generation](http://arxiv.org/pdf/2304.13224v1)     
Summary: The paper proposes a novel score-based diffusion model through backward stochastic differential equations (BSDE), which can determine the initial conditions needed for a desired terminal distribution. The authors demonstrate the theoretical guarantees of the model, the benefits of using Lipschitz networks for score matching, and its potential applications in diffusion inversion, conditional diffusion, and uncertainty quantification. This work offers promising directions for solving real-world problems in score-based generative learning.

</details>
<details>
<summary>Large Language Models</summary>
    
Title: [Evaluation of GPT-3.5 and GPT-4 for supporting real-world information needs in healthcare delivery](http://arxiv.org/pdf/2304.13714v1)     
Summary: This paper evaluates the use of two general purpose large language models, GPT-3.5 and GPT-4, for answering questions in healthcare settings. The responses provided by the models were evaluated by physicians for safety and concordance with existing reports. Results showed that the models were largely safe, but responses often did not meet the specific information need of the question, suggesting the need for further research on prompt engineering, calibration, and custom-tailoring of the models.

Title: [Harnessing the Power of LLMs in Practice: A Survey on ChatGPT and Beyond](http://arxiv.org/pdf/2304.13712v2)     
Summary: This paper provides a practical guide for practitioners and end-users working with Large Language Models (LLMs) in their downstream natural language processing (NLP) tasks. The paper discusses the importance of pre-training data, training data, and test data, and provides a detailed discussion about the use and non-use cases of LLMs for various NLP tasks. The paper also explores the impact of spurious biases on LLMs and other essential considerations for deploying LLMs in practice. The authors aim to provide researchers and practitioners with valuable insights and best practices for working with LLMs.

Title: [HausaNLP at SemEval-2023 Task 12: Leveraging African Low Resource TweetData for Sentiment Analysis](http://arxiv.org/pdf/2304.13634v1)     
Summary: This paper presents the results of SemEval-2023 Task 12, a sentiment analysis task for low-resource African languages using Twitter data. The task had three subtasks, including a zero-shot sentiment classification. The study leveraged pre-trained large language models, including Afro-xlmr-large and BERT, for sentiment analysis in 14 African languages. The findings showed that Afro-xlmr-large performed better than the other models, and Nigerian languages had higher performance due to the larger volume of data. The paper also released the code on GitHub.

Title: [Shades of meaning: Uncovering the geometry of ambiguous word representations through contextualised language models](http://arxiv.org/pdf/2304.13597v1)     
Summary: This paper explores the challenge of lexical ambiguity and how it is represented in contextualized language models. The authors use simulations to show that these models can capture fine-grained distinctions between unambiguous, homonymous, and polysemous words, aligning with lexicographic classifications and psychological theories. The findings provide quantitative support for modern psychological conceptualizations of lexical ambiguity and raise new challenges for understanding the way contextual information shapes the meanings of words across different timescales.

Title: [Toxic comments reduce the activity of volunteer editors on Wikipedia](http://arxiv.org/pdf/2304.13568v1)     
Summary: This academic paper examines the impact of toxic speech on editors' behavior on Wikipedia. By analyzing 57 million comments made on user talk pages of 8.5 million editors, the paper finds that toxic comments consistently reduce the activity of editors and increase the risk of editors leaving the project altogether. The paper argues that mitigating toxic speech on collaborative platforms is essential for their continued success.

Title: [Multidimensional Evaluation for Text Style Transfer Using ChatGPT](http://arxiv.org/pdf/2304.13462v1)     
Summary: This paper investigates the use of ChatGPT as a multidimensional evaluator for text style transfer, comparing it to existing automatic metrics and human judgments. They focus on a zero-shot setting and test its performance on three dimensions of style transfer evaluation. The results show that ChatGPT achieved competitive correlations with human judgments and can be a useful tool in the multidimensional evaluation of stylized text generation.

Title: [Unleashing Infinite-Length Input Capacity for Large-scale Language Models with Self-Controlled Memory System](http://arxiv.org/pdf/2304.13343v1)     
Summary: The paper proposes a Self-Controlled Memory (SCM) system to enable large-scale language models (LLMs) to process ultra-long texts without modification or fine-tuning. The SCM system is composed of three modules: the language model agent, the memory stream, and the memory controller. The experimental results show that the SCM system enables LLMs to achieve multi-turn dialogue capabilities and outperform ChatGPT in scenarios involving ultra-long document summarization or long-term conversations.

Title: [A Case-Based Reasoning Framework for Adaptive Prompting in Cross-Domain Text-to-SQL](http://arxiv.org/pdf/2304.13301v1)     
Summary: The paper proposes a Case-Based Reasoning framework named CBR-ApSQL for adaptive prompting in Text-to-SQL tasks. The framework combines with GPT-3.5 and adapts to retrieve cases and control case-relevant and case-irrelevant knowledge. The proposed approach outperforms the state-of-the-art model in execution accuracy for three different cross-domain datasets.

Title: [The Closeness of In-Context Learning and Weight Shifting for Softmax Regression](http://arxiv.org/pdf/2304.13276v1)     
Summary: The paper studies the in-context learning ability of Transformers in natural language processing tasks. The authors show the upper bounds of the data transformations induced by a single self-attention layer and by gradient-descent on a regression loss for softmax prediction function. The results imply that when training self-attention-only Transformers for regression tasks, the models learned by gradient-descent and Transformers show great similarity.

Title: [Exploring the Curious Case of Code Prompts](http://arxiv.org/pdf/2304.13250v1)     
Summary: The paper examines the effectiveness of code prompts versus text prompts when interacting with language models. The authors compare the performance of code and text prompts across various tasks and find that, with a few exceptions, code prompts do not consistently outperform text prompts. The authors also show that the style of code prompt has a large effect on performance for some tasks, and that fine-tuning on text instructions leads to better relative performance of code prompts. Overall, the paper contributes to our understanding of how language models interact with different input types and provides insights into the use of code prompts for structured reasoning tasks.

Title: [TABLET: Learning From Instructions For Tabular Data](http://arxiv.org/pdf/2304.13188v1)     
Summary: The paper introduces a benchmark dataset, called TABLET, consisting of 20 diverse tabular datasets annotated with natural language instructions for solving tabular prediction problems using large language models (LLMs). The study finds that in-context instructions improve the zero-shot F1 performance of Flan-T5 11b and ChatGPT on TABLET. However, LLMs often ignore instructions and fail to predict specific instances correctly, even with examples, indicating the need for new capabilities in learning from instructions for tabular data.

Title: [AI-assisted coding: Experiments with GPT-4](http://arxiv.org/pdf/2304.13187v1)     
Summary: The paper reports experiments using GPT-4 to generate computer code and demonstrates that AI code generation can significantly improve the quality of code, but requires substantial human validation to ensure accuracy. The findings suggest that while AI coding tools are powerful, they still require humans in the loop to ensure validity and accuracy of the results.

Title: [Generative Relevance Feedback with Large Language Models](http://arxiv.org/pdf/2304.13157v1)     
Summary: The paper proposes Generative Relevance Feedback (GRF), a probabilistic feedback model that generates long-form text from Large Language Models to improve document retrieval effectiveness. The paper studies effective methods for generating text by varying subtasks: queries, entities, facts, news articles, documents, and essays. The authors evaluate GRF on diverse document retrieval benchmarks and show that it significantly outperforms previous pseudo-relevance feedback methods, improving MAP between 5-19% and NDCG@10 17-24% compared to RM3 expansion. The paper contributes to research on large language models and query expansion for document retrieval.

</details>
<details>
<summary>Image Reconstruction</summary>
    
Title: [Multi-View Stereo Representation Revisit: Region-Aware MVSNet](http://arxiv.org/pdf/2304.13614v2)     
Summary: The paper proposes a region-aware MVSNet for multi-view stereo representation that predicts a distance volume from the cost volume to estimate the signed distance of points around the surface, enhancing the perception range, completing textureless regions, reducing outliers at boundaries, and generating mesh topologies with fine details. The approach achieves state-of-the-art results on both DTU and Tanks & Temples datasets, demonstrating its effectiveness in reconstructing complete geometrically-detailed objects from multi-views.

Title: [Neural-PBIR Reconstruction of Shape, Material, and Illumination](http://arxiv.org/pdf/2304.13445v1)     
Summary: This paper introduces a robust object reconstruction pipeline combining neural based object reconstruction and physics-based inverse rendering. The pipeline produces high-quality object shape, reflectance, and illumination predictions using a neural stage, which are then refined using the physics-based inverse rendering stage. The pipeline significantly outperforms existing reconstruction methods in both quality and performance.

Title: [Streamlined Global and Local Features Combinator (SGLC) for High Resolution Image Dehazing](http://arxiv.org/pdf/2304.13375v1)     
Summary: This paper proposes a Streamlined Global and Local Features Combinator (SGLC) to address the issue of accurately dehazing high-resolution images. The SGLC contains two blocks - Global Features Generator (GFG) and Local Features Enhancer (LFE) - to combine global and local features in a streamlined manner. Tested on the Uformer architecture, SGLC significantly improved the PSNR metric. This approach can be applied to other dehazing models for high-resolution input data.

Title: [Discrepancy-Guided Reconstruction Learning for Image Forgery Detection](http://arxiv.org/pdf/2304.13349v1)     
Summary: The paper proposes a novel image forgery detection paradigm that uses a Discrepancy-Guided Encoder (DisGE) and a Double-Head Reconstruction (DouHR) module to extract forgery-sensitive visual patterns and enhance genuine compact visual patterns in different granular spaces, respectively. The proposed method also includes a Discrepancy-Aggregation Detector (DisAD) to aggregate these patterns for improved forgery detection capability on unknown patterns. The effectiveness of the proposed approach is validated through extensive experimental results on four challenging datasets.

</details>
<details>
<summary>Medical Image</summary>
    
Title: [A marker-less human motion analysis system for motion-based biomarker discovery in knee disorders](http://arxiv.org/pdf/2304.13678v1)     
Summary: The paper proposes a marker-less system for motion-based biomarker discovery in knee disorders using standard RGB cameras. Biomarkers are identified using Principal Component Analysis (PCA) and validated as statistically significant through a case study. The system provides a cheap and sensitive alternative to current commercial alternatives for analyzing biomechanics and tracking rehabilitation progress.

Title: [FVP: Fourier Visual Prompting for Source-Free Unsupervised Domain Adaptation of Medical Image Segmentation](http://arxiv.org/pdf/2304.13672v1)     
Summary: The paper proposes Fourier Visual Prompting (FVP), a method for Source-Free Unsupervised Domain Adaptation (SFUDA) of medical image segmentation. FVP adds a visual prompt to input target data, which is learned by minimizing the segmentation loss, and steers the frozen pre-trained model to perform well in the target domain. The proposed method is validated using three public datasets, and experiments show that FVP yields better segmentation results compared to various existing methods.

Title: [Non-rigid Point Cloud Registration for Middle Ear Diagnostics with Endoscopic Optical Coherence Tomography](http://arxiv.org/pdf/2304.13618v1)     
Summary: The paper proposes a non-rigid point cloud registration pipeline, C2P-Net, for merging ex-vivo middle ear models with in-vivo OCT volumetric data to facilitate fast diagnosis and measurement of middle ear infection. The pipeline is capable of handling realistic noise and incompleteness in synthetic and real OCT data. The proposed method can support the interpretation of in-vivo noisy and partial OCT images for the first time.

Title: [Cluster Entropy: Active Domain Adaptation in Pathological Image Segmentation](http://arxiv.org/pdf/2304.13513v1)     
Summary: The paper proposes a method for semi-supervised domain adaptation in pathological image segmentation by introducing a cluster entropy measure for selecting an effective whole slide image (WSI). The cluster entropy method calculates the entropy of each cluster to measure the image features of the WSI and covers the entire distribution of the target domain. The proposed method achieves competitive results against prior arts on datasets collected from two hospitals.

Title: [A Secure Medical Record Sharing Scheme Based on Blockchain and Two-fold Encryption](http://arxiv.org/pdf/2304.13511v1)     
Summary: The paper proposes a blockchain-based secure medical record sharing system that encrypts data using both an asymmetric cryptosystem and dynamic DNA encoding. The encrypted data is stored in distinct blocks designated for each user in the blockchain to ensure data integrity. The proposed scheme enables authorized entities to regain the electronic medical record through decryption. Preliminary evaluations show the efficacy of the scheme.

Title: [Towards clinical AI fairness: A translational perspective](http://arxiv.org/pdf/2304.13493v1)     
Summary: This paper discusses the issue of fairness in artificial intelligence (AI) in the field of healthcare. It highlights the misalignment between technical and clinical perspectives on AI fairness and provides possible solutions to address clinical concerns. The paper advocates for multidisciplinary collaboration to bridge the knowledge gap and ensure fairness in AI in healthcare.

Title: [Effect of latent space distribution on the segmentation of images with multiple annotations](http://arxiv.org/pdf/2304.13476v1)     
Summary: The paper proposes the Generalized Probabilistic U-Net for image segmentation with multiple annotations. The extension allows for more general forms of the Gaussian distribution in the latent space, improving the uncertainty estimation in reference segmentations. The study shows that the choice of distribution affects sample diversity and overlap with reference segmentations for lung tumors and brain white matter hyperintensities. Implementation is available on Github.

Title: [GENIE-NF-AI: Identifying Neurofibromatosis Tumors using Liquid Neural Network (LTC) trained on AACR GENIE Datasets](http://arxiv.org/pdf/2304.13429v1)     
Summary: This paper proposes an AI approach using logistic regression and black box models to diagnose neurofibromatosis tumors using blood tests and pathogenic variables. The models outperformed existing approaches in accuracy. The study demonstrates the potential of AI in the medical field.

Title: [Learnable Ophthalmology SAM](http://arxiv.org/pdf/2304.13425v1)     
Summary: The paper proposes a learnable prompt layer named Learnable Ophthalmology Segment Anything (SAM) for multiple target segmentation in ophthalmology multi-modal images. The prompt layer learns medical prior knowledge from each transformer layer and is trained based on a one-shot mechanism. The paper demonstrates the effectiveness of this approach on four medical segmentation tasks using nine publicly available datasets. The paper falls under the categories of Image Segmentation, Medical Image, Transformer, and Few-Shot/Zero-Shot Learning.

Title: [DiffuseExpand: Expanding dataset for 2D medical image segmentation using diffusion models](http://arxiv.org/pdf/2304.13416v1)     
Summary: This paper proposes an approach called DiffuseExpand for expanding datasets for 2D medical image segmentation using Diffusion Probabilistic Models (DPMs). DiffuseExpand first samples a variety of masks from Gaussian noise to ensure diversity and then synthesizes images to ensure the alignment of images and masks. The effectiveness of DiffuseExpand is demonstrated through comparison and ablation experiments on COVID-19 and CGMH Pelvis datasets.

Title: [Robust One-Step Estimation of Impulsive Time Series](http://arxiv.org/pdf/2304.13394v1)     
Summary: The paper presents a one-step estimation algorithm for impulsive time series modeling, commonly found in biomedical data like hormone secretion. The algorithm uses a linear plant driven by a train of Dirac impulses to model the impulsive input. It effectively resolves the trade-off between data fit and impulsive input sparsity and is improved to handle outliers and unknown basal levels. The algorithm is evaluated on synthetic and clinical data and produces more accurate results through the use of an information criterion.

Title: [Blockchain-based Federated Learning with SMPC Model Verification Against Poisoning Attack for Healthcare Systems](http://arxiv.org/pdf/2304.13360v1)     
Summary: The paper proposes a blockchain-based federated learning framework for healthcare systems. The framework includes an SMPC model verification process to detect and remove malicious updates from FL clients. The proposed approach is evaluated using various medical datasets.

Title: [Understanding the Security and Performance of the Web Presence of Hospitals: A Measurement Study](http://arxiv.org/pdf/2304.13278v1)     
Summary: This academic paper presents a measurement-based analysis of the web presence of hospitals, with a focus on security attributes. The study examines characteristics of government, non-profit, and proprietary hospitals' utilization of domain name registrars, top-level domain distribution, and content type, as well as HTTP request features. The findings indicate a lack of basic security in many hospitals' websites, with only 1% of government hospitals utilizing DNSSEC and 25% using plain HTTP. Furthermore, the study connects these attributes with data breaches, highlighting that security attributes are a strong indicator of the likelihood of a hospital being breached.

Title: [Towards Reliable Colorectal Cancer Polyps Classification via Vision Based Tactile Sensing and Confidence-Calibrated Neural Networks](http://arxiv.org/pdf/2304.13192v1)     
Summary: The paper proposes a confidence-calibrated residual neural network for reliable colorectal cancer polyps classification by utilizing a vision-based tactile sensing system. The model addresses over-confident outputs via post-processing of temperature scaling and is evaluated for non-ideal inputs through reliability diagrams and statistical metrics.

Title: [Towards Explainable and Safe Conversational Agents for Mental Health: A Survey](http://arxiv.org/pdf/2304.13191v1)     
Summary: This paper presents a survey of existing conversational agents in mental health and discusses the need for a more comprehensive, safe, and explainable approach to build responsible Virtual Mental Health Assistants (VMHAs). The paper proposes new directions towards enriching the user experience of VMHAs with explainability, safety, and wholesome trustworthiness. The paper also offers evaluation metrics and practical considerations for VMHAs beyond current literature to build trust between VMHAs and patients in active communications.

Title: [Sample-Specific Debiasing for Better Image-Text Models](http://arxiv.org/pdf/2304.13181v1)     
Summary: This paper proposes a sample-specific debiasing approach to improve the quality of learned representations in self-supervised image-text representation learning for medical applications. The approach corrects for false negatives by using estimated sample-specific class probabilities. The paper provides theoretical analysis and empirical evidence of the advantages of the proposed approach.

Title: [An explicit Fourier-Klibanov method for an age-dependent tumor growth model of Gompertz type](http://arxiv.org/pdf/2304.13177v1)     
Summary: The paper proposes a new explicit Fourier-Klibanov method to approximate an age-dependent tumor growth model of Gompertz type in brain tissue. The method involves nonlinear and linear transformations, and a coupled transport-like PDE system is obtained using Fourier-Klibanov method, and approximated by explicit finite difference operators of characteristics. The resulting difference scheme's stability is analyzed, and the paper presents some computational results demonstrating the method's effectiveness.

</details>
<details>
<summary>Image Classification</summary>
    
Title: [UniNeXt: Exploring A Unified Architecture for Vision Recognition](http://arxiv.org/pdf/2304.13700v1)     
Summary: The paper proposes UniNeXt, a unified architecture for the vision backbone that can significantly improve the performance of various spatial token mixers, regardless of their design. The study shows the importance of the general architecture of vision recognition and suggests that an excellent spatial token mixer may be stifled by a suboptimal general architecture. UniNeXt equipped with naive local window attention even outperforms the previous state-of-the-art.

Title: [A marker-less human motion analysis system for motion-based biomarker discovery in knee disorders](http://arxiv.org/pdf/2304.13678v1)     
Summary: The paper proposes a marker-less system for motion-based biomarker discovery in knee disorders using standard RGB cameras. Biomarkers are identified using Principal Component Analysis (PCA) and validated as statistically significant through a case study. The system provides a cheap and sensitive alternative to current commercial alternatives for analyzing biomechanics and tracking rehabilitation progress.

Title: [PVP: Pre-trained Visual Parameter-Efficient Tuning](http://arxiv.org/pdf/2304.13639v1)     
Summary: This paper proposes a Pre-trained Visual Parameter-efficient (PVP) Tuning framework for fine-tuning pre-trained transformers in a parameter-efficient manner. The proposed method pre-trains the parameter-efficient tuning modules first and then combines them with the pre-trained transformer backbone to perform efficient tuning on downstream tasks. Experimental results show that PVP outperforms state-of-the-art Parameter-Efficient Tuning (PETuning) methods in low-data regimes on five Fine-Grained Visual Classification and VTAB-1k datasets.

Title: [Tensor Decomposition for Model Reduction in Neural Networks: A Review](http://arxiv.org/pdf/2304.13539v1)     
Summary: The paper reviews six tensor decomposition methods and their ability to reduce the computational cost of over-parameterized neural networks used in computer vision and natural language processing tasks. The review includes evaluations on compressed models with improved accuracy, reduced model size, run-time, and energy consumption. This approach is well-suited for implementing neural networks in edge devices.

Title: [ElegansNet: a brief scientific report and initial experiments](http://arxiv.org/pdf/2304.13538v1)     
Summary: 
The paper introduces ElegansNet, a neural network architecture inspired by the connectome of the Caenorhabditis elegans worm. The network topology of the worm is used to design and generate improved deep learning systems, which are compared against both randomly wired networks and state-of-the-art artificial neural networks. ElegansNet outperforms randomly wired networks and achieves top-1 accuracy of 99.99% on Cifar10 and 99.84% on MNIST Unsup on the validation sets in supervised image classification tasks and unsupervised hand-written digits reconstruction. The study explores the interplay between connectome topology and deep learning systems, showcasing the potential of bio-plausible structures in efficiently solving complex tasks.

Title: [Konzeption und Umsetzung einer mobilen Applikation zur Validierung von f√§lschungssicheren Produktlabeln](http://arxiv.org/pdf/2304.13519v1)     
Summary: The paper proposes a cost-effective way to verify the authenticity of a product using a counterfeit-proof label composed of gold nanospheres or rods. The label's unique positions of elements can be measured precisely using a smartphone camera and additional technologies. The paper presents a proof of concept for implementing this system in a mobile application and outlines suitable methods to transmit and secure the required information. The results of validating counterfeit-proof product labels are analyzed, and existing weaknesses are pointed out.

Title: [Efficient Explainable Face Verification based on Similarity Score Argument Backpropagation](http://arxiv.org/pdf/2304.13409v1)     
Summary: This paper proposes an efficient and explainable approach, called xSSAB, for face verification that back-propagates similarity score-based arguments to visualize spatial maps indicating similar and dissimilar areas. The authors also introduce a new benchmark dataset and evaluation protocol for explainable face verification. Their approach achieves a superior trade-off between efficiency and performance compared to state-of-the-art techniques. The paper falls under the categories of Image Classification and Explainable AI.

Title: [Towards Reliable Colorectal Cancer Polyps Classification via Vision Based Tactile Sensing and Confidence-Calibrated Neural Networks](http://arxiv.org/pdf/2304.13192v1)     
Summary: The paper proposes a confidence-calibrated residual neural network for reliable colorectal cancer polyps classification by utilizing a vision-based tactile sensing system. The model addresses over-confident outputs via post-processing of temperature scaling and is evaluated for non-ideal inputs through reliability diagrams and statistical metrics.

</details>
<details>
<summary>Image Registration</summary>
    
</details>
<details>
<summary>Reinforcement learning</summary>
    
Title: [Learning Agile Soccer Skills for a Bipedal Robot with Deep Reinforcement Learning](http://arxiv.org/pdf/2304.13653v1)     
Summary: The paper explores the use of Deep Reinforcement Learning to train a humanoid robot to play soccer. Individual movement skills were trained in isolation and then composed for the game in a self-play setting. The resulting policy exhibited robust and dynamic movement skills and a basic strategic understanding of the game. The agents were trained in simulation and transferred to real robots. Combining high-frequency control, targeted dynamics randomization, and perturbations during training in simulation enabled good-quality transfer, despite significant unmodeled effects and variations across robot instances.

Title: [CROP: Towards Distributional-Shift Robust Reinforcement Learning using Compact Reshaped Observation Processing](http://arxiv.org/pdf/2304.13616v1)     
Summary: This paper proposes a technique called Compact Reshaped Observation Processing (CROP) to improve the generalization capabilities of reinforcement learning. CROP reduces the state information used for policy optimization by providing only relevant information, which precludes overfitting to a specific training layout and improves generalization to unseen environments. The authors provide three CROPs that can be applied to fully observable observation- and action-spaces and empirically show the improvements of CROP in a distributionally shifted safety gridworld. They also provide benchmark comparisons to full observability and data-augmentation in two different-sized procedurally generated mazes.

Title: [Safe Q-learning for continuous-time linear systems](http://arxiv.org/pdf/2304.13573v1)     
Summary: The paper proposes a safe Q-learning algorithm for partially unknown linear time-invariant systems to solve the linear quadratic regulator problem with user-defined state constraints. The problem is framed as a constrained optimal control problem using reciprocal control barrier functions, providing a safety-assured control policy. The proposed method extends Q-learning to continuous-time systems with state constraints, which hasn't been reported in the literature before.

Title: [Learning to Bid in Repeated First-Price Auctions with Budgets](http://arxiv.org/pdf/2304.13477v1)     
Summary: The paper discusses the problem of budget management in repeated first-price auctions in online advertising markets. It proposes a dual-based algorithm with full information feedback and shows that it can achieve a nearly optimal regret with a complexity of $\widetilde{O}(\sqrt{T})$. The paper also considers the setting with one-sided information feedback and presents a modified algorithm that can achieve an $\widetilde{O}(\sqrt{T})$ regret. Theoretical results are complemented with numerical experiments to confirm the effectiveness of the proposed budget management policy.

Title: [Optimizing Energy Efficiency in Metro Systems Under Uncertainty Disturbances Using Reinforcement Learning](http://arxiv.org/pdf/2304.13443v2)     
Summary: The paper proposes a policy-based reinforcement learning approach to optimize energy efficiency in metro systems under disturbances by adjusting the train timetable and the dwell time and cruise speed of trains. The experiments conducted in a simulation environment demonstrate the superiority of the method in achieving a traction energy consumption reduction of up to 10.9% and an increase in regenerative braking energy utilization of up to 47.9%.

Title: [FLEX: an Adaptive Exploration Algorithm for Nonlinear Systems](http://arxiv.org/pdf/2304.13426v1)     
Summary: The paper introduces FLEX, an adaptive exploration algorithm for nonlinear systems in the context of model-based reinforcement learning. The algorithm employs optimal experimental design to maximize information of the next step and minimize the amount of data required to fit an accurate model of the system. FLEX is shown to be effective on a number of nonlinear environments and also competitive in downstream model-based classical control tasks with low computational cost.

Title: [Can Agents Run Relay Race with Strangers? Generalization of RL to Out-of-Distribution Trajectories](http://arxiv.org/pdf/2304.13424v1)     
Summary: The paper proposes a method to improve the "relay-generalization" performance of reinforcement learning agents on out-of-distribution controllable states. The authors demonstrate the prevalence of generalization failure on controllable states from stranger agents and propose a novel method called Self-Trajectory Augmentation (STA) to reduce the failure rate without impacting agent performance. The proposed method is evaluated on the Humanoid environment and the results show a significant improvement in relay-evaluation.

Title: [N$\text{A}^\text{2}$Q: Neural Attention Additive Model for Interpretable Multi-Agent Q-Learning](http://arxiv.org/pdf/2304.13383v1)     
Summary: The paper introduces a new neural attention additive Q-learning (N$\text{A}^\text{2}$Q) method for cooperative multi-agent reinforcement learning that provides interpretable collaboration behavior. The method uses generalized additive models to factorize the joint policy into individual policies and construct identity semantics for estimating credits. Extensive experiments show superior performance compared to state-of-the-art methods on challenging tasks while maintaining human-like interpretability.

Title: [Game-based Platforms for Artificial Intelligence Research](http://arxiv.org/pdf/2304.13269v1)     
Summary: The paper reviews the game-based platforms for artificial intelligence research that have been implemented for studying various research areas, including learning and optimization, decision making, game theory, planning, scheduling, design, and education. These platforms provide ideal benchmarks for exploring and comparing artificial intelligence ideas and techniques. The paper discusses the research trend induced by the evolution of those platforms, and gives an outlook for future research in this area.

Title: [Multi-criteria Hardware Trojan Detection: A Reinforcement Learning Approach](http://arxiv.org/pdf/2304.13232v1)     
Summary: The paper proposes a multi-criteria Hardware Trojan (HT) detection tool that uses reinforcement learning to detect HTs based on different design criteria. The tool features a tunable reward function that allows for exploring existing detection strategies and adapting new detection scenarios with minimal effort. The proposed methodology for comparing HT detection methods fairly showed an average of 84.2% successful HT detection in the ISCAS-85 benchmark.

Title: [Cooperative Hierarchical Deep Reinforcement Learning based Joint Sleep, Power, and RIS Control for Energy-Efficient HetNet](http://arxiv.org/pdf/2304.13226v1)     
Summary: This paper proposes a cooperative hierarchical deep reinforcement learning (Co-HDRL) algorithm for energy-efficient heterogeneous networks (HetNets) using reconfigurable intelligent surfaces (RIS). The algorithm includes a cross-entropy enabled meta-controller for sleep control and correlated equilibrium-based sub-controllers for power control. The simulations show that the RIS-assisted sleep control can achieve more than 16% lower energy consumption and 30% higher energy efficiency than baseline algorithms.

Title: [Reinforcement Learning with Partial Parametric Model Knowledge](http://arxiv.org/pdf/2304.13223v1)     
Summary: The paper proposes a method called Partial Knowledge Least Squares Policy Iteration (PLSPI) that combines model-free RL and model-based control to adapt RL methods for continuous control with incomplete information from a partial model. The effectiveness of the proposed method is demonstrated through numerical experiments using the linear quadratic regulator.

Title: [Dynamic Datasets and Market Environments for Financial Reinforcement Learning](http://arxiv.org/pdf/2304.13174v1)     
Summary: The paper presents FinRL-Meta, an open-source library that processes dynamic datasets from real-world financial markets into gym-style market environments for training financial reinforcement learning agents, which is difficult due to the low signal-to-noise ratio and survivorship bias of financial data. The library provides a data curation pipeline, reproducible examples, cloud deployment, community-wise competitions, and documentation through Jupyter/Python demos. The library is openly accessible and maintained by the AI4Finance community.

Title: [Roll-Drop: accounting for observation noise with a single parameter](http://arxiv.org/pdf/2304.13150v1)     
Summary: This paper presents a new approach for sim-to-real in Deep Reinforcement Learning (DRL) called Roll-Drop, which uses dropout during simulation to take into account observation noise during deployment without explicitly modelling its distribution for each state. This approach enhances the robustness to sensor noise by tuning only a single parameter. The authors show an 80% success rate when up to 25% noise is injected in the observations and deploy the controller trained in simulation on a physical system to assess the improved robustness.

</details>
<details>
<summary>Image Segmentation</summary>
    
Title: [Domain Adaptive and Generalizable Network Architectures and Training Strategies for Semantic Image Segmentation](http://arxiv.org/pdf/2304.13615v1)     
Summary: The paper proposes new network architectures and training strategies for unsupervised domain adaptation and generalization in semantic image segmentation. The proposed DAFormer network is based on Transformers and is trained using three strategies to avoid overfitting to the source domain. The authors also introduce a multi-resolution framework called HRDA that combines small high-resolution crops and large low-resolution crops to capture both fine segmentation details and long-range context dependencies. Experimental results show significant improvements in performance on five different benchmarks.

Title: [Synthetic Aperture Anomaly Imaging](http://arxiv.org/pdf/2304.13590v1)     
Summary: The paper proposes the use of synthetic aperture anomaly imaging to improve anomaly detection in the presence of foliage occlusion. The authors demonstrate that integrating detected anomalies is even more effective than detecting anomalies in integrals, resulting in enhanced occlusion removal, outlier suppression, and higher chances of visually as well as computationally detecting targets that are otherwise occluded. The paper includes simulations and field experiments to validate the hypothesis and present a real-time application designed to address use-cases that suffer from strong occlusion caused by vegetation, such as search and rescue, wildlife observation, early wildfire detection, and surveillance.

Title: [Cluster Entropy: Active Domain Adaptation in Pathological Image Segmentation](http://arxiv.org/pdf/2304.13513v1)     
Summary: The paper proposes a method for semi-supervised domain adaptation in pathological image segmentation by introducing a cluster entropy measure for selecting an effective whole slide image (WSI). The cluster entropy method calculates the entropy of each cluster to measure the image features of the WSI and covers the entire distribution of the target domain. The proposed method achieves competitive results against prior arts on datasets collected from two hospitals.

Title: [EasyPortrait - Face Parsing and Portrait Segmentation Dataset](http://arxiv.org/pdf/2304.13509v1)     
Summary: This paper introduces a new dataset called EasyPortrait, consisting of 20,000 indoor images with fine-grained segmentation masks separated into 9 classes, primarily used for portrait segmentation and face parsing tasks. The images are collected and labeled from crowdsourcing platforms and are publicly available. The paper also outlines the pipeline for creating a large-scale and clean image segmentation dataset using crowdsourcing, without the need for additional synthetic data. The proposed dataset and trained models are publicly available, and the paper discusses experimental results using several models trained on EasyPortrait.

Title: [Compensation Learning in Semantic Segmentation](http://arxiv.org/pdf/2304.13428v1)     
Summary: The paper proposes Compensation Learning in Semantic Segmentation, a framework to identify and compensate ambiguities as well as label noise in semantic segmentation. The proposed method employs a ground truth depending and globally learned bias to the classification logits and introduces a novel uncertainty branch for neural networks to induce the compensation bias only to relevant regions. The method improves the robustness against label noise during training and allows target-oriented manipulation during inference. The proposed method is evaluated on widely used datasets Cityscapes, KITTI-STEP, ADE20k, and COCO-stuff10k.

Title: [Learnable Ophthalmology SAM](http://arxiv.org/pdf/2304.13425v1)     
Summary: The paper proposes a learnable prompt layer named Learnable Ophthalmology Segment Anything (SAM) for multiple target segmentation in ophthalmology multi-modal images. The prompt layer learns medical prior knowledge from each transformer layer and is trained based on a one-shot mechanism. The paper demonstrates the effectiveness of this approach on four medical segmentation tasks using nine publicly available datasets. The paper falls under the categories of Image Segmentation, Medical Image, Transformer, and Few-Shot/Zero-Shot Learning.

Title: [Exploiting CNNs for Semantic Segmentation with Pascal VOC](http://arxiv.org/pdf/2304.13216v1)     
Summary: The paper presents a study on semantic segmentation with the Pascal VOC dataset. The authors use a Fully Convolution Network (FCN) baseline and address the issues in the baseline with three improvements: a cosine annealing learning rate scheduler, data augmentation, and class imbalance weights. They also explore three different architectures: Advanced FCN, Transfer Learning with ResNet, and U-Net. The authors observe that dataset augmentation has the greatest contribution to performance improvement and transfer learning model performs the best on the Pascal dataset. They use loss, accuracy, and IoU plots along with segmentation maps to draw valuable insights about the working of the models.

</details>
<details>
<summary>Object Detection</summary>
    
Title: [A marker-less human motion analysis system for motion-based biomarker discovery in knee disorders](http://arxiv.org/pdf/2304.13678v1)     
Summary: The paper proposes a marker-less system for motion-based biomarker discovery in knee disorders using standard RGB cameras. Biomarkers are identified using Principal Component Analysis (PCA) and validated as statistically significant through a case study. The system provides a cheap and sensitive alternative to current commercial alternatives for analyzing biomechanics and tracking rehabilitation progress.

Title: [Synthetic Aperture Anomaly Imaging](http://arxiv.org/pdf/2304.13590v1)     
Summary: The paper proposes the use of synthetic aperture anomaly imaging to improve anomaly detection in the presence of foliage occlusion. The authors demonstrate that integrating detected anomalies is even more effective than detecting anomalies in integrals, resulting in enhanced occlusion removal, outlier suppression, and higher chances of visually as well as computationally detecting targets that are otherwise occluded. The paper includes simulations and field experiments to validate the hypothesis and present a real-time application designed to address use-cases that suffer from strong occlusion caused by vegetation, such as search and rescue, wildlife observation, early wildfire detection, and surveillance.

Title: [Konzeption und Umsetzung einer mobilen Applikation zur Validierung von f√§lschungssicheren Produktlabeln](http://arxiv.org/pdf/2304.13519v1)     
Summary: The paper proposes a cost-effective way to verify the authenticity of a product using a counterfeit-proof label composed of gold nanospheres or rods. The label's unique positions of elements can be measured precisely using a smartphone camera and additional technologies. The paper presents a proof of concept for implementing this system in a mobile application and outlines suitable methods to transmit and secure the required information. The results of validating counterfeit-proof product labels are analyzed, and existing weaknesses are pointed out.

Title: [From Chaos Comes Order: Ordering Event Representations for Object Detection](http://arxiv.org/pdf/2304.13455v2)     
Summary: The paper proposes a new method for selecting the optimal event representation for object detection by using the Gromov-Wasserstein Discrepancy. The method is much faster than traditional neural network training, and it reveals new and powerful representations that improve the state-of-the-art results. By performing a hyperparameter search on a large family of event representations, the authors show that their optimized representation outperforms existing representations on multiple datasets by a significant margin. This work opens up a new field of explicit representation optimization for event-based learning methods.

Title: [Training-Free Location-Aware Text-to-Image Synthesis](http://arxiv.org/pdf/2304.13427v1)     
Summary: The paper proposes a new method for training-free location-aware text-to-image synthesis using the stable diffusion model. The method allows users to specify the position of generated objects without additional training and proposes an object detection-based evaluation metric to assess control capability. The experimental results indicate that the proposed method outperforms state-of-the-art methods on both control capacity and image quality.

Title: [Group Equivariant BEV for 3D Object Detection](http://arxiv.org/pdf/2304.13390v1)     
Summary: The paper proposes a group equivariant bird's eye view network (GeqBevNet) for 3D object detection in dynamic driving scenes. The network is based on the group equivariant theory and is embedded into the fused BEV feature map to extract rotational equivariant features, leading to lower average orientation error. The GeqBevNet is verified on the nuScenes validation dataset, and the experimental results demonstrate improved performance in object orientation prediction.

Title: [Machine Vision-Based Crop-Load Estimation Using YOLOv8](http://arxiv.org/pdf/2304.13282v1)     
Summary: This academic paper proposed a machine vision-based system for crop-load estimation in apple orchards to optimize automated pruning and thinning platforms. Using YOLOv8-based instance segmentation technique, the system identified trunks and branches of apple trees to estimate geometric and topological parameters such as branch diameter and orientation. The proposed workflow demonstrated high accuracy and efficiency in identifying tree canopy parts in commercial orchard environments, providing a foundation for robotic pruning, flower thinning, and fruitlet thinning to achieve desired yield and quality.

</details>
<details>
<summary>Object Tracking</summary>
    
Title: [Development of a Realistic Crowd Simulation Environment for Fine-grained Validation of People Tracking Methods](http://arxiv.org/pdf/2304.13403v1)     
Summary: This paper presents the development of a crowd simulation environment and its use in fine-grained validation of people-tracking algorithms. The simulator, developed using Unity 3D engine, focuses on realism in environment, weather conditions, traffic, and individual agent models. Three tracking methods were used to validate the generated dataset, namely IOU-Tracker, Deep-Sort, and Deep-TAMA.

</details>
<details>
<summary>Point Cloud</summary>
    
Title: [Non-rigid Point Cloud Registration for Middle Ear Diagnostics with Endoscopic Optical Coherence Tomography](http://arxiv.org/pdf/2304.13618v1)     
Summary: The paper proposes a non-rigid point cloud registration pipeline, C2P-Net, for merging ex-vivo middle ear models with in-vivo OCT volumetric data to facilitate fast diagnosis and measurement of middle ear infection. The pipeline is capable of handling realistic noise and incompleteness in synthetic and real OCT data. The proposed method can support the interpretation of in-vivo noisy and partial OCT images for the first time.

</details>
<details>
<summary>Neural Rendering</summary>
    
Title: [Super-NeRF: View-consistent Detail Generation for NeRF super-resolution](http://arxiv.org/pdf/2304.13518v1)     
Summary: The paper proposes a NeRF super-resolution method, called Super-NeRF, that generates high-resolution NeRF from low-resolution inputs by constructing a consistency-controlling super-resolution module. The module uses optimizable latent codes for each low-resolution image to control the 2D super-resolution images to converge to a view-consistent output. Super-NeRF achieves state-of-the-art NeRF super-resolution performance on high-resolution detail generation and cross-view consistency.

Title: [Neural-PBIR Reconstruction of Shape, Material, and Illumination](http://arxiv.org/pdf/2304.13445v1)     
Summary: This paper introduces a robust object reconstruction pipeline combining neural based object reconstruction and physics-based inverse rendering. The pipeline produces high-quality object shape, reflectance, and illumination predictions using a neural stage, which are then refined using the physics-based inverse rendering stage. The pipeline significantly outperforms existing reconstruction methods in both quality and performance.

Title: [VGOS: Voxel Grid Optimization for View Synthesis from Sparse Inputs](http://arxiv.org/pdf/2304.13386v1)     
Summary: The paper proposes VGOS, an approach for fast radiance field reconstruction from sparse inputs for novel view synthesis. Two methods are introduced to improve the performance of voxel-based radiance field in sparse input scenarios, preventing overfitting and using several regularization techniques to smooth the voxels. Experiments demonstrate state-of-the-art performance for sparse inputs with super-fast convergence.

Title: [Neuro-symbolic Zero-Shot Code Cloning with Cross-Language Intermediate Representation](http://arxiv.org/pdf/2304.13350v1)     
Summary: This paper proposes a meta-model based approach for finding semantically similar clones of codes in COBOL, without any training data, by using an Intermediate Representation (IR) in the form of Abstract Syntax Trees (ASTs). The authors fine-tune the UnixCoder model with SBT IRs of C codes and achieve a 12.85 MAP@2 improvement over the pre-trained model for COBOL codes, demonstrating the efficacy of their approach for cross-programming language transfer.

Title: [TextDeformer: Geometry Manipulation using Text Guidance](http://arxiv.org/pdf/2304.13348v1)     
Summary: The paper presents TextDeformer, a neural rendering framework that uses text guidance to produce deformations of input mesh geometry. The framework is able to handle both large, low-frequency shape changes, as well as small high-frequency details. The approach relies on differentiable rendering and pre-trained image encoders like CLIP and DINO. Deformations are represented through Jacobians to update deformations in a global, smooth manner. Deep features computed on the 2D encoding of the rendering are used to ensure coherence from all 3D viewpoints. The method is demonstrated to be capable of smoothly-deforming a wide variety of source mesh and target text prompts.

Title: [EverLight: Indoor-Outdoor Editable HDR Lighting Estimation](http://arxiv.org/pdf/2304.13207v1)     
Summary: The paper proposes a method called EverLight that combines a parametric light model with 360-degree panoramas to provide an editable lighting capability for indoor and outdoor environments. The method uses GAN-based LDR panorama extrapolation and introduces a lighting co-modulation method to blend the original or edited scene illumination within the panorama generation process. EverLight enables users to edit light direction, intensity, number, etc., to impact shading and reflections while seamlessly blending with the edits. The paper demonstrates state-of-the-art results even when compared to domain-specific methods.

</details>
<details>
<summary>Domain Generalization/Adaptation</summary>
    
Title: [FVP: Fourier Visual Prompting for Source-Free Unsupervised Domain Adaptation of Medical Image Segmentation](http://arxiv.org/pdf/2304.13672v1)     
Summary: The paper proposes Fourier Visual Prompting (FVP), a method for Source-Free Unsupervised Domain Adaptation (SFUDA) of medical image segmentation. FVP adds a visual prompt to input target data, which is learned by minimizing the segmentation loss, and steers the frozen pre-trained model to perform well in the target domain. The proposed method is validated using three public datasets, and experiments show that FVP yields better segmentation results compared to various existing methods.

Title: [Domain Adaptive and Generalizable Network Architectures and Training Strategies for Semantic Image Segmentation](http://arxiv.org/pdf/2304.13615v1)     
Summary: The paper proposes new network architectures and training strategies for unsupervised domain adaptation and generalization in semantic image segmentation. The proposed DAFormer network is based on Transformers and is trained using three strategies to avoid overfitting to the source domain. The authors also introduce a multi-resolution framework called HRDA that combines small high-resolution crops and large low-resolution crops to capture both fine segmentation details and long-range context dependencies. Experimental results show significant improvements in performance on five different benchmarks.

</details>
<details>
<summary>Few-Shot/Zero-Shot Learning</summary>
    
Title: [HausaNLP at SemEval-2023 Task 12: Leveraging African Low Resource TweetData for Sentiment Analysis](http://arxiv.org/pdf/2304.13634v1)     
Summary: This paper presents the results of SemEval-2023 Task 12, a sentiment analysis task for low-resource African languages using Twitter data. The task had three subtasks, including a zero-shot sentiment classification. The study leveraged pre-trained large language models, including Afro-xlmr-large and BERT, for sentiment analysis in 14 African languages. The findings showed that Afro-xlmr-large performed better than the other models, and Nigerian languages had higher performance due to the larger volume of data. The paper also released the code on GitHub.

Title: [Learnable Ophthalmology SAM](http://arxiv.org/pdf/2304.13425v1)     
Summary: The paper proposes a learnable prompt layer named Learnable Ophthalmology Segment Anything (SAM) for multiple target segmentation in ophthalmology multi-modal images. The prompt layer learns medical prior knowledge from each transformer layer and is trained based on a one-shot mechanism. The paper demonstrates the effectiveness of this approach on four medical segmentation tasks using nine publicly available datasets. The paper falls under the categories of Image Segmentation, Medical Image, Transformer, and Few-Shot/Zero-Shot Learning.

Title: [Neuro-symbolic Zero-Shot Code Cloning with Cross-Language Intermediate Representation](http://arxiv.org/pdf/2304.13350v1)     
Summary: This paper proposes a meta-model based approach for finding semantically similar clones of codes in COBOL, without any training data, by using an Intermediate Representation (IR) in the form of Abstract Syntax Trees (ASTs). The authors fine-tune the UnixCoder model with SBT IRs of C codes and achieve a 12.85 MAP@2 improvement over the pre-trained model for COBOL codes, demonstrating the efficacy of their approach for cross-programming language transfer.

Title: [Zero-Shot Slot and Intent Detection in Low-Resource Languages](http://arxiv.org/pdf/2304.13292v1)     
Summary: The paper presents a study on zero-shot slot and intent detection in low-resource languages. Various models and settings were tested, including the recently successful multitask-prompted fine-tuning approach using large language models. The results show that the best model outperforms the baseline by a significant margin in both tasks, demonstrating the potential of zero-shot learning for low-resource language understanding.

Title: [ESPT: A Self-Supervised Episodic Spatial Pretext Task for Improving Few-Shot Learning](http://arxiv.org/pdf/2304.13287v1)     
Summary: This paper proposes a novel self-supervised approach, called ESPT, to improve few-shot learning performance. ESPT uses a pretext task to capture and utilize local visual information and data structure information of the whole episode, promoting learning more transferable feature representations. The experiments demonstrate that ESPT achieves state-of-the-art performance on three benchmark datasets for few-shot image classification.

Title: [From Association to Generation: Text-only Captioning by Unsupervised Cross-modal Mapping](http://arxiv.org/pdf/2304.13273v2)     
Summary: This paper proposes a zero-shot method, K-nearest-neighbor Cross-modality Mapping (Knight), for generating image and video captions by mapping images/videos to the language modality. The proposed method achieves state-of-the-art performance in zero-shot methods for image and video captioning with text-only unsupervised training. The paper addresses the modality gap between the CLIP representations of different modalities and the inability of CLIP to transfer concepts across modalities for generation-based tasks.

Title: [StepFormer: Self-supervised Step Discovery and Localization in Instructional Videos](http://arxiv.org/pdf/2304.13265v1)     
Summary: The paper presents StepFormer, a self-supervised transformer decoder model that can discover and localize instruction steps in videos without any human annotation. The model is trained on a large dataset of instructional videos using automatically generated subtitles, and it outperforms previous unsupervised and weakly-supervised approaches on step detection and localization tasks by a significant margin. Additionally, the model can perform zero-shot multi-step localization, and it demonstrates emergent properties that allow it to achieve better performance than relevant baselines.

Title: [TABLET: Learning From Instructions For Tabular Data](http://arxiv.org/pdf/2304.13188v1)     
Summary: The paper introduces a benchmark dataset, called TABLET, consisting of 20 diverse tabular datasets annotated with natural language instructions for solving tabular prediction problems using large language models (LLMs). The study finds that in-context instructions improve the zero-shot F1 performance of Flan-T5 11b and ChatGPT on TABLET. However, LLMs often ignore instructions and fail to predict specific instances correctly, even with examples, indicating the need for new capabilities in learning from instructions for tabular data.

</details>
<details>
<summary>Visual Question Answering (VQA)</summary>
    
Title: [HeySQuAD: A Spoken Question Answering Dataset](http://arxiv.org/pdf/2304.13689v1)     
Summary: The paper introduces a new large-scale community-shared spoken question answering (SQA) dataset, HeySQuAD, consisting of human-spoken and machine-generated questions and corresponding textual answers. The dataset aims to measure the ability of machines to understand noisy spoken questions and answer them accurately. The paper also presents benchmarks and observations on the impact of noise from human-spoken and machine-generated questions on model and answering accuracy. Significantly, the paper highlights that training using transcribed human-spoken questions leads to significant improvements over training on original textual questions only, for the task of SQA.

Title: [A Symmetric Dual Encoding Dense Retrieval Framework for Knowledge-Intensive Visual Question Answering](http://arxiv.org/pdf/2304.13649v1)     
Summary: The paper proposes a new framework for Knowledge-Intensive Visual Question Answering (KI-VQA) tasks, consisting of a retriever and a reader. The retriever is based on a symmetric dual encoding dense retrieval framework called DEDR, which outperforms state-of-the-art baselines on two KI-VQA datasets. The paper also introduces MM-FiD, an encoder-decoder multi-modal fusion-in-decoder model, which utilizes the retrieved passages to generate textual answers for KI-VQA tasks and improves question answering accuracy compared to competitive baselines in the literature.

</details>
<details>
<summary>Image-to-Image Translation</summary>
    
</details>
<details>
<summary>Transformer</summary>
    
Title: [UniNeXt: Exploring A Unified Architecture for Vision Recognition](http://arxiv.org/pdf/2304.13700v1)     
Summary: The paper proposes UniNeXt, a unified architecture for the vision backbone that can significantly improve the performance of various spatial token mixers, regardless of their design. The study shows the importance of the general architecture of vision recognition and suggests that an excellent spatial token mixer may be stifled by a suboptimal general architecture. UniNeXt equipped with naive local window attention even outperforms the previous state-of-the-art.

Title: [Domain Adaptive and Generalizable Network Architectures and Training Strategies for Semantic Image Segmentation](http://arxiv.org/pdf/2304.13615v1)     
Summary: The paper proposes new network architectures and training strategies for unsupervised domain adaptation and generalization in semantic image segmentation. The proposed DAFormer network is based on Transformers and is trained using three strategies to avoid overfitting to the source domain. The authors also introduce a multi-resolution framework called HRDA that combines small high-resolution crops and large low-resolution crops to capture both fine segmentation details and long-range context dependencies. Experimental results show significant improvements in performance on five different benchmarks.

Title: [SIMARA: a database for key-value information extraction from full pages](http://arxiv.org/pdf/2304.13606v1)     
Summary: The paper introduces SIMARA, a database for information extraction from historical handwritten documents. The corpus includes annotated finding aids from the National Archives of France. The proposed model is based on the Transformer architecture trained for end-to-end information extraction, and three sets are provided for training, validation, and testing. The database is freely accessible.

Title: [Impact of Position Bias on Language Models in Token Classification](http://arxiv.org/pdf/2304.13567v1)     
Summary: The paper investigates the impact of position bias on the performance of language models in token classification tasks. The study includes various benchmark datasets for named entity recognition and part-of-speech tagging. The authors propose two methods to mitigate the effect of position bias and show improvement in model performance. The paper focuses on evaluating the performance of Transformer models in a specific issue of language models.

Title: [Key-value information extraction from full handwritten pages](http://arxiv.org/pdf/2304.13530v1)     
Summary: The paper proposes a Transformer-based approach for extracting key-value information from full handwritten pages. The model combines feature extraction, handwriting recognition, and named entity recognition in a single model, and is compared with traditional two-stage methods. The attention-based model is able to learn from key-value annotations and outperforms previous methods on three public databases.

Title: [Learnable Ophthalmology SAM](http://arxiv.org/pdf/2304.13425v1)     
Summary: The paper proposes a learnable prompt layer named Learnable Ophthalmology Segment Anything (SAM) for multiple target segmentation in ophthalmology multi-modal images. The prompt layer learns medical prior knowledge from each transformer layer and is trained based on a one-shot mechanism. The paper demonstrates the effectiveness of this approach on four medical segmentation tasks using nine publicly available datasets. The paper falls under the categories of Image Segmentation, Medical Image, Transformer, and Few-Shot/Zero-Shot Learning.

Title: [STIR: Siamese Transformer for Image Retrieval Postprocessing](http://arxiv.org/pdf/2304.13393v2)     
Summary: The paper proposes a new approach called Siamese Transformer for Image Retrieval (STIR) that reranks top image retrieval results in a single forward pass, achieving state-of-the-art performance on image retrieval datasets. The approach uses attention mechanism to compare query images and retrieved candidates on a pixel level, without relying on global/local feature extraction. The paper also introduces a simpler model using triplet loss with hard negatives mining that performs at the state-of-the-art level but is more scalable to production environments.

Title: [The Closeness of In-Context Learning and Weight Shifting for Softmax Regression](http://arxiv.org/pdf/2304.13276v1)     
Summary: The paper studies the in-context learning ability of Transformers in natural language processing tasks. The authors show the upper bounds of the data transformations induced by a single self-attention layer and by gradient-descent on a regression loss for softmax prediction function. The results imply that when training self-attention-only Transformers for regression tasks, the models learned by gradient-descent and Transformers show great similarity.

Title: [StepFormer: Self-supervised Step Discovery and Localization in Instructional Videos](http://arxiv.org/pdf/2304.13265v1)     
Summary: The paper presents StepFormer, a self-supervised transformer decoder model that can discover and localize instruction steps in videos without any human annotation. The model is trained on a large dataset of instructional videos using automatically generated subtitles, and it outperforms previous unsupervised and weakly-supervised approaches on step detection and localization tasks by a significant margin. Additionally, the model can perform zero-shot multi-step localization, and it demonstrates emergent properties that allow it to achieve better performance than relevant baselines.

Title: [LEMaRT: Label-Efficient Masked Region Transform for Image Harmonization](http://arxiv.org/pdf/2304.13166v1)     
Summary: The paper introduces a self-supervised pre-training method called LEMaRT for image harmonization using large-scale unannotated image datasets. They generate pre-training data using the Label-Efficient Masked Region Transform (LEMaRT) pipeline and pre-train a new image harmonization model, SwinIH, by retrofitting the Swin Transformer with a combination of local and global self-attention mechanisms. SwinIH outperforms the state of the art on the iHarmony4 dataset and is label-efficient.

</details>
<details>
<summary>Semi-supervised learning</summary>
    
Title: [Diffsurv: Differentiable sorting for censored time-to-event data](http://arxiv.org/pdf/2304.13594v1)     
Summary: This paper proposes a novel method called Diffsurv for survival analysis, a crucial semi-supervised task in machine learning with numerous real-world applications, particularly in healthcare. Diffsurv is a differentiable sorting method that can account for censoring in datasets by predicting matrices of possible permutations that take into account the label uncertainty introduced by censored samples. Experimental results show that Diffsurv outperforms established baselines in various simulated and real-world risk prediction scenarios. The paper also presents a novel method for top-k risk prediction that leverages the algorithmic supervision enabled by Diffsurv.

Title: [SEAL: Simultaneous Label Hierarchy Exploration And Learning](http://arxiv.org/pdf/2304.13374v1)     
Summary: This paper proposes a Simultaneous label hierarchy Exploration And Learning (SEAL) framework that explores the label hierarchy by augmenting observed labels with latent labels that follow a prior hierarchical structure. It uses a 1-Wasserstein metric on the tree metric space to learn a data-driven label hierarchy and perform both supervised and semi-supervised learning. The approach shows superior results on various datasets and reveals insightful label structure.

</details>
<details>
<summary>Self-supervised learning</summary>
    
Title: [ESPT: A Self-Supervised Episodic Spatial Pretext Task for Improving Few-Shot Learning](http://arxiv.org/pdf/2304.13287v1)     
Summary: This paper proposes a novel self-supervised approach, called ESPT, to improve few-shot learning performance. ESPT uses a pretext task to capture and utilize local visual information and data structure information of the whole episode, promoting learning more transferable feature representations. The experiments demonstrate that ESPT achieves state-of-the-art performance on three benchmark datasets for few-shot image classification.

Title: [Self-Supervised Multi-Modal Sequential Recommendation](http://arxiv.org/pdf/2304.13277v1)     
Summary: This paper proposes a self-supervised multi-modal pretraining method for sequential recommendation systems. The method uses a dual-tower retrieval architecture and enables the alignment of various feature combinations of items, thereby generalizing to diverse datasets with different item features. The proposed method outperforms traditional sequential recommendation methods on five publicly available datasets.

Title: [StepFormer: Self-supervised Step Discovery and Localization in Instructional Videos](http://arxiv.org/pdf/2304.13265v1)     
Summary: The paper presents StepFormer, a self-supervised transformer decoder model that can discover and localize instruction steps in videos without any human annotation. The model is trained on a large dataset of instructional videos using automatically generated subtitles, and it outperforms previous unsupervised and weakly-supervised approaches on step detection and localization tasks by a significant margin. Additionally, the model can perform zero-shot multi-step localization, and it demonstrates emergent properties that allow it to achieve better performance than relevant baselines.

Title: [Learning to Predict Navigational Patterns from Partial Observations](http://arxiv.org/pdf/2304.13242v1)     
Summary: The paper presents a self-supervised learning method for learning to infer navigational patterns in real-world environments from partial observations only. The model predicts unbiased local directional soft lane probabilities and infers global navigational patterns using a maximum likelihood graph. Experiments show that the SSL model outperforms two SOTA supervised lane graph prediction models on the nuScenes dataset. The proposed SSL method is suggested as a scalable and interpretable continual learning paradigm for navigation by perception.

Title: [Sample-Specific Debiasing for Better Image-Text Models](http://arxiv.org/pdf/2304.13181v1)     
Summary: This paper proposes a sample-specific debiasing approach to improve the quality of learned representations in self-supervised image-text representation learning for medical applications. The approach corrects for false negatives by using estimated sample-specific class probabilities. The paper provides theoretical analysis and empirical evidence of the advantages of the proposed approach.

Title: [LEMaRT: Label-Efficient Masked Region Transform for Image Harmonization](http://arxiv.org/pdf/2304.13166v1)     
Summary: The paper introduces a self-supervised pre-training method called LEMaRT for image harmonization using large-scale unannotated image datasets. They generate pre-training data using the Label-Efficient Masked Region Transform (LEMaRT) pipeline and pre-train a new image harmonization model, SwinIH, by retrofitting the Swin Transformer with a combination of local and global self-attention mechanisms. SwinIH outperforms the state of the art on the iHarmony4 dataset and is label-efficient.

</details>
<details>
<summary>UAV/Remote Sensing/Satellite Image</summary>
    
Title: [An Investigation into Active Control for Accessible Orbital Flight](http://arxiv.org/pdf/2304.13704v1)     
Summary: The paper discusses the development of an accessible and miniaturized thrust-vector-control technology for miniature scale orbital flights using an Arduino-based flight computer, state machine control software, and active-control hardware. Initial test flights and ground test data show stable control, providing adaptability and control applicable to both small and large scale test vehicles. The technology holds potential for faster amateur rocket development and accessible orbital flights for conducting concurrent experiments.

Title: [Drones on the Rise: Exploring the Current and Future Potential of UAVs](http://arxiv.org/pdf/2304.13702v1)     
Summary: The paper provides an overview of the current state and potential advancements in Unmanned Aerial Vehicles (UAVs) technology and their applications in various fields such as aerial photography, surveying, agriculture, infrastructure inspection, disaster management, and military operations. The article also discusses concerns related to the impact of UAVs on society.

Title: [Synthetic Aperture Anomaly Imaging](http://arxiv.org/pdf/2304.13590v1)     
Summary: The paper proposes the use of synthetic aperture anomaly imaging to improve anomaly detection in the presence of foliage occlusion. The authors demonstrate that integrating detected anomalies is even more effective than detecting anomalies in integrals, resulting in enhanced occlusion removal, outlier suppression, and higher chances of visually as well as computationally detecting targets that are otherwise occluded. The paper includes simulations and field experiments to validate the hypothesis and present a real-time application designed to address use-cases that suffer from strong occlusion caused by vegetation, such as search and rescue, wildlife observation, early wildfire detection, and surveillance.

Title: [Thermal Vision for Soil Assessment in a Multipurpose Environmental Chamber under Martian Conditions towards Robot Navigation](http://arxiv.org/pdf/2304.13525v1)     
Summary: The paper proposes a framework using multipurpose environmental chambers to generate diurnal cycle dataset pairs which can be useful to relate the thermal behavior of soil on Earth for robot remote sensing data to target planetary exploration conditions. The proposed framework is applied to generate datasets using the UMA-Laserlab chamber which replicates the atmospheric composition of Mars. The resulting dataset pairs have been made available for the scientific community.

Title: [Leveraging Compositional Methods for Modeling and Verification of an Autonomous Taxi System](http://arxiv.org/pdf/2304.13517v1)     
Summary: The paper proposes the use of compositional formal modeling and verification methods for an autonomous taxi system. The authors identify several research needs, such as libraries of formal models, probabilistic contract frameworks, and standard high-level functional architectures. They believe that addressing these needs will improve the adoption of formal methods in the design of autonomous systems, including learning-enabled systems, and increase confidence in their safe operations.

Title: [Routing Heterogeneous Traffic in Delay-Tolerant Satellite Networks](http://arxiv.org/pdf/2304.13501v1)     
Summary: This paper proposes adaptations to Contact Graph Routing (CGR) to prioritize traffic with different quality of service (QoS) requirements in Delay-tolerant networking (DTN) satellite networks. The proposed algorithms effectively improve delivery ratio and energy efficiency while meeting latency constraints. An integer linear programming optimization model is also presented as a performance upper bound. The simulations show promising results for improving QoS-compliant delivery ratio in heterogeneous traffic routing.

Title: [A Cooperative NOMA User Pairing in UAV-Based Wireless Networks](http://arxiv.org/pdf/2304.13499v1)     
Summary: The paper proposes a cooperative NOMA user pairing in UAV-based wireless networks to enhance the downlink transmission performance and optimum use of power and bandwidth resources. The paper studies joint user pair and resource allocation-based distance to optimize fair throughput, which concentrates on UAV-aided communication from different wireless-powered nodes, and the simulation results illustrate that the proposed user pairing strategies enhance the system's efficiency.

Title: [Network Coding Power Control Mechanisms for Time Varying Channels](http://arxiv.org/pdf/2304.13498v1)     
Summary: The paper proposes a network-coding structure for compensating channel variations in satellite communications using a markov process model for large scale fading channels. The model exploits the channel delay profile and dependency between channel states to predict variations under fading and closed form delay induced. The proposed mechanism works under fixed power and adaptive power control, providing compensation for zero packet transmissions.

Title: [An Adaptive Control Strategy for Neural Network based Optimal Quadcopter Controllers](http://arxiv.org/pdf/2304.13460v1)     
Summary: The paper presents an adaptive control strategy for neural network based optimal quadcopter controllers. The strategy addresses the reality gap issue encountered in sim-to-real transfer by identifying the unmodeled pitch moment and proposing an adaptive control strategy that learns from optimal trajectories of a system affected by constant external pitch, roll, and yaw moments. The effectiveness of the method is demonstrated through energy-optimal hover-to-hover flights, and the advantages are compared with state-of-the-art differential-flatness-based controllers.

Title: [ESCM: An Efficient and Secure Communication Mechanism for UAV Networks](http://arxiv.org/pdf/2304.13244v1)     
Summary: The paper proposes a communication mechanism called ESCM, specifically designed for UAV networks. ESCM includes a routing protocol based on artificial bee colony algorithm and a blockchain system with a consensus algorithm based on network coding. The concept of digital twin is used to map UAVs from the physical world into cyberspace, transforming the UAV network into a static network. The proposed mechanism improves communication efficiency and security through network coding and encryption, respectively, and is suitable for high mobility network scenarios. Simulation results confirm the advantages of ESCM in terms of performance improvements.

Title: [Single-View Height Estimation with Conditional Diffusion Probabilistic Models](http://arxiv.org/pdf/2304.13214v1)     
Summary: The paper proposes a single-view height estimation method using a generative diffusion model trained on optical and DSM images. The model is conditioned on the source image to generate high-resolution 3D surfaces. The approach shows promising results on the Vaihingen benchmark dataset.

Title: [Autoencoder-based Radio Frequency Interference Mitigation For SMAP Passive Radiometer](http://arxiv.org/pdf/2304.13158v1)     
Summary: The paper proposes an autoencoder-based method for mitigating radio frequency interference (RFI) in passive space-borne radiometers operating in the 1400-1427 MHz protected frequency band. The proposed method aims to remove the dominant RFI caused by potential coexistent terrestrial users (i.e., 5G base station) from the received contaminated signal at the passive receiver side, potentially preserving valuable information and preventing the contaminated data from being discarded.

</details>
<details>
<summary>Image Synthesis/Generation</summary>
    
Title: [Controllable Image Generation via Collage Representations](http://arxiv.org/pdf/2304.13722v1)     
Summary: The paper proposes a new approach for fine-grained scene controllability in image generation through the use of image collages. The approach, called "mixing and matching scenes", utilizes an adversarially trained generative image model conditioned on appearance features and spatial positions of objects in a collage to generate coherent images. The model is evaluated on the OpenImages and MS-COCO datasets and outperforms baselines in terms of fine-grained scene controllability while maintaining competitive image quality and sample diversity. The study highlights the potential of collage-based generative models for efficient and effective content creation.

Title: [Ray Conditioning: Trading Photo-consistency for Photo-realism in Multi-view Image Generation](http://arxiv.org/pdf/2304.13681v1)     
Summary: The paper proposes a technique called ray conditioning that generates multi-view images by conditioning a 2D GAN on a light field prior. The method allows for explicit viewpoint control, state-of-the-art photorealism, and identity consistency, making it suitable for the viewpoint editing task. By relaxing the photo-consistency constraint, the method achieves a balance between photo-consistency and photorealism, addressing the trade-off between the two.

Title: [Video Frame Interpolation with Densely Queried Bilateral Correlation](http://arxiv.org/pdf/2304.13596v1)     
Summary: The paper proposes a new approach for Video Frame Interpolation (VFI) called Densely Queried Bilateral Correlation (DQBC). This approach models correlations between neighboring frames in a way that is more friendly to small and fast-moving objects. The motion fields generated by DQBC are refined and up-sampled with context features before a CNN-based SynthNet synthesizes the final interpolated frame. The approach results in higher accuracy and less inference time than state-of-the-art approaches.

Title: [Super-NeRF: View-consistent Detail Generation for NeRF super-resolution](http://arxiv.org/pdf/2304.13518v1)     
Summary: The paper proposes a NeRF super-resolution method, called Super-NeRF, that generates high-resolution NeRF from low-resolution inputs by constructing a consistency-controlling super-resolution module. The module uses optimizable latent codes for each low-resolution image to control the 2D super-resolution images to converge to a view-consistent output. Super-NeRF achieves state-of-the-art NeRF super-resolution performance on high-resolution detail generation and cross-view consistency.

Title: [Training-Free Location-Aware Text-to-Image Synthesis](http://arxiv.org/pdf/2304.13427v1)     
Summary: The paper proposes a new method for training-free location-aware text-to-image synthesis using the stable diffusion model. The method allows users to specify the position of generated objects without additional training and proposes an object detection-based evaluation metric to assess control capability. The experimental results indicate that the proposed method outperforms state-of-the-art methods on both control capacity and image quality.

Title: [DiffuseExpand: Expanding dataset for 2D medical image segmentation using diffusion models](http://arxiv.org/pdf/2304.13416v1)     
Summary: This paper proposes an approach called DiffuseExpand for expanding datasets for 2D medical image segmentation using Diffusion Probabilistic Models (DPMs). DiffuseExpand first samples a variety of masks from Gaussian noise to ensure diversity and then synthesizes images to ensure the alignment of images and masks. The effectiveness of DiffuseExpand is demonstrated through comparison and ablation experiments on COVID-19 and CGMH Pelvis datasets.

Title: [A Portrait of Emotion: Empowering Self-Expression through AI-Generated Art](http://arxiv.org/pdf/2304.13324v1)     
Summary: This paper investigates the ability of AI-generated artwork to reflect human cognitive processes and self-expression. The study found that AI can facilitate creativity and self-expression of emotions, suggesting its potential use in mental health interventions. The research framework with generative AIs can help design AI-based interventions in related fields such as therapy and counseling.

Title: [Single-View Height Estimation with Conditional Diffusion Probabilistic Models](http://arxiv.org/pdf/2304.13214v1)     
Summary: The paper proposes a single-view height estimation method using a generative diffusion model trained on optical and DSM images. The model is conditioned on the source image to generate high-resolution 3D surfaces. The approach shows promising results on the Vaihingen benchmark dataset.

Title: [EverLight: Indoor-Outdoor Editable HDR Lighting Estimation](http://arxiv.org/pdf/2304.13207v1)     
Summary: The paper proposes a method called EverLight that combines a parametric light model with 360-degree panoramas to provide an editable lighting capability for indoor and outdoor environments. The method uses GAN-based LDR panorama extrapolation and introduces a lighting co-modulation method to blend the original or edited scene illumination within the panorama generation process. EverLight enables users to edit light direction, intensity, number, etc., to impact shading and reflections while seamlessly blending with the edits. The paper demonstrates state-of-the-art results even when compared to domain-specific methods.

Title: [Generating Procedural Materials from Text or Image Prompts](http://arxiv.org/pdf/2304.13172v1)     
Summary: The paper proposes a multi-modal node graph generation neural architecture for high-quality procedural material synthesis, which can be conditioned on different inputs, using a CLIP-based encoder. It also creates a substantially augmented material graph dataset to improve generation quality. The proposed model generates high-quality graph samples using a regularized sampling process and improves matching quality by differentiable optimization for top-ranked samples. The paper compares the proposed method with CLIP-based database search baselines and achieves superior or similar performance without requiring massive data storage. The model can produce a set of material graphs unconditionally, conditioned on images, text prompts, or partial graphs, serving as a tool for automatic visual programming completion.

Title: [LumiGAN: Unconditional Generation of Relightable 3D Human Faces](http://arxiv.org/pdf/2304.13153v1)     
Summary: This paper introduces LumiGAN, an unconditional GAN for generating 3D human faces with a physically based lighting module that enables relighting under novel illumination at inference time. LumiGAN can create realistic shadow effects using an efficient visibility formulation that is learned in a self-supervised manner, and generates plausible physical properties for relightable faces without any ground truth data. The paper showcases significantly improved geometry generation compared to state-of-the-art non-relightable 3D GANs and notably better photorealism than existing relightable GANs.

</details>
<details>
<summary>Graph Neural Networks</summary>
    
Title: [Hitting Subgraphs in Sparse Graphs and Geometric Intersection Graphs](http://arxiv.org/pdf/2304.13695v1)     
Summary: The paper investigates the (Induced) Subgraph Hitting problem in graph theory, where the aim is to compute the minimum-sized set of vertices that does not contain any forbidden subgraph. The authors propose an efficient approximation scheme with a linear running time for various broad graph classes, including geometric intersection graphs. The reduction technique introduced in the paper has potential applications in different areas of computer science, such as approximation algorithms, parameterized complexity, and graph theory.

Title: [ElegansNet: a brief scientific report and initial experiments](http://arxiv.org/pdf/2304.13538v1)     
Summary: 
The paper introduces ElegansNet, a neural network architecture inspired by the connectome of the Caenorhabditis elegans worm. The network topology of the worm is used to design and generate improved deep learning systems, which are compared against both randomly wired networks and state-of-the-art artificial neural networks. ElegansNet outperforms randomly wired networks and achieves top-1 accuracy of 99.99% on Cifar10 and 99.84% on MNIST Unsup on the validation sets in supervised image classification tasks and unsupervised hand-written digits reconstruction. The study explores the interplay between connectome topology and deep learning systems, showcasing the potential of bio-plausible structures in efficiently solving complex tasks.

Title: [SCV-GNN: Sparse Compressed Vector-based Graph Neural Network Aggregation](http://arxiv.org/pdf/2304.13532v1)     
Summary: This paper proposes a new sparse compressed vector-based graph neural network aggregation method called SCV-GNN. The authors use Z-Morton ordering to derive a data-locality-based computation ordering and partitioning scheme optimized for the aggregation operation. The proposed method achieves a significant speedup and reduces memory traffic compared to traditional compressed sparse column and compressed sparse row methods. The paper provides experimental results over various datasets to support the effectiveness of their proposed method.

Title: [Scene Graph Lossless Compression with Adaptive Prediction for Objects and Relations](http://arxiv.org/pdf/2304.13359v1)     
Summary: The paper proposes a new framework for lossless compression of scene graph data using adaptive predictors and context modeling with a Graph Context Convolution approach. The framework consists of a unified prior extractor and specialized element predictors to adapt for different data elements. Experiments show the effectiveness of this framework for scene graph compression.

Title: [An Approximation Algorithm for Two-Edge-Connected Subgraph Problem via Triangle-free Two-Edge-Cover](http://arxiv.org/pdf/2304.13228v1)     
Summary: The paper proposes a $(1.3+\varepsilon)$-approximation algorithm for the 2-Edge-Connected Spanning Subgraph problem (2-ECSS) using a minimum triangle-free 2-edge-cover in the graph. This algorithm improves upon the previously known best approximation ratio and uses techniques from both finding a maximum triangle-free 2-matching and arguments by previous approximation algorithms for the 2-ECSS problem.

Title: [Reconfiguration of the Union of Arborescences](http://arxiv.org/pdf/2304.13217v1)     
Summary: The paper demonstrates the reconfigurability of the union of k arborescences in digraphs, generalizing a previous result for k=1. The union of k arborescences can be represented as a common matroid basis of two matroids, giving a non-trivial example of matroid pairs for which two common bases are always reconfigurable to each other. This paper falls under the categories of Graph Neural Networks and Theory.

Title: [Graph-CoVis: GNN-based Multi-view Panorama Global Pose Estimation](http://arxiv.org/pdf/2304.13201v1)     
Summary: The paper introduces Graph-CoVis, a novel Graph Neural Network-based architecture for global multi-view spherical camera pose estimation. The proposed approach extends CoVisPose from relative two-view to global multi-view spherical camera pose estimation by jointly learning the co-visible structure and global motion in an end-to-end and fully-supervised approach. The performance of the model is evaluated on real homes presenting wide-baselines, occlusion, and limited visual overlap using the ZInD dataset. The results show that Graph-CoVis performs competitively with state-of-the-art approaches.

Title: [Connector 0.5: A unified framework for graph representation learning](http://arxiv.org/pdf/2304.13195v1)     
Summary: The paper introduces a unified framework called Connector for graph representation learning. The framework covers various graph embedding models ranging from shallow to state-of-the-art models, and includes the ability to construct various types of graphs with different structural relations. The framework aims to provide an efficient open-source solution for deep graph embedding models to represent structural relations in graphs. The framework is available on Github at https://github.com/NSLab-CUK/Connector.

Title: [Jet: Multilevel Graph Partitioning on GPUs](http://arxiv.org/pdf/2304.13194v1)     
Summary: The paper introduces a new parallel algorithm named Jet for partition refinement in multilevel graph partitioning, specifically designed for GPUs. The algorithm is combined with GPU-aware coarsening to develop a k-way graph partitioner. The study shows that the new partitioner outperforms state-of-the-art shared memory graph partitioners on a large collection of test graphs.

Title: [Generating Procedural Materials from Text or Image Prompts](http://arxiv.org/pdf/2304.13172v1)     
Summary: The paper proposes a multi-modal node graph generation neural architecture for high-quality procedural material synthesis, which can be conditioned on different inputs, using a CLIP-based encoder. It also creates a substantially augmented material graph dataset to improve generation quality. The proposed model generates high-quality graph samples using a regularized sampling process and improves matching quality by differentiable optimization for top-ranked samples. The paper compares the proposed method with CLIP-based database search baselines and achieves superior or similar performance without requiring massive data storage. The model can produce a set of material graphs unconditionally, conditioned on images, text prompts, or partial graphs, serving as a tool for automatic visual programming completion.

Title: [SAFE: Machine Unlearning With Shard Graphs](http://arxiv.org/pdf/2304.13169v1)     
Summary: The paper presents SAFE, a method for machine unlearning with shard graphs. The method introduces the notion of a shard graph in which limited information from other shards is incorporated during training, instead of treating each shard as independent. This results in a modest increase in expected forgetting cost but a significant increase in accuracy, while still achieving complete removal of residual influence after forgetting. SAFE is trained on shards an order-of-magnitude smaller than current state-of-the-art methods, while maintaining high accuracy, as demonstrated empirically on fine-grained computer vision datasets.

</details>
<details>
<summary>Vision-Language (Multimodality)</summary>
    
Title: [Controllable Image Generation via Collage Representations](http://arxiv.org/pdf/2304.13722v1)     
Summary: The paper proposes a new approach for fine-grained scene controllability in image generation through the use of image collages. The approach, called "mixing and matching scenes", utilizes an adversarially trained generative image model conditioned on appearance features and spatial positions of objects in a collage to generate coherent images. The model is evaluated on the OpenImages and MS-COCO datasets and outperforms baselines in terms of fine-grained scene controllability while maintaining competitive image quality and sample diversity. The study highlights the potential of collage-based generative models for efficient and effective content creation.

Title: [Multimodal Grounding for Embodied AI via Augmented Reality Headsets for Natural Language Driven Task Planning](http://arxiv.org/pdf/2304.13676v1)     
Summary: The paper proposes the use of an Augmented Reality (AR) headset for multimodal grounding in Embodied Artificial Intelligence (EAI) systems for industrial tasks. The study shows the feasibility of co-located human-robot teaming using an AR headset for information exchange between an EAI agent and a human operator for various inspection tasks. The paper highlights potential pitfalls in EAI's construction and provides both quantitative and qualitative analysis on prompt robustness.

Title: [Towards Multi-Modal DBMSs for Seamless Querying of Texts and Tables](http://arxiv.org/pdf/2304.13559v1)     
Summary: This paper proposes Multi-Modal Databases (MMDBs), a new class of database systems that can seamlessly query text and tables using SQL. They extend relational databases with Multi-Modal Operators (MMOps) based on recent large language models to allow textual data to be treated as tables without manual transformation. The evaluation shows that the MMDB prototype outperforms text-to-table approaches in accuracy and performance, requiring significantly less training data to fine-tune the model for an unseen text collection.

Title: [From Association to Generation: Text-only Captioning by Unsupervised Cross-modal Mapping](http://arxiv.org/pdf/2304.13273v2)     
Summary: This paper proposes a zero-shot method, K-nearest-neighbor Cross-modality Mapping (Knight), for generating image and video captions by mapping images/videos to the language modality. The proposed method achieves state-of-the-art performance in zero-shot methods for image and video captioning with text-only unsupervised training. The paper addresses the modality gap between the CLIP representations of different modalities and the inability of CLIP to transfer concepts across modalities for generation-based tasks.

</details>
<details>
<summary>Model Compression/Knowledge Distillation/Pruning</summary>
    
Title: [Sparsified Model Zoo Twins: Investigating Populations of Sparsified Neural Network Models](http://arxiv.org/pdf/2304.13718v1)     
Summary: This paper investigates the robustness and performance of two sparsification methods for Neural Networks on large populations of models. The authors apply the methods on model zoos to create sparsified versions of the zoos and compare them with the original models. They find both methods to be robust and highly correlated with the original models, with magnitude pruning outperforming variational dropout in most cases. The models and sparsified versions are publicly available.

Title: [Tensor Decomposition for Model Reduction in Neural Networks: A Review](http://arxiv.org/pdf/2304.13539v1)     
Summary: The paper reviews six tensor decomposition methods and their ability to reduce the computational cost of over-parameterized neural networks used in computer vision and natural language processing tasks. The review includes evaluations on compressed models with improved accuracy, reduced model size, run-time, and energy consumption. This approach is well-suited for implementing neural networks in edge devices.

Title: [Scene Graph Lossless Compression with Adaptive Prediction for Objects and Relations](http://arxiv.org/pdf/2304.13359v1)     
Summary: The paper proposes a new framework for lossless compression of scene graph data using adaptive predictors and context modeling with a Graph Context Convolution approach. The framework consists of a unified prior extractor and specialized element predictors to adapt for different data elements. Experiments show the effectiveness of this framework for scene graph compression.

Title: [Concept-Monitor: Understanding DNN training through individual neurons](http://arxiv.org/pdf/2304.13346v1)     
Summary: The paper proposes a framework called Concept-Monitor that helps to understand and visualize the DNN training process through a novel embedding space and concept diversity metric. The paper also introduces a new training regularizer that incentivizes hidden neurons to learn diverse concepts, improving training performance. The paper applies Concept-Monitor to conduct several case studies on various training paradigms, including adversarial training, fine-tuning, and network pruning via the Lottery Ticket Hypothesis.

Title: [Making Models Shallow Again: Jointly Learning to Reduce Non-Linearity and Depth for Latency-Efficient Private Inference](http://arxiv.org/pdf/2304.13274v1)     
Summary: The paper proposes a joint optimization method to reduce non-linearity and depth in deep neural networks for latency-efficient private inference. The method leverages ReLU sensitivity of a convolutional block to remove a ReLU layer and merge its surrounding convolution layers to create a shallower block. The joint reduction method can yield models with improved reduction of both non-linear and linear operations without significant accuracy drop. Evaluation on ResNet18 on CIFAR-100 shows up to 1.73x and 1.47x improvement in reducing ReLUs and linear operations, respectively.

Title: [C2PI: An Efficient Crypto-Clear Two-Party Neural Network Private Inference](http://arxiv.org/pdf/2304.13266v1)     
Summary: The paper proposes C2PI, a two-party private inference framework for neural networks that significantly reduces computational and communication costs compared to existing frameworks. They achieve this by introducing an empirically-defined privacy evaluation based on inference data privacy attacks and leveraging the findings to perform more efficient partitioning of the neural network model. Based on experimental evaluations, C2PI can speed up existing private inference frameworks and save communication costs.

Title: [Towards Compute-Optimal Transfer Learning](http://arxiv.org/pdf/2304.13164v1)     
Summary: The paper proposes a solution to the high computational and memory requirements of finetuning or using large pretrained models in transfer learning by implementing zero-shot structured pruning of pretrained models. The authors show that this method can increase compute efficiency with minimal reduction in performance and improve performance in low computational regimes by more than 20%. The method is evaluated on the Nevis'22 continual learning benchmark, which offers a diverse set of transfer scenarios.

</details>
<details>
<summary>Contrastive Learning</summary>
    
Title: [Sample-Specific Debiasing for Better Image-Text Models](http://arxiv.org/pdf/2304.13181v1)     
Summary: This paper proposes a sample-specific debiasing approach to improve the quality of learned representations in self-supervised image-text representation learning for medical applications. The approach corrects for false negatives by using estimated sample-specific class probabilities. The paper provides theoretical analysis and empirical evidence of the advantages of the proposed approach.

</details>
<details>
<summary>Continual Learning</summary>
    
Title: [Deep Lifelong Cross-modal Hashing](http://arxiv.org/pdf/2304.13357v1)     
Summary: The paper proposes a method for lifelong cross-modal hashing which allows for efficient retrieval of data with new categories without the need for re-training the hash function. The method introduces a lifelong learning strategy and hashing loss that enable the original hash codes to participate in lifelong learning while maintaining similarity and dissimilarity among original and incremental hash codes. Experimental results show comparative performance with state-of-the-art cross-modal hashing methods, with significant improvements in retrieval accuracy and training time reduction when new data arrives continuously.

Title: [Evaluation of Regularization-based Continual Learning Approaches: Application to HAR](http://arxiv.org/pdf/2304.13327v1)     
Summary: The paper evaluates three regularization-based approaches for Continual Learning in the domain of Human Activity Recognition (HAR) and compares their performance on the UCI HAR dataset. The paper highlights the strengths and limitations of each approach and concludes that no single technique outperforms all others in every scenario. The paper contributes to the growing field of Continual Learning, which enables the evolution of Machine Learning models without complete retraining.

Title: [SAFE: Machine Unlearning With Shard Graphs](http://arxiv.org/pdf/2304.13169v1)     
Summary: The paper presents SAFE, a method for machine unlearning with shard graphs. The method introduces the notion of a shard graph in which limited information from other shards is incorporated during training, instead of treating each shard as independent. This results in a modest increase in expected forgetting cost but a significant increase in accuracy, while still achieving complete removal of residual influence after forgetting. SAFE is trained on shards an order-of-magnitude smaller than current state-of-the-art methods, while maintaining high accuracy, as demonstrated empirically on fine-grained computer vision datasets.

</details>
<details>
<summary>Adversarial Learning</summary>
    
Title: [Robust decentralised proof-of-position algorithms for smart city applications](http://arxiv.org/pdf/2304.13543v1)     
Summary: The paper presents a class of decentralised algorithms called Tree-Proof-of-Position (T-PoP) for smart city applications. T-PoP algorithms are designed to establish the likelihood of an agent being in the position they claim to be, even under adversarial conditions. The paper presents a theoretical formulation for T-PoP, analyses its security and reliability properties, and validates the model through Monte-Carlo simulations. Use-cases and applications for T-PoP in smart city environments are also discussed.

Title: [Improving Adversarial Transferability by Intermediate-level Perturbation Decay](http://arxiv.org/pdf/2304.13410v1)     
Summary: The paper proposes a novel intermediate-level method, named intermediate-level perturbation decay (ILPD), to improve the transferability of adversarial examples. ILPD crafts adversarial examples within a single stage of optimization, encouraging the intermediate-level perturbation to be in an effective adversarial direction and to possess a great magnitude simultaneously. Experimental results show that ILPD outperforms state-of-the-arts by large margins in attacking various victim models on ImageNet and CIFAR-10 datasets.

Title: [Concept-Monitor: Understanding DNN training through individual neurons](http://arxiv.org/pdf/2304.13346v1)     
Summary: The paper proposes a framework called Concept-Monitor that helps to understand and visualize the DNN training process through a novel embedding space and concept diversity metric. The paper also introduces a new training regularizer that incentivizes hidden neurons to learn diverse concepts, improving training performance. The paper applies Concept-Monitor to conduct several case studies on various training paradigms, including adversarial training, fine-tuning, and network pruning via the Lottery Ticket Hypothesis.

Title: [SHIELD: Thwarting Code Authorship Attribution](http://arxiv.org/pdf/2304.13255v1)     
Summary: This paper introduces SHIELD, a method to examine the robustness of different code authorship attribution approaches against adversarial attacks. The paper defines and implements four attacks on attribution techniques using adversarial code perturbation and experiments with a dataset of 200 programmers from the Google Code Jam competition. The study shows the vulnerability of current authorship attribution methods against non-targeted attacks with a success rate exceeding 98.5% and the possibility of impersonating a programmer using targeted-adversarial perturbations with a success rate ranging from 66% to 88%.

Title: [Analyzing In-browser Cryptojacking](http://arxiv.org/pdf/2304.13253v1)     
Summary: This paper analyzes the static, dynamic, and economic aspects of in-browser cryptojacking, which involves the unauthorized use of a device's resources to mine cryptocurrencies via malicious JavaScript codes. The paper categorizes and analyzes samples of cryptojacking scripts using machine learning techniques, tests the effect of cryptojacking on system resources, and builds an analytical model to evaluate the feasibility of cryptojacking as an alternative to online advertising. The paper also proposes countermeasures for in-browser cryptojacking that improve existing remedies.

Title: [Generating Adversarial Examples with Task Oriented Multi-Objective Optimization](http://arxiv.org/pdf/2304.13229v1)     
Summary: The paper proposes a novel approach called Task Oriented Multi-Objective Optimization (TAMOO) to generate adversarial examples which satisfy specific objectives. The proposed approach aims to maintain task-goals that have already been achieved and allocate more effort towards improving task-goals that have not been achieved yet. Comprehensive experiments show that TAMOO outperforms existing methods in generating effective and diverse adversarial examples.

</details>
<details>
<summary>Federated Learning</summary>
    
Title: [Unlocking the Potential of Collaborative AI -- On the Socio-technical Challenges of Federated Machine Learning](http://arxiv.org/pdf/2304.13688v2)     
Summary: This academic paper focuses on the challenges of collaborative AI projects and how Federated Machine Learning can potentially unlock untapped data silos. Through a systematic literature review, focus group, and expert interviews, the paper provides a collection of socio-technical challenges and an extended Business Model Canvas for the initial viability assessment of collaborative AI projects.

Title: [FLCC: Efficient Distributed Federated Learning on IoMT over CSMA/CA](http://arxiv.org/pdf/2304.13549v1)     
Summary: This paper proposes an efficient distributed federated learning approach called FLCC to improve a remote healthcare system over ad hoc networks. The FL model utilizes CSMA/CA to schedule transmissions and eliminates untrusted devices. The approach uses spatial clustering and frequency allocation techniques to improve the data exchange process between nodes. The proposed FLCC approach surpasses the baseline FL algorithms in terms of explicitly defining user criteria and achieving high accuracy in a robust network.

Title: [Killing Two Birds with One Stone: Quantization Achieves Privacy in Distributed Learning](http://arxiv.org/pdf/2304.13545v1)     
Summary: This paper proposes a quantization-based solution to address privacy-preserving machine learning and communication efficiency in distributed settings. The proposed method adds binomial noise to uniformly quantized gradients to achieve differential privacy levels while maintaining communication efficiency. The approach is demonstrated in the context of distributed stochastic gradient descent and provides new insights into the trade-offs between communication, privacy, and learning performance.

Title: [Byzantine-Resilient Learning Beyond Gradients: Distributing Evolutionary Search](http://arxiv.org/pdf/2304.13540v1)     
Summary: The paper proposes a method to create byzantine-resilient distributed learning algorithms in a gradient-free setting. The authors introduce a general definition of byzantine-resilience in machine learning - the model-consensus - that extends classical distributed consensus. They show that gradient-free ($1,\lambda$)-Evolutionary Search algorithms can be combined with classical distributed consensus algorithms to generate gradient-free byzantine-resilient distributed learning algorithms. The method is demonstrated using Total Order Broadcast and proof-of-work leader election.

Title: [Fair Selection of Edge Nodes to Participate in Clustered Federated Multitask Learning](http://arxiv.org/pdf/2304.13423v1)     
Summary: This paper introduces a two-phased client selection and scheduling approach to improve the convergence speed while capturing all data distributions in clustered federated multitask learning. The proposed algorithms reduce training time and improve the convergence speed while providing every user with a customized model tailored to its data distribution.

Title: [Secure Communication Model For Quantum Federated Learning: A Post Quantum Cryptography (PQC) Framework](http://arxiv.org/pdf/2304.13413v1)     
Summary: The paper presents a Secure Communication Model for Quantum Federated Learning using a Post Quantum Cryptography (PQC) Framework. The model includes a dynamic server selection and investigates convergence and security conditions. The results and implementation of the framework are publicly available. The approach combines federated learning with quantum computing techniques, making it an interesting contribution to both fields.

Title: [FedVS: Straggler-Resilient and Privacy-Preserving Vertical Federated Learning for Split Models](http://arxiv.org/pdf/2304.13407v1)     
Summary: This paper proposes FedVS, a solution to address two major challenges in split vertical federated learning: performance degradation due to straggling clients during training and data and model privacy leakage from clients' uploaded data embeddings. FedVS uses secret sharing schemes for local data and models to ensure information-theoretical privacy and reconstructs aggregation of embeddings via decrypting computation shares from non-straggling clients. The experiments demonstrate the advantages of FedVS in straggler mitigation and privacy protection over baseline protocols on various types of VFL datasets.

Title: [Blockchain-based Federated Learning with SMPC Model Verification Against Poisoning Attack for Healthcare Systems](http://arxiv.org/pdf/2304.13360v1)     
Summary: The paper proposes a blockchain-based federated learning framework for healthcare systems. The framework includes an SMPC model verification process to detect and remove malicious updates from FL clients. The proposed approach is evaluated using various medical datasets.

Title: [SMPC-based Federated Learning for 6G enabled Internet of Medical Things](http://arxiv.org/pdf/2304.13352v1)     
Summary: The paper proposes a Secure Multi-Party Computation (SMPC)-based Federated Learning framework for the Internet of Medical Things (IoMT) powered by Sixth Generation (6G) connectivity. The framework employs Convolutional Neural Networks (CNNs) and Encrypted Inference methods to improve model accuracy and maintain data and model privacy among multiple hospitals with clusters of mixed IoMT and edge devices. The proposed framework's performance was evaluated through experiments with various CNN models and datasets.

Title: [Bayesian Federated Learning: A Survey](http://arxiv.org/pdf/2304.13267v1)     
Summary: This paper provides a survey of Bayesian federated learning (BFL), which addresses the limitations of existing federated learning methods, including limited and dynamic data and conditions, heterogeneities, and uncertainties. The paper discusses client- and server-side and federated BFL methods and their pros and cons, as well as the limitations of existing BFL methods and future directions for BFL research to address the complex requirements of real-life federated learning applications.

</details>
<details>
<summary>Video</summary>
    
Title: [A Control-Centric Benchmark for Video Prediction](http://arxiv.org/pdf/2304.13723v1)     
Summary: The paper proposes a control-centric benchmark called VP2 for action-conditioned video prediction in the context of robotic manipulation. The benchmark is designed to evaluate how accurately a given model can predict execution success through sampling-based planning. The authors use the benchmark to analyze the effects of model size, training data quantity, and ensembling on planning performance. They find that while scale can improve perceptual quality, uncertainty awareness is also important for planning.

Title: [Video Frame Interpolation with Densely Queried Bilateral Correlation](http://arxiv.org/pdf/2304.13596v1)     
Summary: The paper proposes a new approach for Video Frame Interpolation (VFI) called Densely Queried Bilateral Correlation (DQBC). This approach models correlations between neighboring frames in a way that is more friendly to small and fast-moving objects. The motion fields generated by DQBC are refined and up-sampled with context features before a CNN-based SynthNet synthesizes the final interpolated frame. The approach results in higher accuracy and less inference time than state-of-the-art approaches.

Title: [Latency Target based Analysis of the DASH.js Player](http://arxiv.org/pdf/2304.13551v1)     
Summary: This paper analyses the low latency performance of the Adaptive Bitrate (ABR) algorithms in the dash.js Dynamic Adaptive Streaming over HTTP (DASH) player with respect to a range of latency targets and configuration options. The study shows that the default Dynamic algorithm achieves the best overall QoE and highlights how some low latency configuration settings can be detrimental to performance. The paper also provides modifications to the L2A-LL algorithm to demonstrate significant improvements.

Title: [StepFormer: Self-supervised Step Discovery and Localization in Instructional Videos](http://arxiv.org/pdf/2304.13265v1)     
Summary: The paper presents StepFormer, a self-supervised transformer decoder model that can discover and localize instruction steps in videos without any human annotation. The model is trained on a large dataset of instructional videos using automatically generated subtitles, and it outperforms previous unsupervised and weakly-supervised approaches on step detection and localization tasks by a significant margin. Additionally, the model can perform zero-shot multi-step localization, and it demonstrates emergent properties that allow it to achieve better performance than relevant baselines.

</details>
<details>
<summary>3D</summary>
    
Title: [Ray Conditioning: Trading Photo-consistency for Photo-realism in Multi-view Image Generation](http://arxiv.org/pdf/2304.13681v1)     
Summary: The paper proposes a technique called ray conditioning that generates multi-view images by conditioning a 2D GAN on a light field prior. The method allows for explicit viewpoint control, state-of-the-art photorealism, and identity consistency, making it suitable for the viewpoint editing task. By relaxing the photo-consistency constraint, the method achieves a balance between photo-consistency and photorealism, addressing the trade-off between the two.

Title: [Multi-View Stereo Representation Revisit: Region-Aware MVSNet](http://arxiv.org/pdf/2304.13614v2)     
Summary: The paper proposes a region-aware MVSNet for multi-view stereo representation that predicts a distance volume from the cost volume to estimate the signed distance of points around the surface, enhancing the perception range, completing textureless regions, reducing outliers at boundaries, and generating mesh topologies with fine details. The approach achieves state-of-the-art results on both DTU and Tanks & Temples datasets, demonstrating its effectiveness in reconstructing complete geometrically-detailed objects from multi-views.

Title: [Hydra-Multi: Collaborative Online Construction of 3D Scene Graphs with Multi-Robot Teams](http://arxiv.org/pdf/2304.13487v1)     
Summary: This paper proposes Hydra-Multi, the first multi-robot spatial perception system capable of constructing a joint 3D scene graph online from sensor data collected by robots in a team. It is a centralized system that incorporates loop closure detections and effectively finds the relative transforms between the robots' frames, while supporting heterogeneous teams by fusing different map representations built by robots with different sensor suites. The proposed method is evaluated on simulated and real scenarios and shows accurate 3D scene reconstruction.

Title: [Group Equivariant BEV for 3D Object Detection](http://arxiv.org/pdf/2304.13390v1)     
Summary: The paper proposes a group equivariant bird's eye view network (GeqBevNet) for 3D object detection in dynamic driving scenes. The network is based on the group equivariant theory and is embedded into the fused BEV feature map to extract rotational equivariant features, leading to lower average orientation error. The GeqBevNet is verified on the nuScenes validation dataset, and the experimental results demonstrate improved performance in object orientation prediction.

Title: [ZRG: A High Resolution 3D Residential Rooftop Geometry Dataset for Machine Learning](http://arxiv.org/pdf/2304.13219v1)     
Summary: The paper presents a new dataset called ZRG that contains high resolution orthomosaics of aerial imagery of residential rooftops along with corresponding digital surface models, 3D rooftop wireframes, and multiview imagery generated point clouds to enable residential rooftop geometry and scene understanding. The paper also provides baselines for the tasks of roof outline extraction, monocular height estimation, and planar roof structure extraction.

Title: [LumiGAN: Unconditional Generation of Relightable 3D Human Faces](http://arxiv.org/pdf/2304.13153v1)     
Summary: This paper introduces LumiGAN, an unconditional GAN for generating 3D human faces with a physically based lighting module that enables relighting under novel illumination at inference time. LumiGAN can create realistic shadow effects using an efficient visibility formulation that is learned in a self-supervised manner, and generates plausible physical properties for relightable faces without any ground truth data. The paper showcases significantly improved geometry generation compared to state-of-the-art non-relightable 3D GANs and notably better photorealism than existing relightable GANs.

</details>
<details>
<summary>Sound</summary>
    
</details>
<details>
<summary>Dataset</summary>
    
Title: [HeySQuAD: A Spoken Question Answering Dataset](http://arxiv.org/pdf/2304.13689v1)     
Summary: The paper introduces a new large-scale community-shared spoken question answering (SQA) dataset, HeySQuAD, consisting of human-spoken and machine-generated questions and corresponding textual answers. The dataset aims to measure the ability of machines to understand noisy spoken questions and answer them accurately. The paper also presents benchmarks and observations on the impact of noise from human-spoken and machine-generated questions on model and answering accuracy. Significantly, the paper highlights that training using transcribed human-spoken questions leads to significant improvements over training on original textual questions only, for the task of SQA.

Title: [What Happened 3 Seconds Ago? Inferring the Past with Thermal Imaging](http://arxiv.org/pdf/2304.13651v1)     
Summary: This paper introduces a new dataset called Thermal-IM, which is the first RGB-Thermal dataset for human motion analysis. The authors also propose a three-stage neural network model for accurate past human pose estimation using thermal cues. The dataset and model achieve remarkable performance, demonstrating the usefulness of thermal imaging in inferring past human-object interactions.

Title: [ChartSumm: A Comprehensive Benchmark for Automatic Chart Summarization of Long and Short Summaries](http://arxiv.org/pdf/2304.13620v1)     
Summary: The paper introduces ChartSumm, a large-scale benchmark dataset for automatic chart summarization consisting of 84,363 charts with metadata and descriptions covering various types and topics. The dataset is a challenging benchmark for future research as strong baseline models face issues such as hallucination and missing out on important data points. The potential of expanding ChartSumm to other languages is also investigated.

Title: [SIMARA: a database for key-value information extraction from full pages](http://arxiv.org/pdf/2304.13606v1)     
Summary: The paper introduces SIMARA, a database for information extraction from historical handwritten documents. The corpus includes annotated finding aids from the National Archives of France. The proposed model is based on the Transformer architecture trained for end-to-end information extraction, and three sets are provided for training, validation, and testing. The database is freely accessible.

Title: [The Systematic Review-lution: A Manifesto to Promote Rigour and Inclusivity in Research Synthesis](http://arxiv.org/pdf/2304.13556v1)     
Summary: The paper titled "The Systematic Review-lution: A Manifesto to Promote Rigour and Inclusivity in Research Synthesis" argues for a revolution in the meta-level approach to research within HCI, emphasizing the need for greater rigour in primary research reporting and careful consideration of both primary and secondary research methods, expectations, and infrastructure. The paper calls for the development of an inclusive but rigorous set of standards that support systematic review work in HCI.

Title: [LoRaWAN-enabled Smart Campus: The Dataset and a People Counter Use Case](http://arxiv.org/pdf/2304.13366v1)     
Summary: This paper presents a detailed description of a Smart Campus dataset based on LoRaWAN technology. The dataset is openly available and includes missing transmission analysis and a solution using k-nearest neighbor as well as future readings prediction through long short-term memory (LSTM) models. One application is demonstrated with a deep neural network predicting the number of people inside a room with an accuracy of 95%.

Title: [ZRG: A High Resolution 3D Residential Rooftop Geometry Dataset for Machine Learning](http://arxiv.org/pdf/2304.13219v1)     
Summary: The paper presents a new dataset called ZRG that contains high resolution orthomosaics of aerial imagery of residential rooftops along with corresponding digital surface models, 3D rooftop wireframes, and multiview imagery generated point clouds to enable residential rooftop geometry and scene understanding. The paper also provides baselines for the tasks of roof outline extraction, monocular height estimation, and planar roof structure extraction.

Title: [TABLET: Learning From Instructions For Tabular Data](http://arxiv.org/pdf/2304.13188v1)     
Summary: The paper introduces a benchmark dataset, called TABLET, consisting of 20 diverse tabular datasets annotated with natural language instructions for solving tabular prediction problems using large language models (LLMs). The study finds that in-context instructions improve the zero-shot F1 performance of Flan-T5 11b and ChatGPT on TABLET. However, LLMs often ignore instructions and fail to predict specific instances correctly, even with examples, indicating the need for new capabilities in learning from instructions for tabular data.

Title: [Dynamic Datasets and Market Environments for Financial Reinforcement Learning](http://arxiv.org/pdf/2304.13174v1)     
Summary: The paper presents FinRL-Meta, an open-source library that processes dynamic datasets from real-world financial markets into gym-style market environments for training financial reinforcement learning agents, which is difficult due to the low signal-to-noise ratio and survivorship bias of financial data. The library provides a data curation pipeline, reproducible examples, cloud deployment, community-wise competitions, and documentation through Jupyter/Python demos. The library is openly accessible and maintained by the AI4Finance community.

Title: [Introducing MBIB -- the first Media Bias Identification Benchmark Task and Dataset Collection](http://arxiv.org/pdf/2304.13148v1)     
Summary: The paper introduces MBIB, a Media Bias Identification Benchmark consisting of nine tasks and 22 associated datasets for evaluating media bias detection techniques. The authors evaluate the benchmark using state-of-the-art Transformer techniques and find an uneven distribution of research interest and resource allocation to individual bias types. The unified benchmark shifts the current paradigm towards developing more robust systems that tackle multiple bias types simultaneously.

</details>
<details>
<summary>Theory</summary>
    
Title: [Cut-restriction: from cuts to analytic cuts](http://arxiv.org/pdf/2304.13657v1)     
Summary: This paper introduces a procedure called cut-restriction to restrict arbitrary cuts to analytic cuts. This procedure applies to all sequent calculi satisfying language-independent and simple-to-check conditions and is obtained by adapting the age-old cut-elimination. The paper encompasses existing results in a uniform way and establishes novel analytic subformula properties.

Title: [Automatic Amortized Resource Analysis with Regular Recursive Types](http://arxiv.org/pdf/2304.13627v1)     
Summary: The paper presents a solution to the challenge of inferring bounds on the resource consumption of programs that use complex custom data structures. The paper proposes a type-based automatic amortized resource analysis (AARA) technique, which uses potential method of amortized analysis to reduce bound inference to standard type inference with additional linear constraint solving. The paper introduces resource polynomials, which are functions that generate the space of possible bounds for values of a given type, and demonstrates their ability to be integrated with AARA while preserving the benefits of past techniques. The authors show that resource polynomials can be uniformly constructed for algebraic data structures defined by regular recursive types, enabling a broad generalization of all previously proposed polynomial resource functions. The paper also proposes the use of new techniques for stating the rules of this type system and proving its soundness.

Title: [On the Order of Power Series and the Sum of Square Roots Problem](http://arxiv.org/pdf/2304.13605v1)     
Summary: The paper focuses on the study of the order of power series and the sum of square roots problem. The authors show that the Wronskian approach used to bound the order of the sum of square roots is optimal up to a polynomial blowup. They also investigate upper bounds for the order of power series in various scenarios and solve a special case of the inequality testing problem. The second part of the paper deals with a generalization of the equality variant of the sum of square roots problem and identifies the key mathematical challenges in solving it.

Title: [Leapfrog methods for relativistic charged-particle dynamics](http://arxiv.org/pdf/2304.13578v1)     
Summary: The paper proposes and analyses basic leapfrog integrators, their energy-preserving and variational/symplectic variants for numerical integration of the equations of motion of relativistic charged particles in an electromagnetic field. The numerical methods preserve structure such as conservation and long-time near-conservation of energy and mass shell, and preservation of volume in phase space. In the non-relativistic limit, the considered methods reduce to the Boris algorithm for non-relativistic charged-particle dynamics and its energy-preserving and variational/symplectic variants.

Title: [A strongly universal cellular automaton on the heptagrif with seven states, new proof](http://arxiv.org/pdf/2304.13575v1)     
Summary: The paper presents a new proof for the existence of a strongly universal cellular automaton with seven states on the heptagrid that is rotation invariant. The new proof improves upon a previous paper by simplifying the structures and reducing the number of rules required.

Title: [The Systematic Review-lution: A Manifesto to Promote Rigour and Inclusivity in Research Synthesis](http://arxiv.org/pdf/2304.13556v1)     
Summary: The paper titled "The Systematic Review-lution: A Manifesto to Promote Rigour and Inclusivity in Research Synthesis" argues for a revolution in the meta-level approach to research within HCI, emphasizing the need for greater rigour in primary research reporting and careful consideration of both primary and secondary research methods, expectations, and infrastructure. The paper calls for the development of an inclusive but rigorous set of standards that support systematic review work in HCI.

Title: [Turning block-sequential automata networks into smaller parallel networks with isomorphic limit dynamics](http://arxiv.org/pdf/2304.13550v1)     
Summary: The paper presents an algorithm to turn block-sequential automata networks into smaller parallel networks with isomorphic limit dynamics. The algorithm is restricted to a family of automata cycles known as tangential cycles and can reduce any instance of these networks while conserving their limit dynamics. The paper also characterizes the number of reductions operated and shows that any tangential cycle reduced by the algorithm is transformed into a network whose size is that of the largest cycle of the initial network. Additionally, the paper allows the direct characterization of block-sequential double cycles as parallel ones.

Title: [A Two-Step Rule for Backpropagation](http://arxiv.org/pdf/2304.13537v1)     
Summary: This paper presents a simplified two-step computational rule for the back-propagation algorithm in artificial neural networks. The rule incorporates both the forward and backward phases of computations involved in the learning process and efficiently propagates changes to all synaptic weights in the network. The paper specifically focuses on computing up and down partial derivatives of the cost function of all connections feeding into the output layer.

Title: [Towards replicated algorithms](http://arxiv.org/pdf/2304.13524v1)     
Summary: The paper introduces the concept of replicated algorithms, which are capable of replicating themselves and solving problems in parallel similar to the human brain. These algorithms operate as a model for mapping known inputs to known outputs and can operate in the condition of open-ended evolution.

Title: [Sequential decomposition of propositional logic programs](http://arxiv.org/pdf/2304.13522v1)     
Summary: The paper proposes a study of the sequential decomposition of propositional logic programs by examining well-known Green's relations in semigroup theory between programs. The ultimate goal is to contribute to the development of an algebraic theory of logic programming.

Title: [Deterministic stream-sampling for probabilistic programming: semantics and verification](http://arxiv.org/pdf/2304.13504v1)     
Summary: This paper presents a higher-order probabilistic programming language centered on the notion of samplers and sampler operations, and provides an operational and denotational semantics in terms of continuous maps between topological spaces. The paper also develops tools for the formal verification of sampler correctness, presenting an equational calculus to reason about equivalence of samplers and a sound calculus to prove semantic correctness of samplers.

Title: [How Semantic Information G Measure Relates to Distortion, Freshness, Purposiveness, and Efficiency](http://arxiv.org/pdf/2304.13502v1)     
Summary: The paper proposes a semantic information measure called G measure, which combines distortion, freshness, purposiveness, and efficiency to improve communication efficiency and provide more useful information. The measure is discussed in the context of semantic predictive information and purposive information and is applied to optimization problems. The paper also suggests that the G measure may have potential applications in deep learning. Further research is needed to explore semantic communication optimization combining utilities.

Title: [Fundamental Tradeoffs in Learning with Prior Information](http://arxiv.org/pdf/2304.13479v1)     
Summary: The paper explores the tradeoffs between the accuracy of prior information and learning performance in statistical estimation problems. It introduces the concept of prioritized risk and presents a reduction-based approach for lower bounding the prioritized risk. The approach provides insights into tradeoffs between prior information and learning performance for different problems, including estimation, regression, and reinforcement learning.

Title: [An efficient multiple harmonic balance method for computing quasi-periodic responses of nonlinear systems](http://arxiv.org/pdf/2304.13446v1)     
Summary: The paper proposes a reconstruction multiple harmonic balance (RMHB) method for computing quasi-periodic responses of nonlinear systems. The method is based on discrete time domain collocations and addresses the issue of non-physical solutions in existing time domain MHB-like methods caused by aliasing. The proposed method is shown to be more efficient and robust than state-of-the-art methods in numerical examples.

Title: [The Logic of Logic Programming](http://arxiv.org/pdf/2304.13430v1)     
Summary: The paper explores the logic of logic programming and argues that it is not programming in the Horn clause sublogic of classical logic, but rather programming in a logic of (inductive) definitions. They propose that this provides a natural solution to the main semantic questions of logic programming and its extensions.

Title: [With a little help from your friends: semi-cooperative games via Joker moves](http://arxiv.org/pdf/2304.13417v1)     
Summary: The paper introduces the concept of "Joker games", where Player 2 helps Player 1 by playing a Joker move in semi-cooperative games. The paper formalizes these games as cost games and studies their theoretical properties. The paper also illustrates the use of Joker games in model-based testing.

Title: [MacWilliams' Extension Theorem for rank-metric codes](http://arxiv.org/pdf/2304.13341v1)     
Summary: The paper explores the applicability of MacWilliams' Extension Theorem to rank-metric codes, which are codes endowed with a metric that measures the rank distance between two codewords. It provides examples of obstructions to the existence of an extension and a positive result.

Title: [Game-Theoretically Secure Protocols for the Ordinal Random Assignment Problem](http://arxiv.org/pdf/2304.13338v1)     
Summary: The paper studies game-theoretically secure protocols for the ordinal random assignment problem, where players have a total preference order on items. The authors investigate the game-theoretic notion of maximin security and give an impossibility result that shows no maximin secure protocol can achieve both fairness and ordinal efficiency. They also propose a maximin secure protocol that achieves fairness and stability and a variant inspired by the probabilistic serial mechanism that achieves fairness, stability, and uniform dominance.

Title: [Nominal Topology for Data Languages](http://arxiv.org/pdf/2304.13337v1)     
Summary: The paper introduces a new topological perspective on data languages that are recognized by orbit-finite nominal monoids. They propose pro-orbit-finite nominal topological spaces and characterize recognizable data languages as topologically clopen sets of pro-orbit-finite words. The paper also explores the expressive power of pro-orbit-finite equations by establishing a nominal version of Reiterman's pseudovariety theorem.

Title: [Entropy-based convergence rates of greedy algorithms](http://arxiv.org/pdf/2304.13332v1)     
Summary: The paper presents convergence estimates of two types of greedy algorithms in terms of the metric entropy of underlying compact sets. The first part measures the error of a standard greedy reduced basis method for parametric PDEs, while the second part derives a novel and simple convergence analysis of the classical orthogonal greedy algorithm for nonlinear dictionary approximation. The entropy-based convergence estimate is compared with classical width-based analysis for reduced basis methods and improves upon existing results for dictionary approximation.

Title: [Specifying programs with propositions and with congruences](http://arxiv.org/pdf/2304.13321v1)     
Summary: The paper presents Krivine and Parigot's Second-order functional arithmetic in Deduction modulo and highlights the unique aspect of the theory where programs are specified with congruences instead of propositions.

Title: [Simple Type Theory as a Clausal Theory](http://arxiv.org/pdf/2304.13319v1)     
Summary: The paper presents Simple Type Theory as a clausal rewrite system in Polarized deduction modulo. It gives a formal presentation of the theory and demonstrates how it can be used as a basis for logical reasoning. The paper falls under the category of Theory.

Title: [The physical Church thesis and the sensitivity to initial conditions](http://arxiv.org/pdf/2304.13318v1)     
Summary: The paper discusses the physical Church thesis and its compatibility with chaotic dynamical systems. It argues that there exist computable chaotic systems, thereby suggesting that chaos is not inconsistent with computability, similar to how it is not incompatible with determinism.

Title: [Preconditioned discontinuous Galerkin method and convection-diffusion-reaction problems with guaranteed bounds to resulting spectra](http://arxiv.org/pdf/2304.13315v1)     
Summary: This paper presents a new preconditioning concept for linear second-order partial differential equations, specifically for convection-diffusion-reaction problems discretized by Galerkin or discontinuous Galerkin methods. The method provides guaranteed bounds to resulting spectra, including all individual eigenvalues of the preconditioned matrix in the case of a symmetric problem, and real and imaginary parts of resulting eigenvalues in the case of a non-symmetric problem. The approach is shown to be effective through numerical experiments.

Title: [Technical Note: Defining and Quantifying AND-OR Interactions for Faithful and Concise Explanation of DNNs](http://arxiv.org/pdf/2304.13312v1)     
Summary: The paper proposes a new method for explaining the inference logic of deep neural networks (DNNs) by quantifying the AND-OR interactions between input variables. The authors redefine the definition of interactions and demonstrate the uniqueness of AND and OR interactions in quantifying the effect of the relationship between input variables. They also propose techniques to boost the conciseness of the explanation while maintaining faithfulness. The paper provides a new way to explain the behavior of DNNs using symbolic concepts.

Title: [Solution of planar elastic stress problems using stress basis functions](http://arxiv.org/pdf/2304.13251v1)     
Summary: This paper proposes two methods for solving stress problems in linear elasticity using stress basis functions. The first method involves minimizing the strain energy using a complementary energy principle. The second method is restricted to planar homogeneous isotropic bodies and involves minimizing the squared L^2 norm of the trace of stress. The paper demonstrates the application of these methods to solve various stress problems, including those with sharp corners, multiple-connectedness, and material inhomogeneity. The proposed methods present new principles in the field of linear elasticity.

Title: [Numerical Approximation of Andrews Plots with Optimal Spatial-Spectral Smoothing](http://arxiv.org/pdf/2304.13239v1)     
Summary: This paper presents a technical analysis of Andrews plots and develops a solution to an infinite-dimensional quadratic minimization program over linear isometries from Euclidean space to $L^2([0,1])$. The authors also introduce spectral smoothing terms to induce optimal spatial-spectral smoothing in Andrews plots and show that the resulting plots have efficient numerical approximations.

Title: [Performance of the Gittins Policy in the G/G/1 and G/G/k, With and Without Setup Times](http://arxiv.org/pdf/2304.13231v1)     
Summary: This academic paper investigates the performance of the Gittins policy in the G/G/1 and G/G/k queue models, with and without setup times, and assesses whether the policy is still effective beyond the M/G/1 model. The paper establishes that Gittins is optimal in these systems under heavy traffic, with negligible suboptimality gaps, and provides a theoretical analysis of the policy that can handle multiple servers, non-Poisson arrivals, and setup times.

Title: [The Nonlocal Neural Operator: Universal Approximation](http://arxiv.org/pdf/2304.13221v1)     
Summary: This paper introduces a new class of operator approximators, called nonlocal neural operators (NNOs), which are capable of approximating operators between functions defined on arbitrary geometries, and includes the Fourier neural operator (FNO) as a special case. The paper also presents analysis of the NNOs, which shows that if the architecture includes computation of a spatial average, it benefits from universal approximation. The result unifies the analysis of a wide range of neural operator architectures and sheds new light on the interaction of nonlocality and nonlinearity.

Title: [Reconfiguration of the Union of Arborescences](http://arxiv.org/pdf/2304.13217v1)     
Summary: The paper demonstrates the reconfigurability of the union of k arborescences in digraphs, generalizing a previous result for k=1. The union of k arborescences can be represented as a common matroid basis of two matroids, giving a non-trivial example of matroid pairs for which two common bases are always reconfigurable to each other. This paper falls under the categories of Graph Neural Networks and Theory.

</details>
<details>
<summary>Natural Language Processing</summary>
    
Title: [Harnessing the Power of LLMs in Practice: A Survey on ChatGPT and Beyond](http://arxiv.org/pdf/2304.13712v2)     
Summary: This paper provides a practical guide for practitioners and end-users working with Large Language Models (LLMs) in their downstream natural language processing (NLP) tasks. The paper discusses the importance of pre-training data, training data, and test data, and provides a detailed discussion about the use and non-use cases of LLMs for various NLP tasks. The paper also explores the impact of spurious biases on LLMs and other essential considerations for deploying LLMs in practice. The authors aim to provide researchers and practitioners with valuable insights and best practices for working with LLMs.

Title: [Using Implicit Feedback to Improve Question Generation](http://arxiv.org/pdf/2304.13664v1)     
Summary: The paper proposes a system called GEN that learns from implicit feedback to improve question generation in NLP. GEN takes sentence/question pairs as input and creates patterns to generate new questions. Each generated question, when corrected by the user, is used as a new seed in the next iteration to create more patterns. GEN takes advantage of the corrections to score patterns and rank generated questions. Results show that GEN improves by learning from implicit feedback and can increase question generation performance by up to 10%.

Title: [HausaNLP at SemEval-2023 Task 12: Leveraging African Low Resource TweetData for Sentiment Analysis](http://arxiv.org/pdf/2304.13634v1)     
Summary: This paper presents the results of SemEval-2023 Task 12, a sentiment analysis task for low-resource African languages using Twitter data. The task had three subtasks, including a zero-shot sentiment classification. The study leveraged pre-trained large language models, including Afro-xlmr-large and BERT, for sentiment analysis in 14 African languages. The findings showed that Afro-xlmr-large performed better than the other models, and Nigerian languages had higher performance due to the larger volume of data. The paper also released the code on GitHub.

Title: [Shades of meaning: Uncovering the geometry of ambiguous word representations through contextualised language models](http://arxiv.org/pdf/2304.13597v1)     
Summary: This paper explores the challenge of lexical ambiguity and how it is represented in contextualized language models. The authors use simulations to show that these models can capture fine-grained distinctions between unambiguous, homonymous, and polysemous words, aligning with lexicographic classifications and psychological theories. The findings provide quantitative support for modern psychological conceptualizations of lexical ambiguity and raise new challenges for understanding the way contextual information shapes the meanings of words across different timescales.

Title: [Impact of Position Bias on Language Models in Token Classification](http://arxiv.org/pdf/2304.13567v1)     
Summary: The paper investigates the impact of position bias on the performance of language models in token classification tasks. The study includes various benchmark datasets for named entity recognition and part-of-speech tagging. The authors propose two methods to mitigate the effect of position bias and show improvement in model performance. The paper focuses on evaluating the performance of Transformer models in a specific issue of language models.

Title: ["I'm" Lost in Translation: Pronoun Missteps in Crowdsourced Data Sets](http://arxiv.org/pdf/2304.13557v1)     
Summary: The paper discusses the biases and challenges in the translation of pronouns between English and Japanese in crowdsourced data sets for natural language processing (NLP) tasks. The authors identify biases towards masculine pronouns and nuanced reactions towards feminine, neutral, and non-binary pronouns. Their solution includes embedding plurality in NLP data sets to address these biases.

Title: [Zero-Shot Slot and Intent Detection in Low-Resource Languages](http://arxiv.org/pdf/2304.13292v1)     
Summary: The paper presents a study on zero-shot slot and intent detection in low-resource languages. Various models and settings were tested, including the recently successful multitask-prompted fine-tuning approach using large language models. The results show that the best model outperforms the baseline by a significant margin in both tasks, demonstrating the potential of zero-shot learning for low-resource language understanding.

Title: [Improving Conversational Passage Re-ranking with View Ensemble](http://arxiv.org/pdf/2304.13290v1)     
Summary: The paper proposes a conversational passage re-ranker called ConvRerank, which uses a new pseudo-labeling approach to improve its fine-tuning. The proposed view-ensemble method enhances the quality of the pseudo-labeled data, resulting in a balance between effectiveness and efficiency when combined with a conversational dense retriever in a cascaded pipeline. The approach shows potential in improving the effectiveness of conversational search.

Title: [Structure Diagram Recognition in Financial Announcements](http://arxiv.org/pdf/2304.13240v1)     
Summary: The paper proposes a new method for accurately recognizing and extracting structured data from financial announcements' structure diagrams, which can be used to build financial knowledge graphs and improve financial applications' efficiency. The method includes detecting and extracting different types of connecting lines, synthesizing and annotating a large number of diagrams to create a benchmark, and experimentally verifying the significant performance advantage over previous methods.

Title: [Towards Explainable and Safe Conversational Agents for Mental Health: A Survey](http://arxiv.org/pdf/2304.13191v1)     
Summary: This paper presents a survey of existing conversational agents in mental health and discusses the need for a more comprehensive, safe, and explainable approach to build responsible Virtual Mental Health Assistants (VMHAs). The paper proposes new directions towards enriching the user experience of VMHAs with explainability, safety, and wholesome trustworthiness. The paper also offers evaluation metrics and practical considerations for VMHAs beyond current literature to build trust between VMHAs and patients in active communications.

Title: [TABLET: Learning From Instructions For Tabular Data](http://arxiv.org/pdf/2304.13188v1)     
Summary: The paper introduces a benchmark dataset, called TABLET, consisting of 20 diverse tabular datasets annotated with natural language instructions for solving tabular prediction problems using large language models (LLMs). The study finds that in-context instructions improve the zero-shot F1 performance of Flan-T5 11b and ChatGPT on TABLET. However, LLMs often ignore instructions and fail to predict specific instances correctly, even with examples, indicating the need for new capabilities in learning from instructions for tabular data.

Title: [Sebis at SemEval-2023 Task 7: A Joint System for Natural Language Inference and Evidence Retrieval from Clinical Trial Reports](http://arxiv.org/pdf/2304.13180v1)     
Summary: The paper describes a joint system for natural language inference and evidence retrieval from clinical trial reports. Two systems were developed: a pipeline and a joint system with a shared representation and multi-task learning approach. The final system combines their outputs in an ensemble system. The paper formalizes the models, presents their characteristics and challenges, and provides an analysis of achieved results.

Title: [Modeling Spoken Information Queries for Virtual Assistants: Open Problems, Challenges and Opportunities](http://arxiv.org/pdf/2304.13149v1)     
Summary: This academic paper focuses on the challenges and opportunities of modeling spoken information queries for virtual assistants. The authors suggest using query domain classification, knowledge graphs, user interaction data, and query personalization to improve speech recognition accuracy. The paper also covers current problems and challenges in speech recognition.

Title: [Introducing MBIB -- the first Media Bias Identification Benchmark Task and Dataset Collection](http://arxiv.org/pdf/2304.13148v1)     
Summary: The paper introduces MBIB, a Media Bias Identification Benchmark consisting of nine tasks and 22 associated datasets for evaluating media bias detection techniques. The authors evaluate the benchmark using state-of-the-art Transformer techniques and find an uneven distribution of research interest and resource allocation to individual bias types. The unified benchmark shifts the current paradigm towards developing more robust systems that tackle multiple bias types simultaneously.

</details>
</details>